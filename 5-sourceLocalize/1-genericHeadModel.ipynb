{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "# from sklearn.decomposition import FastICA\n",
    "# from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from itertools import combinations\n",
    "# from sklearn.preprocessing import normalize\n",
    "# from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import Pool\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroudTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt = load_groudtruth('./HEXACO.csv')\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(['H','E','X','A','C','O'],[ sum(gt['lh']), sum(gt['le']), sum(gt['lx']), sum(gt['la']), sum(gt['lc']), sum(gt['lo'])  ])\n",
    "ax.set_title(\"Distribution of Labels\")\n",
    "ax.set_xlabel(\"Labels\")\n",
    "# ax.set_ylabel(\"Distribution of Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from cache\n"
     ]
    }
   ],
   "source": [
    "# clear_cache()\n",
    "try:\n",
    "    # Load from cache\n",
    "    EEG_audio = load('EEG_audio')\n",
    "    EEG_image = load('EEG_image')\n",
    "    print('Load data from cache')\n",
    "    if( set(EEG_audio.keys()) != set(EEG_image.keys()) ):\n",
    "        extra = None\n",
    "        if(len(EEG_audio.keys()) > len(EEG_image.keys())):\n",
    "            extra = set(EEG_audio.keys()).difference( set(EEG_image.keys()) )\n",
    "        else:\n",
    "            extra = set(EEG_image.keys()).difference( set(EEG_audio.keys()) )\n",
    "        raise ValueError(f\"In equal keys. audio has {len(EEG_audio.keys())} and image has {len(EEG_image.keys())}. The extra key is {extra}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    EEG_audio, EEG_image = load_data(path='./data',exclude_list=[11,36])\n",
    "    # Save to cache\n",
    "    save(EEG_audio, 'EEG_audio')\n",
    "    save(EEG_image, 'EEG_image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Head Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_model():\n",
    "    import os.path as op\n",
    "    import numpy as np\n",
    "\n",
    "    import mne\n",
    "    from mne.datasets import eegbci\n",
    "    from mne.datasets import fetch_fsaverage\n",
    "\n",
    "    # Download fsaverage files\n",
    "    fs_dir = fetch_fsaverage(verbose=True)\n",
    "    subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "    # The files live in:\n",
    "    subject = 'fsaverage'\n",
    "    trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "    src = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif')\n",
    "    bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "    return trans, src, bem\n",
    "\n",
    "def get_forward(info):\n",
    "\n",
    "    trans, src, bem = get_head_model()\n",
    "    fwd = mne.make_forward_solution(info, trans=trans, src=src,\n",
    "                                bem=bem, eeg=True, mindist=5.0, n_jobs=1)\n",
    "    return fwd\n",
    "\n",
    "def get_raw(df,sfreq):\n",
    "    raw = dataframe_to_raw(df, sfreq=sfreq)\n",
    "    #### Preprocess\n",
    "    # High-pass at 0.1 Hz with  FIR filter; zero phase; Hamming Window; Auto select length and Bandwidth\n",
    "    raw.filter(l_freq=0.1,h_freq=None,method='fir',phase='zero',fir_window='hamming') # Slow drift\n",
    "    # Notch Filter at 50,100,150,200 Hz with FIR filter; zero phase; Hamming Window, Bandwidth = 0.1; auto length selection\n",
    "    raw.notch_filter(freqs=[50],method='fir', phase='zero', fir_window='hamming',trans_bandwidth=0.1, filter_length='auto') # Line power\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files missing from root.txt in /home/akrarads/mne_data/MNE-fsaverage-data\n",
      "0 files missing from bem.txt in /home/akrarads/mne_data/MNE-fsaverage-data/fsaverage\n",
      "Source space          : /home/akrarads/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif\n",
      "MRI -> head transform : /home/akrarads/venv/hci/lib/python3.8/site-packages/mne/data/fsaverage/fsaverage-trans.fif\n",
      "Measurement data      : instance of Info\n",
      "Conductor model   : /home/akrarads/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Accurate field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Reading /home/akrarads/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif...\n",
      "Read 2 source spaces a total of 20484 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "     0.999994  0.003552  0.000202      -1.76 mm\n",
      "    -0.003558  0.998389  0.056626      31.09 mm\n",
      "    -0.000001 -0.056626  0.998395      39.60 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "\n",
      "Read   8 EEG channels from info\n",
      "Head coordinate coil definitions created.\n",
      "Source spaces are now in head coordinates.\n",
      "\n",
      "Setting up the BEM model using /home/akrarads/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif...\n",
      "\n",
      "Loading surfaces...\n",
      "\n",
      "Loading the solution matrix...\n",
      "\n",
      "Three-layer model surfaces loaded.\n",
      "Loaded linear_collocation BEM solution from /home/akrarads/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Employing the head->MRI coordinate transform with the BEM model.\n",
      "BEM model fsaverage-5120-5120-5120-bem-sol.fif is now set up\n",
      "\n",
      "Source spaces are in head coordinates.\n",
      "Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)\n",
      "    Skipping interior check for 2433 sources that fit inside a sphere of radius   47.7 mm\n",
      "    Skipping solid angle check for 0 points using Qhull\n",
      "    Skipping interior check for 2241 sources that fit inside a sphere of radius   47.7 mm\n",
      "    Skipping solid angle check for 0 points using Qhull\n",
      "\n",
      "Setting up for EEG...\n",
      "Computing EEG at 20484 source locations (free orientations)...\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# mne.set_config('SUBJECTS_DIR','/home/akrarads/mne_data/MNE-fsaverage-data')\n",
    "# mne.get_config()\n",
    "\n",
    "#### Just get fwd ####\n",
    "with get_raw(df=EEG_image[33],sfreq=250) as raw:\n",
    "    fwd = get_forward(raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = dataframe_to_raw(EEG_image[33], sfreq=250)\n",
    "#### Preprocess\n",
    "# High-pass at 0.1 Hz with  FIR filter; zero phase; Hamming Window; Auto select length and Bandwidth\n",
    "raw.filter(l_freq=0.1,h_freq=None,method='fir',phase='zero',fir_window='hamming', verbose=verbose) # Slow drift\n",
    "# Notch Filter at 50,100,150,200 Hz with FIR filter; zero phase; Hamming Window, Bandwidth = 0.1; auto length selection\n",
    "raw.notch_filter(freqs=[50],method='fir', phase='zero', fir_window='hamming',trans_bandwidth=0.1, filter_length='auto', verbose=verbose) # Line power\n",
    "\n",
    "events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=verbose, uint_cast=False)\n",
    "events_dict = dict({\n",
    "    1: [],\n",
    "    2: [],\n",
    "    3: [],\n",
    "    4: [],\n",
    "    5: [],\n",
    "})\n",
    "for row in events:\n",
    "    row[2] = int(str(row[2])[0])\n",
    "    events_dict[row[2]].append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_dict = dict()\n",
    "epochs_dict['all'] = mne.Epochs(raw, events, tmin=0, tmax=6, baseline=(0,1), verbose=verbose, preload=True)\n",
    "for cat in range(1,6): #1 -> 5\n",
    "    epochs_dict[cat] = mne.Epochs(raw, events_dict[cat], tmin=0, tmax=6, baseline=(0,1), verbose=verbose, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.8e-11 (2.2e-16 eps * 8 dim * 1.6e+04  max singular value)\n",
      "    Estimated rank (eeg): 8\n",
      "    EEG: rank 8 computed from 8 data channels with 0 projectors\n",
      "Reducing data rank from 8 -> 8\n",
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using DIAGONAL_FIXED\n",
      "    EEG regularization : 0.1\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "    EEG regularization : 0.1\n",
      "    EEG regularization : 0.1\n",
      "    EEG regularization : 0.1\n",
      "Number of samples used : 88559\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -33.283\n",
      "   empirical: -33.359\n",
      "   diagonal_fixed: -33.396\n",
      "selecting best estimator: shrunk\n",
      "[done]\n",
      "====================\n",
      "Computing inverse operator with 8 channels.\n",
      "    8 out of 8 channels remain after picking\n",
      "Selected 8 channels\n",
      "Creating the depth weighting matrix...\n",
      "    8 EEG channels\n",
      "    limit = 20485/20484 = 3.432080\n",
      "    scale = 14529.9 exp = 0.1\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4.7e-14 (2.2e-16 eps * 8 dim * 26  max singular value)\n",
      "    Estimated rank (eeg): 8\n",
      "    EEG: rank 8 computed from 8 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 2.01289\n",
      "    scaling factor to adjust the trace = 5.40612e+18 (nchan = 8 nzero = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-119-c0f9ffc9ab5c>:8: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inv = mne.minimum_norm.make_inverse_operator(raw.info, fwd, cov, loose=1, depth=0.1)\n",
      "<ipython-input-119-c0f9ffc9ab5c>:8: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inv = mne.minimum_norm.make_inverse_operator(raw.info, fwd, cov, loose=1, depth=0.1)\n"
     ]
    }
   ],
   "source": [
    "# f = epochs_1.average().plot()\n",
    "# f = epochs_2.average().plot()\n",
    "# f = epochs_3.average().plot()\n",
    "# f = epochs_4.average().plot()\n",
    "# f = epochs_5.average().plot()\n",
    "cov = mne.compute_covariance(epochs_dict['all'], method='auto')\n",
    "print('='*20)\n",
    "inv = mne.minimum_norm.make_inverse_operator(raw.info, fwd, cov, loose=1, depth=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a30f4385b3f96ea1f19840f1ab5b961aed18d97e42a99090a74c3e6c2d4f9ce"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('py3': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
