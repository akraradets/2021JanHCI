{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import Pool\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groud truth - Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>e</th>\n",
       "      <th>x</th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "      <th>o</th>\n",
       "      <th>lh</th>\n",
       "      <th>le</th>\n",
       "      <th>lx</th>\n",
       "      <th>la</th>\n",
       "      <th>lc</th>\n",
       "      <th>lo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.63</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.38</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.19</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.13</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.06</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.94</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.44</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.63</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.31</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.81</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.06</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.63</td>\n",
       "      <td>3.69</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.75</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.19</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.81</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.50</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.50</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.63</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.19</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.56</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.44</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.50</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.94</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.06</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.00</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.38</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.69</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.56</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.63</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       h     e     x     a     c     o  lh  le  lx  la  lc  lo\n",
       "id                                                            \n",
       "2   3.63  3.19  2.94  2.38  3.38  2.38   1   0   0   0   0   0\n",
       "3   3.38  3.44  3.50  3.50  4.50  3.81   0   0   1   1   1   1\n",
       "4   3.19  3.75  3.69  3.19  2.63  2.63   0   1   1   0   0   0\n",
       "5   3.25  3.63  2.13  3.56  3.63  2.31   0   1   0   1   1   0\n",
       "6   3.25  2.75  3.50  2.50  3.75  5.00   0   0   1   0   1   1\n",
       "7   4.06  3.06  3.38  2.88  2.50  4.19   1   0   1   0   0   1\n",
       "8   3.94  2.94  3.19  3.75  3.38  3.81   1   0   1   1   0   1\n",
       "9   4.44  4.00  3.38  3.75  3.69  3.31   1   1   1   1   1   0\n",
       "10  3.63  3.25  3.50  3.31  3.88  2.69   1   0   1   1   1   0\n",
       "11  3.31  4.00  2.25  3.19  2.81  3.19   0   1   0   0   0   0\n",
       "12  2.81  3.44  3.13  3.56  3.25  3.75   0   0   1   1   0   1\n",
       "13  3.06  3.06  3.00  2.69  3.31  3.44   0   0   0   0   0   0\n",
       "14  4.63  3.69  2.25  3.13  2.94  2.63   1   1   0   0   0   0\n",
       "15  3.75  2.94  2.94  3.50  4.19  3.19   1   0   0   1   1   0\n",
       "16  4.19  4.25  1.88  2.81  3.25  3.81   1   1   0   0   0   1\n",
       "17  4.25  3.00  4.00  2.50  3.25  3.25   1   0   1   0   0   0\n",
       "18  2.81  3.31  2.06  2.75  3.00  3.19   0   0   0   0   0   0\n",
       "20  3.25  3.31  4.31  3.44  2.00  4.25   0   0   1   1   0   1\n",
       "21  4.06  3.00  2.88  3.56  3.81  3.81   1   0   0   1   1   1\n",
       "22  3.50  3.88  1.88  2.63  3.94  3.69   0   1   0   0   1   1\n",
       "23  3.13  4.19  3.00  2.38  2.88  3.88   0   1   0   0   0   1\n",
       "25  3.25  3.44  3.75  3.50  3.88  3.44   0   0   1   1   1   0\n",
       "26  3.50  3.19  2.44  2.94  2.44  3.25   0   0   0   0   0   0\n",
       "27  2.63  3.88  3.81  3.88  3.31  3.88   0   1   1   1   0   1\n",
       "28  3.19  4.31  2.19  1.88  2.56  3.25   0   1   0   0   0   0\n",
       "29  3.56  4.38  2.06  2.94  3.44  4.56   1   1   0   0   1   1\n",
       "30  4.50  3.81  2.44  3.13  2.94  4.31   1   1   0   0   0   1\n",
       "31  4.06  3.56  2.63  3.31  3.75  4.06   1   1   0   1   1   1\n",
       "32  2.75  3.25  3.75  2.81  3.06  3.31   0   0   1   0   0   0\n",
       "33  4.00  3.56  2.38  3.63  3.63  3.19   1   1   0   1   1   0\n",
       "34  3.38  2.69  3.69  3.31  3.81  3.50   0   0   1   1   1   0\n",
       "35  3.69  3.44  3.56  4.00  3.38  4.38   1   0   1   1   0   1\n",
       "36  3.56  4.56  3.31  3.63  4.38  4.31   1   1   1   1   1   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv('./HEXACO.csv')\n",
    "# Honesty-Humility\tEmotionality\teXtraversion\tAgreeableness\tConscientiousness\tOpenness to Experience\n",
    "gt = df[['id','Honesty-Humility','Emotionality','eXtraversion','Agreeableness','Conscientiousness','Openness to Experience']].rename(columns={'Honesty-Humility':'h',\n",
    "                                  'Emotionality':'e',\n",
    "                                  'eXtraversion':'x',\n",
    "                                 'Agreeableness':'a',\n",
    "                             'Conscientiousness':'c',\n",
    "                        'Openness to Experience':'o'}).set_index('id')\n",
    "\n",
    "gt['lh'] = (gt[['h']] > np.median(gt['h'])) * 1\n",
    "gt['le'] = (gt[['e']] > np.median(gt['e'])) * 1\n",
    "gt['lx'] = (gt[['x']] > np.median(gt['x'])) * 1\n",
    "gt['la'] = (gt[['a']] > np.median(gt['a'])) * 1\n",
    "gt['lc'] = (gt[['c']] > np.median(gt['c'])) * 1\n",
    "gt['lo'] = (gt[['o']] > np.median(gt['o'])) * 1\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "ax.bar(['H','E','X','A','C','O'],[ sum(gt['lh']), sum(gt['le']), sum(gt['lx']), sum(gt['la']), sum(gt['lc']), sum(gt['lo'])  ])\n",
    "ax.set_title(\"Distribution of Labels\")\n",
    "ax.set_xlabel(\"Labels\")\n",
    "# ax.set_ylabel(\"Distribution of Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path, folders, filenames = next(walk('./data'))\n",
    "\n",
    "    filenames.remove('11-audio.csv')\n",
    "    filenames.remove('11-image.csv')\n",
    "\n",
    "    filenames.remove('36-audio.csv')\n",
    "    filenames.remove('36-image.csv')\n",
    "\n",
    "    path = './data'\n",
    "    columns = {'Unnamed: 1':'Fp1',\n",
    "            'Unnamed: 2':'Fp2',\n",
    "            'Unnamed: 3':'F3',\n",
    "            'Unnamed: 4':'F4',\n",
    "            'Unnamed: 5':'F7',\n",
    "            'Unnamed: 6':'F8',\n",
    "            'Unnamed: 7':'P7',\n",
    "            'Unnamed: 8':'P8'}\n",
    "\n",
    "    EEG_audio, EEG_image = dict(), dict()\n",
    "    from itertools import product\n",
    "    categories = [1,2,3,4,5]\n",
    "    blocks = [1,2]\n",
    "    with tqdm(filenames) as t:\n",
    "        for filename in t:\n",
    "            t.set_description(f\"{filename}\")\n",
    "            participant_id, stimuli = filename.split('-')\n",
    "            stimuli = stimuli.rstrip('.csv')\n",
    "            data = pandas.read_csv(f'{path}/{filename}', dtype={'Marker': str}).rename(columns=columns).drop(columns='timestamps')\n",
    "            # Aviod warning on stim has negative value\n",
    "            marker = np.array(data['Marker'])\n",
    "            marker[marker == '-1'] = '1'\n",
    "            data['Marker'] = marker\n",
    "\n",
    "            if(stimuli == 'audio'):\n",
    "                EEG_audio[int(participant_id)] = data\n",
    "            elif(stimuli == 'image'):\n",
    "                EEG_image[int(participant_id)] = data\n",
    "            else:\n",
    "                raise ValueError(f\"Stimuli:{stimuli} is unexpected.\")\n",
    "    return EEG_audio, EEG_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from cache\n"
     ]
    }
   ],
   "source": [
    "# clear_cache()\n",
    "try:\n",
    "    # Load from cache\n",
    "    EEG_audio = load('EEG_audio')\n",
    "    EEG_image = load('EEG_image')\n",
    "    print('Load data from cache')\n",
    "    if( set(EEG_audio.keys()) != set(EEG_image.keys()) ):\n",
    "        extra = None\n",
    "        if(len(EEG_audio.keys()) > len(EEG_image.keys())):\n",
    "            extra = set(EEG_audio.keys()).difference( set(EEG_image.keys()) )\n",
    "        else:\n",
    "            extra = set(EEG_image.keys()).difference( set(EEG_audio.keys()) )\n",
    "        raise ValueError(f\"In equal keys. audio has {len(EEG_audio.keys())} and image has {len(EEG_image.keys())}. The extra key is {extra}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    EEG_audio, EEG_image = load_data()\n",
    "    # Save to cache\n",
    "    save(EEG_audio, 'EEG_audio')\n",
    "    save(EEG_image, 'EEG_image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre process with PSD + log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "# raw = dataframe_to_raw(EEG_image[33], sfreq=250)\n",
    "            \n",
    "# # Preprocess\n",
    "# raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "# raw.filter(1., None, verbose=False) # Slow drift\n",
    "# ica = mne.preprocessing.ICA(n_components=8, max_iter='auto')\n",
    "# ica.fit(raw, verbose=False)\n",
    "# raw = ica.apply(raw, verbose=False)\n",
    "\n",
    "# events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "# events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "# # Check data\n",
    "# if(events.shape[0] != 50):\n",
    "#     raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "# epochs = mne.Epochs(raw, events, tmin=0.3, tmax=5.8, baseline=(0.3,0.3), verbose=False)\n",
    "# if(epochs.get_data().shape[0] != 50):\n",
    "#     raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "# # Extract features\n",
    "\n",
    "# for evoked in epochs.iter_evoked():\n",
    "#     power,freq = mne.time_frequency.psd_array_welch(evoked.data,sfreq=250,n_fft=128, verbose=False)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filt = filter_list[0]\n",
    "# print(power.shape, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# for filt in filter_list:\n",
    "#     a = np.argwhere((freq <= filt[1]) & (freq >= filt[0])).reshape(-1)\n",
    "#     # print(a.reshape(-1))\n",
    "#     features.append(list(power[:,a].mean(axis=0)))\n",
    "#     # break\n",
    "# np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = np.array(['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma'])\n",
    "filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "def build_data(p_num, EEG,ids):\n",
    "    X = None\n",
    "    Y = None\n",
    "    with tqdm(ids) as t:\n",
    "        for index, id in enumerate(t):\n",
    "            t.set_description(f\"{id}\")\n",
    "            print(f\"p_no={p_num}|index={index}|id={id}\")\n",
    "            raw = dataframe_to_raw(EEG[id], sfreq=250)\n",
    "            \n",
    "            # Preprocess\n",
    "            raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "            raw.filter(1., None, verbose=False) # Slow drift\n",
    "            # ica = mne.preprocessing.ICA(n_components=8, max_iter='auto')\n",
    "            # ica.fit(raw, verbose=False)\n",
    "            # raw = ica.apply(raw, verbose=False)\n",
    "\n",
    "            events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "            events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "            # Check data\n",
    "            if(events.shape[0] != 50):\n",
    "                raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "            epochs = mne.Epochs(raw, events, tmin=0.3, tmax=5.8, baseline=(0.3,0.3), verbose=False)\n",
    "            if(epochs.get_data().shape[0] != 50):\n",
    "                raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "            # Extract features\n",
    "\n",
    "            for evoked in epochs.iter_evoked():\n",
    "                power,freq = mne.time_frequency.psd_array_welch(evoked.data,sfreq=250,n_fft=128, verbose=False)\n",
    "                # print(power.shape, power[:8].shape)\n",
    "                # row = power[:8].mean(axis=0)\n",
    "                # row = np.expand_dims(row.reshape(-1), axis=0)\n",
    "                row = power[:8]\n",
    "                row = np.expand_dims(row, axis=0)\n",
    "                row = 10 * np.log10(row)\n",
    "                if(type(X) == type(None)): X = row\n",
    "                else: X = np.concatenate( [X, row ], axis=0 )\n",
    "\n",
    "                label = gt.loc[id][['lh','le','lx','la','lc','lo']].to_numpy()\n",
    "                label = np.expand_dims(label, axis=0)\n",
    "                if(type(Y) == type(None)): Y = label\n",
    "                else: Y = np.concatenate( [Y, label ], axis=0 )\n",
    "\n",
    "    print(f\"{p_num} done| {ids}\")\n",
    "    return np.array(X),np.array(Y),freq\n",
    "\n",
    "def get_accuracy(X,y):\n",
    "    result = []\n",
    "    traits = [\"h\",\"e\",\"x\",\"a\",\"c\",\"o\"]\n",
    "    for index,label in enumerate(traits):\n",
    "        y = Y[:,index]\n",
    "        X_copy = X.copy() * -1\n",
    "        X_copy = normalize(X_copy,axis=0)\n",
    "        mnb = MultinomialNB()\n",
    "        mnb.fit(X_copy, y)\n",
    "        acc = sum(mnb.predict(X_copy) == y) / len(y)\n",
    "        scores = cross_val_score(mnb, X_copy, y)\n",
    "        result.append([acc,scores.mean(),scores.std()])\n",
    "        print(label,\"| Accuracy: %0.2f Scores: %0.2f (+/- %0.2f)\" % (acc,scores.mean(), scores.std() * 2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_no=1|index=0|id=10\n",
      "p_no=2|index=0|id=12\n",
      "p_no=3|index=0|id=13\n",
      "p_no=4|index=0|id=14\n",
      "p_no=5|index=0|id=15\n",
      "p_no=6|index=0|id=16\n",
      "p_no=1|index=1|id=17\n",
      "p_no=2|index=1|id=18\n",
      "p_no=3|index=1|id=2\n",
      "p_no=4|index=1|id=20\n",
      "p_no=5|index=1|id=21\n",
      "p_no=6|index=1|id=22\n",
      "p_no=3|index=2|id=26\n",
      "p_no=2|index=2|id=25\n",
      "p_no=1|index=2|id=23\n",
      "p_no=5|index=2|id=28\n",
      "p_no=4|index=2|id=27\n",
      "p_no=6|index=2|id=29\n",
      "p_no=2|index=3|id=30\n",
      "p_no=3|index=3|id=31\n",
      "p_no=1|index=3|id=3\n",
      "p_no=5|index=3|id=33\n",
      "p_no=4|index=3|id=32\n",
      "p_no=6|index=3|id=34\n",
      "p_no=3|index=4|id=6\n",
      "p_no=1|index=4|id=35\n",
      "p_no=5|index=4|id=8\n",
      "p_no=4|index=4|id=7\n",
      "p_no=2|index=4|id=5\n",
      "p_no=6|index=4|id=9\n",
      "1 done| [10 17 23  3 35]\n",
      "3 done| [13  2 26 31  6]\n",
      "5 done| [15 21 28 33  8]\n",
      "2 done| [12 18 25 30  5]\n",
      "4 done| [14 20 27 32  7]\n",
      "6 done| [16 22 29 34  9]\n",
      "(1500, 8, 65) (1500, 6)\n",
      "========= close ========\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # [33,2,10,12,16]\n",
    "    t_out = 300\n",
    "    pool = Pool()\n",
    "    ids = np.array(list(EEG_image.keys()))\n",
    "    p1 = pool.apply_async(build_data, [1,EEG_image,ids[0::6]])\n",
    "    p2 = pool.apply_async(build_data, [2,EEG_image,ids[1::6]])\n",
    "    p3 = pool.apply_async(build_data, [3,EEG_image,ids[2::6]])\n",
    "    p4 = pool.apply_async(build_data, [4,EEG_image,ids[3::6]])\n",
    "    p5 = pool.apply_async(build_data, [5,EEG_image,ids[4::6]])\n",
    "    p6 = pool.apply_async(build_data, [6,EEG_image,ids[5::6]])\n",
    "    ans1 = p1.get(timeout=t_out)\n",
    "    ans2 = p2.get(timeout=t_out)\n",
    "    ans3 = p3.get(timeout=t_out)\n",
    "    ans4 = p4.get(timeout=t_out)\n",
    "    ans5 = p5.get(timeout=t_out)\n",
    "    ans6 = p6.get(timeout=t_out)\n",
    "    X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "    Y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "    freq = ans1[2]\n",
    "    print(X.shape, Y.shape)\n",
    "finally:\n",
    "    print(\"========= close ========\")\n",
    "    pool.close() \n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20121/1983967163.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Number 1 ====================\n",
      "  ['Delta']\n",
      "h | Accuracy: 0.53 Scores: 0.53 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.57 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.53 Scores: 0.53 (+/- 0.05)\n",
      " Averag accuracy: 0.5552222222222222 Average Score: 0.5548888888888889 Average Variance: 0.014972539957045018\n",
      "  ['Theta']\n",
      "h | Accuracy: 0.55 Scores: 0.55 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.57 (+/- 0.07)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.53 Scores: 0.53 (+/- 0.09)\n",
      " Averag accuracy: 0.5604444444444444 Average Score: 0.5598888888888888 Average Variance: 0.018821699570215605\n",
      "  ['Alpha']\n",
      "h | Accuracy: 0.58 Scores: 0.57 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.59 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.56 Scores: 0.55 (+/- 0.05)\n",
      " Averag accuracy: 0.5702222222222222 Average Score: 0.569111111111111 Average Variance: 0.013037633126072229\n",
      "  ['Beta']\n",
      "h | Accuracy: 0.63 Scores: 0.63 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.59 (+/- 0.07)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.63 Scores: 0.63 (+/- 0.04)\n",
      " Averag accuracy: 0.5923333333333333 Average Score: 0.591111111111111 Average Variance: 0.013065551264576189\n",
      "  ['Gamma']\n",
      "h | Accuracy: 0.67 Scores: 0.68 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.59 (+/- 0.09)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.70 Scores: 0.70 (+/- 0.03)\n",
      " Averag accuracy: 0.6112222222222222 Average Score: 0.6109999999999999 Average Variance: 0.014441353643321638\n",
      "==================== Number 2 ====================\n",
      "  ['Delta' 'Theta']\n",
      "h | Accuracy: 0.56 Scores: 0.55 (+/- 0.08)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.53 Scores: 0.52 (+/- 0.04)\n",
      " Averag accuracy: 0.5613333333333334 Average Score: 0.5578888888888889 Average Variance: 0.013522833865970951\n",
      "  ['Delta' 'Alpha']\n",
      "h | Accuracy: 0.55 Scores: 0.55 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.56 Scores: 0.56 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.54 Scores: 0.54 (+/- 0.05)\n",
      " Averag accuracy: 0.5582222222222222 Average Score: 0.5584444444444444 Average Variance: 0.013653520181220631\n",
      "  ['Delta' 'Beta']\n",
      "h | Accuracy: 0.60 Scores: 0.59 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.56 Scores: 0.56 (+/- 0.08)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.55 Scores: 0.55 (+/- 0.07)\n",
      " Averag accuracy: 0.5696666666666667 Average Score: 0.5668888888888889 Average Variance: 0.017162673392154423\n",
      "  ['Delta' 'Gamma']\n",
      "h | Accuracy: 0.61 Scores: 0.60 (+/- 0.03)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.57 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.66 Scores: 0.64 (+/- 0.03)\n",
      " Averag accuracy: 0.5935555555555556 Average Score: 0.5854444444444444 Average Variance: 0.009299972515607444\n",
      "  ['Theta' 'Alpha']\n",
      "h | Accuracy: 0.54 Scores: 0.54 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.57 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.58 Scores: 0.54 (+/- 0.07)\n",
      " Averag accuracy: 0.5657777777777777 Average Score: 0.5597777777777778 Average Variance: 0.015727201046036397\n",
      "  ['Theta' 'Beta']\n",
      "h | Accuracy: 0.65 Scores: 0.65 (+/- 0.09)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.08)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.61 (+/- 0.04)\n",
      " Averag accuracy: 0.5907777777777777 Average Score: 0.589 Average Variance: 0.018053479811992793\n",
      "  ['Theta' 'Gamma']\n",
      "h | Accuracy: 0.67 Scores: 0.66 (+/- 0.03)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.62 Scores: 0.57 (+/- 0.15)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.63 Scores: 0.62 (+/- 0.05)\n",
      " Averag accuracy: 0.6026666666666666 Average Score: 0.592 Average Variance: 0.018339660775235297\n",
      "  ['Alpha' 'Beta']\n",
      "h | Accuracy: 0.64 Scores: 0.63 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.65 Scores: 0.64 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.61 Scores: 0.60 (+/- 0.05)\n",
      " Averag accuracy: 0.6002222222222223 Average Score: 0.5943333333333333 Average Variance: 0.010687909139010235\n",
      "  ['Alpha' 'Gamma']\n",
      "h | Accuracy: 0.64 Scores: 0.63 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.56 (+/- 0.09)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.65 Scores: 0.65 (+/- 0.07)\n",
      " Averag accuracy: 0.5918888888888888 Average Score: 0.5903333333333333 Average Variance: 0.016738268620505477\n",
      "  ['Beta' 'Gamma']\n",
      "h | Accuracy: 0.67 Scores: 0.67 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.66 Scores: 0.65 (+/- 0.01)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.68 Scores: 0.67 (+/- 0.06)\n",
      " Averag accuracy: 0.6185555555555556 Average Score: 0.6162222222222221 Average Variance: 0.00905993489995261\n",
      "==================== Number 3 ====================\n",
      "  ['Delta' 'Theta' 'Alpha']\n",
      "h | Accuracy: 0.56 Scores: 0.55 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.54 Scores: 0.53 (+/- 0.07)\n",
      " Averag accuracy: 0.5635555555555555 Average Score: 0.5605555555555555 Average Variance: 0.01539286494256578\n",
      "  ['Delta' 'Theta' 'Beta']\n",
      "h | Accuracy: 0.63 Scores: 0.60 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.11)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.59 Scores: 0.58 (+/- 0.10)\n",
      " Averag accuracy: 0.5836666666666666 Average Score: 0.5768888888888889 Average Variance: 0.023287803623133842\n",
      "  ['Delta' 'Theta' 'Gamma']\n",
      "h | Accuracy: 0.63 Scores: 0.61 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.64 Scores: 0.62 (+/- 0.03)\n",
      " Averag accuracy: 0.5916666666666668 Average Score: 0.5833333333333333 Average Variance: 0.011549075115930299\n",
      "  ['Delta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.62 Scores: 0.60 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.56 Scores: 0.56 (+/- 0.07)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.57 Scores: 0.56 (+/- 0.06)\n",
      " Averag accuracy: 0.5743333333333333 Average Score: 0.5704444444444444 Average Variance: 0.0148375277406127\n",
      "  ['Delta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.61 Scores: 0.60 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.60 Scores: 0.60 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.63 Scores: 0.62 (+/- 0.07)\n",
      " Averag accuracy: 0.5897777777777776 Average Score: 0.5856666666666667 Average Variance: 0.013622532474020572\n",
      "  ['Delta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.62 Scores: 0.62 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.61 Scores: 0.60 (+/- 0.08)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.68 Scores: 0.65 (+/- 0.07)\n",
      " Averag accuracy: 0.6008888888888889 Average Score: 0.5938888888888888 Average Variance: 0.0164990492810735\n",
      "  ['Theta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.63 Scores: 0.63 (+/- 0.06)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.59 (+/- 0.08)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.59 (+/- 0.05)\n",
      " Averag accuracy: 0.5903333333333333 Average Score: 0.5853333333333334 Average Variance: 0.01554291879175245\n",
      "  ['Theta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.64 Scores: 0.63 (+/- 0.06)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.62 Scores: 0.61 (+/- 0.02)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.63 Scores: 0.63 (+/- 0.04)\n",
      " Averag accuracy: 0.5982222222222222 Average Score: 0.5967777777777777 Average Variance: 0.009939489309046116\n",
      "  ['Theta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.67 Scores: 0.67 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.62 Scores: 0.61 (+/- 0.12)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.65 Scores: 0.65 (+/- 0.04)\n",
      " Averag accuracy: 0.6071111111111112 Average Score: 0.6043333333333333 Average Variance: 0.016618514951807575\n",
      "  ['Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.65 Scores: 0.65 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.61 Scores: 0.60 (+/- 0.07)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.65 Scores: 0.65 (+/- 0.07)\n",
      " Averag accuracy: 0.6014444444444444 Average Score: 0.5991111111111111 Average Variance: 0.014659505229511928\n",
      "==================== Number 4 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.64 Scores: 0.62 (+/- 0.09)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.57 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.58 Scores: 0.58 (+/- 0.10)\n",
      " Averag accuracy: 0.5826666666666667 Average Score: 0.5773333333333334 Average Variance: 0.02091710730200078\n",
      "  ['Delta' 'Theta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.63 Scores: 0.61 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.60 Scores: 0.59 (+/- 0.03)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.63 Scores: 0.61 (+/- 0.06)\n",
      " Averag accuracy: 0.5933333333333334 Average Score: 0.5855555555555555 Average Variance: 0.011832482053655793\n",
      "  ['Delta' 'Theta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.65 Scores: 0.62 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.61 Scores: 0.61 (+/- 0.10)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.67 Scores: 0.64 (+/- 0.03)\n",
      " Averag accuracy: 0.6043333333333334 Average Score: 0.5948888888888889 Average Variance: 0.013941456549043578\n",
      "  ['Delta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.63 Scores: 0.62 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.59 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.65 Scores: 0.64 (+/- 0.06)\n",
      " Averag accuracy: 0.5943333333333333 Average Score: 0.5905555555555555 Average Variance: 0.012772255661044252\n",
      "  ['Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.65 Scores: 0.65 (+/- 0.03)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.66 Scores: 0.64 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.65 Scores: 0.65 (+/- 0.06)\n",
      " Averag accuracy: 0.6101111111111109 Average Score: 0.6073333333333334 Average Variance: 0.011771511107868638\n",
      "==================== Number 5 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.64 Scores: 0.62 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.61 Scores: 0.60 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.66 Scores: 0.63 (+/- 0.06)\n",
      " Averag accuracy: 0.6007777777777777 Average Score: 0.5924444444444444 Average Variance: 0.013991382512965058\n",
      "Best Score is 0.6162222222222221 at index 14 with combination ['Beta' 'Gamma']\n"
     ]
    }
   ],
   "source": [
    "X,Y = shuffle(X,Y)\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "\n",
    "result_image = []\n",
    "best_image = 0\n",
    "best_image_idx = -1\n",
    "best_image_comb = None\n",
    "for r in [1,2,3,4,5]:\n",
    "    print(\"=\"*20,f\"Number {r}\",\"=\"*20)\n",
    "    for comb in combinations([0,1,2,3,4],r):\n",
    "        print(\" \",band_names[list(comb)])\n",
    "        selected_x = None\n",
    "        # print(bands[ list(comb) ])\n",
    "        for pt in bands[ list(comb) ]:\n",
    "            # print(pt)\n",
    "            if(type(selected_x) == type(None)): selected_x = X[:,:,pt].mean(axis=2)\n",
    "            else:\n",
    "                selected_x = np.concatenate([selected_x, X[:,:,pt].mean(axis=2)], axis=1)\n",
    "        # print(selected_x.shape)\n",
    "        # pts = np.concatenate( bands[ list(comb) ] )\n",
    "        result = np.array(get_accuracy(selected_x,Y))\n",
    "        print(\" Averag accuracy:\", result[:,0].mean(), \"Average Score:\", result[:,1].mean(), \"Average Variance:\", result[:,2].mean())\n",
    "        result_image.append(result)\n",
    "        if(result[:,1].mean() > best_image):\n",
    "            best_image = result[:,1].mean()\n",
    "            best_image_idx = len(result_image)-1\n",
    "            best_image_comb = band_names[ list(comb) ]\n",
    "\n",
    "print(f\"Best Score is {best_image} at index {best_image_idx} with combination {best_image_comb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_no=1|index=0|id=10\n",
      "p_no=2|index=0|id=12\n",
      "p_no=3|index=0|id=13\n",
      "p_no=4|index=0|id=14\n",
      "p_no=5|index=0|id=15\n",
      "p_no=6|index=0|id=16\n",
      "p_no=1|index=1|id=17\n",
      "p_no=2|index=1|id=18\n",
      "p_no=3|index=1|id=2\n",
      "p_no=4|index=1|id=20\n",
      "p_no=5|index=1|id=21\n",
      "p_no=6|index=1|id=22\n",
      "p_no=1|index=2|id=23\n",
      "p_no=2|index=2|id=25\n",
      "p_no=3|index=2|id=26\n",
      "p_no=4|index=2|id=27\n",
      "p_no=5|index=2|id=28\n",
      "p_no=6|index=2|id=29\n",
      "p_no=1|index=3|id=3\n",
      "p_no=3|index=3|id=31\n",
      "p_no=2|index=3|id=30\n",
      "p_no=4|index=3|id=32\n",
      "p_no=5|index=3|id=33\n",
      "p_no=6|index=3|id=34\n",
      "p_no=3|index=4|id=6\n",
      "p_no=1|index=4|id=35\n",
      "p_no=2|index=4|id=5\n",
      "p_no=4|index=4|id=7\n",
      "p_no=5|index=4|id=8\n",
      "p_no=6|index=4|id=9\n",
      "3 done| [13  2 26 31  6]\n",
      "1 done| [10 17 23  3 35]\n",
      "4 done| [14 20 27 32  7]\n",
      "5 done| [15 21 28 33  8]\n",
      "6 done| [16 22 29 34  9]\n",
      "2 done| [12 18 25 30  5]\n",
      "(1500, 8, 65) (1500, 6)\n",
      "========= close ========\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # [33,2,10,12,16]\n",
    "    t_out = 300\n",
    "    pool = Pool()\n",
    "    ids = np.array(list(EEG_audio.keys()))\n",
    "    p1 = pool.apply_async(build_data, [1,EEG_audio,ids[0::6]])\n",
    "    p2 = pool.apply_async(build_data, [2,EEG_audio,ids[1::6]])\n",
    "    p3 = pool.apply_async(build_data, [3,EEG_audio,ids[2::6]])\n",
    "    p4 = pool.apply_async(build_data, [4,EEG_audio,ids[3::6]])\n",
    "    p5 = pool.apply_async(build_data, [5,EEG_audio,ids[4::6]])\n",
    "    p6 = pool.apply_async(build_data, [6,EEG_audio,ids[5::6]])\n",
    "    ans1 = p1.get(timeout=t_out)\n",
    "    ans2 = p2.get(timeout=t_out)\n",
    "    ans3 = p3.get(timeout=t_out)\n",
    "    ans4 = p4.get(timeout=t_out)\n",
    "    ans5 = p5.get(timeout=t_out)\n",
    "    ans6 = p6.get(timeout=t_out)\n",
    "    X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "    Y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "    print(X.shape, Y.shape)\n",
    "finally:\n",
    "    print(\"========= close ========\")\n",
    "    pool.close() \n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20121/2490288531.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Number 1 ====================\n",
      "  ['Delta']\n",
      "h | Accuracy: 0.59 Scores: 0.56 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.56 Scores: 0.55 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.60 Scores: 0.60 (+/- 0.04)\n",
      " Averag accuracy: 0.575 Average Score: 0.5681111111111111\n",
      "  ['Theta']\n",
      "h | Accuracy: 0.55 Scores: 0.53 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.60 Scores: 0.54 (+/- 0.08)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.58 Scores: 0.59 (+/- 0.03)\n",
      " Averag accuracy: 0.5722222222222221 Average Score: 0.5592222222222222\n",
      "  ['Alpha']\n",
      "h | Accuracy: 0.56 Scores: 0.56 (+/- 0.03)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.52 Scores: 0.51 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.55 Scores: 0.55 (+/- 0.03)\n",
      " Averag accuracy: 0.5562222222222222 Average Score: 0.555\n",
      "  ['Beta']\n",
      "h | Accuracy: 0.54 Scores: 0.55 (+/- 0.02)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.57 Scores: 0.57 (+/- 0.03)\n",
      " Averag accuracy: 0.5661111111111111 Average Score: 0.5667777777777777\n",
      "  ['Gamma']\n",
      "h | Accuracy: 0.59 Scores: 0.59 (+/- 0.06)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.54 Scores: 0.53 (+/- 0.03)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.59 Scores: 0.59 (+/- 0.04)\n",
      " Averag accuracy: 0.5697777777777777 Average Score: 0.5673333333333332\n",
      "==================== Number 2 ====================\n",
      "  ['Delta' 'Theta']\n",
      "h | Accuracy: 0.55 Scores: 0.54 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.55 Scores: 0.54 (+/- 0.03)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.60 Scores: 0.60 (+/- 0.04)\n",
      " Averag accuracy: 0.5666666666666665 Average Score: 0.5643333333333334\n",
      "  ['Delta' 'Alpha']\n",
      "h | Accuracy: 0.57 Scores: 0.56 (+/- 0.08)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.57 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.60 Scores: 0.60 (+/- 0.04)\n",
      " Averag accuracy: 0.5724444444444444 Average Score: 0.5711111111111111\n",
      "  ['Delta' 'Beta']\n",
      "h | Accuracy: 0.55 Scores: 0.55 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.55 Scores: 0.55 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.62 (+/- 0.02)\n",
      " Averag accuracy: 0.5707777777777777 Average Score: 0.5697777777777776\n",
      "  ['Delta' 'Gamma']\n",
      "h | Accuracy: 0.64 Scores: 0.62 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.57 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.62 (+/- 0.02)\n",
      " Averag accuracy: 0.5882222222222221 Average Score: 0.5836666666666667\n",
      "  ['Theta' 'Alpha']\n",
      "h | Accuracy: 0.61 Scores: 0.58 (+/- 0.02)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.61 Scores: 0.61 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.58 Scores: 0.58 (+/- 0.03)\n",
      " Averag accuracy: 0.5826666666666667 Average Score: 0.5772222222222222\n",
      "  ['Theta' 'Beta']\n",
      "h | Accuracy: 0.57 Scores: 0.56 (+/- 0.08)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.55 Scores: 0.54 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.60 Scores: 0.60 (+/- 0.03)\n",
      " Averag accuracy: 0.5712222222222222 Average Score: 0.5666666666666667\n",
      "  ['Theta' 'Gamma']\n",
      "h | Accuracy: 0.64 Scores: 0.62 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.55 Scores: 0.53 (+/- 0.01)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.60 Scores: 0.59 (+/- 0.06)\n",
      " Averag accuracy: 0.5805555555555556 Average Score: 0.5743333333333333\n",
      "  ['Alpha' 'Beta']\n",
      "h | Accuracy: 0.62 Scores: 0.60 (+/- 0.03)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.07)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.58 Scores: 0.58 (+/- 0.06)\n",
      " Averag accuracy: 0.5796666666666667 Average Score: 0.5775555555555555\n",
      "  ['Alpha' 'Gamma']\n",
      "h | Accuracy: 0.60 Scores: 0.60 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.61 (+/- 0.06)\n",
      " Averag accuracy: 0.5824444444444443 Average Score: 0.5808888888888888\n",
      "  ['Beta' 'Gamma']\n",
      "h | Accuracy: 0.64 Scores: 0.64 (+/- 0.02)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.65 Scores: 0.65 (+/- 0.03)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.60 Scores: 0.59 (+/- 0.04)\n",
      " Averag accuracy: 0.5983333333333333 Average Score: 0.596111111111111\n",
      "==================== Number 3 ====================\n",
      "  ['Delta' 'Theta' 'Alpha']\n",
      "h | Accuracy: 0.57 Scores: 0.56 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.60 Scores: 0.60 (+/- 0.04)\n",
      " Averag accuracy: 0.5746666666666668 Average Score: 0.5726666666666667\n",
      "  ['Delta' 'Theta' 'Beta']\n",
      "h | Accuracy: 0.55 Scores: 0.55 (+/- 0.06)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.55 Scores: 0.55 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.62 (+/- 0.02)\n",
      " Averag accuracy: 0.5715555555555556 Average Score: 0.5712222222222223\n",
      "  ['Delta' 'Theta' 'Gamma']\n",
      "h | Accuracy: 0.62 Scores: 0.61 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.57 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.62 (+/- 0.02)\n",
      " Averag accuracy: 0.5862222222222221 Average Score: 0.582\n",
      "  ['Delta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.58 Scores: 0.57 (+/- 0.08)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.57 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.61 (+/- 0.04)\n",
      " Averag accuracy: 0.5774444444444443 Average Score: 0.5762222222222221\n",
      "  ['Delta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.62 Scores: 0.59 (+/- 0.08)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.61 Scores: 0.61 (+/- 0.05)\n",
      " Averag accuracy: 0.5865555555555555 Average Score: 0.5815555555555555\n",
      "  ['Delta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.62 Scores: 0.61 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.57 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.63 Scores: 0.63 (+/- 0.02)\n",
      " Averag accuracy: 0.5862222222222222 Average Score: 0.5841111111111111\n",
      "  ['Theta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.62 Scores: 0.60 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.63 Scores: 0.62 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      " Averag accuracy: 0.5883333333333333 Average Score: 0.5843333333333333\n",
      "  ['Theta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.63 Scores: 0.62 (+/- 0.05)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.63 Scores: 0.62 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.60 Scores: 0.60 (+/- 0.04)\n",
      " Averag accuracy: 0.5926666666666667 Average Score: 0.5903333333333333\n",
      "  ['Theta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.65 Scores: 0.63 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.62 Scores: 0.61 (+/- 0.09)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.61 Scores: 0.60 (+/- 0.05)\n",
      " Averag accuracy: 0.5953333333333334 Average Score: 0.5906666666666666\n",
      "  ['Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.65 Scores: 0.64 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.59 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.64 Scores: 0.62 (+/- 0.03)\n",
      " Averag accuracy: 0.5958888888888888 Average Score: 0.5913333333333332\n",
      "==================== Number 4 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.59 Scores: 0.57 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.61 (+/- 0.03)\n",
      " Averag accuracy: 0.5796666666666667 Average Score: 0.576111111111111\n",
      "  ['Delta' 'Theta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.63 Scores: 0.60 (+/- 0.08)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.59 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.61 (+/- 0.04)\n",
      " Averag accuracy: 0.589111111111111 Average Score: 0.584\n",
      "  ['Delta' 'Theta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.61 Scores: 0.59 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.57 Scores: 0.57 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.63 Scores: 0.63 (+/- 0.02)\n",
      " Averag accuracy: 0.5841111111111111 Average Score: 0.5812222222222222\n",
      "  ['Delta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.62 Scores: 0.62 (+/- 0.08)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.58 (+/- 0.05)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.62 (+/- 0.04)\n",
      " Averag accuracy: 0.588 Average Score: 0.5862222222222221\n",
      "  ['Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.66 Scores: 0.64 (+/- 0.04)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.64 Scores: 0.63 (+/- 0.04)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.61 Scores: 0.62 (+/- 0.03)\n",
      " Averag accuracy: 0.6015555555555556 Average Score: 0.5982222222222222\n",
      "==================== Number 5 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.62 Scores: 0.61 (+/- 0.07)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.00)\n",
      "x | Accuracy: 0.53 Scores: 0.53 (+/- 0.00)\n",
      "a | Accuracy: 0.59 Scores: 0.59 (+/- 0.06)\n",
      "c | Accuracy: 0.57 Scores: 0.57 (+/- 0.00)\n",
      "o | Accuracy: 0.62 Scores: 0.62 (+/- 0.03)\n",
      " Averag accuracy: 0.5887777777777777 Average Score: 0.5865555555555555\n",
      "Best Score is 0.5982222222222222 at index 29 with combination ['Theta' 'Alpha' 'Beta' 'Gamma']\n"
     ]
    }
   ],
   "source": [
    "X,Y = shuffle(X,Y)\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "\n",
    "result_audio = []\n",
    "best_audio = 0\n",
    "best_audio_idx = -1\n",
    "best_audio_comb = None\n",
    "for r in [1,2,3,4,5]:\n",
    "    print(\"=\"*20,f\"Number {r}\",\"=\"*20)\n",
    "    for comb in combinations([0,1,2,3,4],r):\n",
    "        print(\" \",band_names[list(comb)])\n",
    "        selected_x = None\n",
    "        # print(bands[ list(comb) ])\n",
    "        for pt in bands[ list(comb) ]:\n",
    "            # print(pt)\n",
    "            if(type(selected_x) == type(None)): selected_x = X[:,:,pt].mean(axis=2)\n",
    "            else:\n",
    "                selected_x = np.concatenate([selected_x, X[:,:,pt].mean(axis=2)], axis=1)\n",
    "        # print(selected_x.shape)\n",
    "        # pts = np.concatenate( bands[ list(comb) ] )\n",
    "        result = np.array(get_accuracy(selected_x,Y))\n",
    "        print(\" Averag accuracy:\", result[:,0].mean(), \"Average Score:\", result[:,1].mean()), \"Average Variance:\", result[:,2].mean()\n",
    "        result_audio.append(result)\n",
    "        if(result[:,1].mean() > best_audio):\n",
    "            best_audio = result[:,1].mean()\n",
    "            best_audio_idx = len(result_audio)-1\n",
    "            best_audio_comb = band_names[ list(comb) ]\n",
    "\n",
    "print(f\"Best Score is {best_audio} at index {best_audio_idx} with combination {best_audio_comb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_image = np.array(result_image)\n",
    "result_audio = np.array(result_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 6, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traits = [\"h\",\"e\",\"x\",\"a\",\"c\",\"o\"]\n",
    "width =.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.bar(np.arange(6)      ,result_image[14,:,0] * 100, width=width, label='image', ecolor='black', capsize=10)\n",
    "ax.bar(np.arange(6)+width,result_audio[29,:,0] * 100, width=width, label='audio', ecolor='black', capsize=10)\n",
    "\n",
    "ax.set_xlabel('Traits')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Accuracy of each trait prediction')\n",
    "ax.set_xticks(np.arange(6) + width / 2)\n",
    "ax.set_xticklabels(traits)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, image accuracy is 0.62 and audio accuracy is 0.6\n",
      "On average, image    score is 0.62 and audio    score is 0.6\n",
      "On average, image      std is 0.01 and audio      std is 0.01\n"
     ]
    }
   ],
   "source": [
    "print(f\"On average, image accuracy is {round(result_image[14,:,0].mean(),2)} and audio accuracy is {round(result_audio[29,:,0].mean(),2)}\")\n",
    "print(f\"On average, image    score is {round(result_image[14,:,1].mean(),2)} and audio    score is {round(result_audio[29,:,1].mean(),2)}\")\n",
    "print(f\"On average, image      std is {round(result_image[14,:,2].mean(),2)} and audio      std is {round(result_audio[29,:,2].mean(),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([0,1,2]).reshape(-1,1)\n",
    "a2 = np.array([0,1,2]).reshape(-1,1)\n",
    "a = np.concatenate([a1,a2], axis=1)\n",
    "print(a)\n",
    "normalize(a,axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}