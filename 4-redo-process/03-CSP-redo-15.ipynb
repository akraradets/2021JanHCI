{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import Pool\n",
    "plt.style.use('seaborn-whitegrid')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Groud truth - Median"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df = pandas.read_csv('./HEXACO.csv')\n",
    "# Honesty-Humility\tEmotionality\teXtraversion\tAgreeableness\tConscientiousness\tOpenness to Experience\n",
    "gt = df[['id','Honesty-Humility','Emotionality','eXtraversion','Agreeableness','Conscientiousness','Openness to Experience']].rename(columns={'Honesty-Humility':'h',\n",
    "                                  'Emotionality':'e',\n",
    "                                  'eXtraversion':'x',\n",
    "                                 'Agreeableness':'a',\n",
    "                             'Conscientiousness':'c',\n",
    "                        'Openness to Experience':'o'}).set_index('id')\n",
    "\n",
    "gt['lh'] = (gt[['h']] > np.median(gt['h'])) * 1\n",
    "gt['le'] = (gt[['e']] > np.median(gt['e'])) * 1\n",
    "gt['lx'] = (gt[['x']] > np.median(gt['x'])) * 1\n",
    "gt['la'] = (gt[['a']] > np.median(gt['a'])) * 1\n",
    "gt['lc'] = (gt[['c']] > np.median(gt['c'])) * 1\n",
    "gt['lo'] = (gt[['o']] > np.median(gt['o'])) * 1\n",
    "gt"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       h     e     x     a     c     o  lh  le  lx  la  lc  lo\n",
       "id                                                            \n",
       "2   3.63  3.19  2.94  2.38  3.38  2.38   1   0   0   0   0   0\n",
       "3   3.38  3.44  3.50  3.50  4.50  3.81   0   0   1   1   1   1\n",
       "4   3.19  3.75  3.69  3.19  2.63  2.63   0   1   1   0   0   0\n",
       "5   3.25  3.63  2.13  3.56  3.63  2.31   0   1   0   1   1   0\n",
       "6   3.25  2.75  3.50  2.50  3.75  5.00   0   0   1   0   1   1\n",
       "7   4.06  3.06  3.38  2.88  2.50  4.19   1   0   1   0   0   1\n",
       "8   3.94  2.94  3.19  3.75  3.38  3.81   1   0   1   1   0   1\n",
       "9   4.44  4.00  3.38  3.75  3.69  3.31   1   1   1   1   1   0\n",
       "10  3.63  3.25  3.50  3.31  3.88  2.69   1   0   1   1   1   0\n",
       "11  3.31  4.00  2.25  3.19  2.81  3.19   0   1   0   0   0   0\n",
       "12  2.81  3.44  3.13  3.56  3.25  3.75   0   0   1   1   0   1\n",
       "13  3.06  3.06  3.00  2.69  3.31  3.44   0   0   0   0   0   0\n",
       "14  4.63  3.69  2.25  3.13  2.94  2.63   1   1   0   0   0   0\n",
       "15  3.75  2.94  2.94  3.50  4.19  3.19   1   0   0   1   1   0\n",
       "16  4.19  4.25  1.88  2.81  3.25  3.81   1   1   0   0   0   1\n",
       "17  4.25  3.00  4.00  2.50  3.25  3.25   1   0   1   0   0   0\n",
       "18  2.81  3.31  2.06  2.75  3.00  3.19   0   0   0   0   0   0\n",
       "20  3.25  3.31  4.31  3.44  2.00  4.25   0   0   1   1   0   1\n",
       "21  4.06  3.00  2.88  3.56  3.81  3.81   1   0   0   1   1   1\n",
       "22  3.50  3.88  1.88  2.63  3.94  3.69   0   1   0   0   1   1\n",
       "23  3.13  4.19  3.00  2.38  2.88  3.88   0   1   0   0   0   1\n",
       "25  3.25  3.44  3.75  3.50  3.88  3.44   0   0   1   1   1   0\n",
       "26  3.50  3.19  2.44  2.94  2.44  3.25   0   0   0   0   0   0\n",
       "27  2.63  3.88  3.81  3.88  3.31  3.88   0   1   1   1   0   1\n",
       "28  3.19  4.31  2.19  1.88  2.56  3.25   0   1   0   0   0   0\n",
       "29  3.56  4.38  2.06  2.94  3.44  4.56   1   1   0   0   1   1\n",
       "30  4.50  3.81  2.44  3.13  2.94  4.31   1   1   0   0   0   1\n",
       "31  4.06  3.56  2.63  3.31  3.75  4.06   1   1   0   1   1   1\n",
       "32  2.75  3.25  3.75  2.81  3.06  3.31   0   0   1   0   0   0\n",
       "33  4.00  3.56  2.38  3.63  3.63  3.19   1   1   0   1   1   0\n",
       "34  3.38  2.69  3.69  3.31  3.81  3.50   0   0   1   1   1   0\n",
       "35  3.69  3.44  3.56  4.00  3.38  4.38   1   0   1   1   0   1\n",
       "36  3.56  4.56  3.31  3.63  4.38  4.31   1   1   1   1   1   1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>e</th>\n",
       "      <th>x</th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "      <th>o</th>\n",
       "      <th>lh</th>\n",
       "      <th>le</th>\n",
       "      <th>lx</th>\n",
       "      <th>la</th>\n",
       "      <th>lc</th>\n",
       "      <th>lo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.63</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.38</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.19</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.13</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.06</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.94</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.44</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.63</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.31</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.81</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.06</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.63</td>\n",
       "      <td>3.69</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.75</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.19</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.81</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.50</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.50</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.63</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.19</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.56</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.44</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.50</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.94</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.06</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.00</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.38</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.69</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.56</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.63</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "ax.bar(['H','E','X','A','C','O'],[ sum(gt['lh']), sum(gt['le']), sum(gt['lx']), sum(gt['la']), sum(gt['lc']), sum(gt['lo'])  ])\n",
    "ax.set_title(\"Distribution of Labels\")\n",
    "ax.set_xlabel(\"Labels\")\n",
    "# ax.set_ylabel(\"Distribution of Labels\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EEG data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def load_data():\n",
    "    path, folders, filenames = next(walk('./data'))\n",
    "\n",
    "    filenames.remove('11-audio.csv')\n",
    "    filenames.remove('11-image.csv')\n",
    "\n",
    "    filenames.remove('36-audio.csv')\n",
    "    filenames.remove('36-image.csv')\n",
    "\n",
    "    path = './data'\n",
    "    columns = {'Unnamed: 1':'Fp1',\n",
    "            'Unnamed: 2':'Fp2',\n",
    "            'Unnamed: 3':'F3',\n",
    "            'Unnamed: 4':'F4',\n",
    "            'Unnamed: 5':'F7',\n",
    "            'Unnamed: 6':'F8',\n",
    "            'Unnamed: 7':'P7',\n",
    "            'Unnamed: 8':'P8'}\n",
    "\n",
    "    EEG_audio, EEG_image = dict(), dict()\n",
    "    from itertools import product\n",
    "    categories = [1,2,3,4,5]\n",
    "    blocks = [1,2]\n",
    "    with tqdm(filenames) as t:\n",
    "        for filename in t:\n",
    "            t.set_description(f\"{filename}\")\n",
    "            participant_id, stimuli = filename.split('-')\n",
    "            stimuli = stimuli.rstrip('.csv')\n",
    "            data = pandas.read_csv(f'{path}/{filename}', dtype={'Marker': str}).rename(columns=columns).drop(columns='timestamps')\n",
    "            # Aviod warning on stim has negative value\n",
    "            marker = np.array(data['Marker'])\n",
    "            marker[marker == '-1'] = '1'\n",
    "            data['Marker'] = marker\n",
    "\n",
    "            if(stimuli == 'audio'):\n",
    "                EEG_audio[int(participant_id)] = data\n",
    "            elif(stimuli == 'image'):\n",
    "                EEG_image[int(participant_id)] = data\n",
    "            else:\n",
    "                raise ValueError(f\"Stimuli:{stimuli} is unexpected.\")\n",
    "    return EEG_audio, EEG_image\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# clear_cache()\n",
    "try:\n",
    "    # Load from cache\n",
    "    EEG_audio = load('EEG_audio')\n",
    "    EEG_image = load('EEG_image')\n",
    "    print('Load data from cache')\n",
    "    if( set(EEG_audio.keys()) != set(EEG_image.keys()) ):\n",
    "        extra = None\n",
    "        if(len(EEG_audio.keys()) > len(EEG_image.keys())):\n",
    "            extra = set(EEG_audio.keys()).difference( set(EEG_image.keys()) )\n",
    "        else:\n",
    "            extra = set(EEG_image.keys()).difference( set(EEG_audio.keys()) )\n",
    "        raise ValueError(f\"In equal keys. audio has {len(EEG_audio.keys())} and image has {len(EEG_image.keys())}. The extra key is {extra}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    EEG_audio, EEG_image = load_data()\n",
    "    # Save to cache\n",
    "    save(EEG_audio, 'EEG_audio')\n",
    "    save(EEG_image, 'EEG_image')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load data from cache\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre process with PSD + log + mne ICA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# raw = dataframe_to_raw(EEG_image[33], sfreq=250)\n",
    "\n",
    "# # Preprocess\n",
    "# raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "# raw.filter(1., None, verbose=False) # Slow drift\n",
    "\n",
    "# events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "# events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "# # Check data\n",
    "# if(events.shape[0] != 50):\n",
    "#     raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "# epochs = mne.Epochs(raw, events, tmin=0.3, tmax=5.8, baseline=(0.3,0.3), verbose=False)\n",
    "# if(epochs.get_data().shape[0] != 50):\n",
    "#     raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "# # for evoked in epochs.iter_evoked():\n",
    "# #     reduc = ica.apply(evoked, verbose=False)\n",
    "# #     power,freq = mne.time_frequency.psd_array_welch(reduc.data[:6],sfreq=250,n_fft=128, verbose=False)\n",
    "# #     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# # Extract features\n",
    "# events = np.array([int(event / 100) for event in epochs.events[:,2]])\n",
    "# Y = None\n",
    "# X = None\n",
    "# csp = mne.decoding.CSP(n_components=8, transform_into='csp_space', norm_trace=True)\n",
    "# data = csp.fit_transform(epochs.get_data()[:,:8,:], events)\n",
    "# print(data.shape)\n",
    "# for index, evoked in enumerate(epochs.iter_evoked()):\n",
    "#     # event = int(evoked.comment[0])\n",
    "#     # events.append(event)\n",
    "#     power,freq = mne.time_frequency.psd_array_welch(data[index],sfreq=250,n_fft=128, verbose=False)\n",
    "#     row = power\n",
    "#     row = np.expand_dims(row, axis=0)\n",
    "#     row = 10 * np.log10(row)\n",
    "#     if(type(X) == type(None)): X = row\n",
    "#     else: X = np.concatenate( [X, row ], axis=0 )\n",
    "\n",
    "#     label = gt.loc[33][['lh','le','lx','la','lc','lo']].to_numpy()\n",
    "#     label = np.expand_dims(label, axis=0)\n",
    "#     if(type(Y) == type(None)): Y = label\n",
    "#     else: Y = np.concatenate( [Y, label ], axis=0 )\n",
    "# print(events.shape, X.shape, Y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# data = X.copy().reshape(50,-1)\n",
    "# # data\n",
    "# print(data.shape)\n",
    "# data_norm = normalize(data.copy(), axis=0)\n",
    "# mnb = GaussianNB()\n",
    "# mnb.fit(data_norm, events)\n",
    "# acc = sum(mnb.predict(data_norm) == events) / len(events)\n",
    "# scores = cross_val_score(mnb, data_norm, events)\n",
    "# print(acc, scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# proj_data.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "band_names = np.array(['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma'])\n",
    "filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "def build_data(p_num, EEG,ids):\n",
    "    X = None\n",
    "    Y = None\n",
    "    t_start, t_stop = (2.0,4.0)\n",
    "    with tqdm(ids) as t:\n",
    "        for index, id in enumerate(t):\n",
    "            t.set_description(f\"{id}\")\n",
    "            print(f\"p_no={p_num}|index={index}|id={id}\")\n",
    "            raw = dataframe_to_raw(EEG[id], sfreq=250)\n",
    "            \n",
    "            # Preprocess\n",
    "            raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "            raw.filter(1., None, verbose=False) # Slow drift\n",
    "            # ica = mne.preprocessing.ICA(n_components=8, max_iter='auto')\n",
    "            # ica.fit(raw, verbose=False)\n",
    "            # raw = ica.apply(raw, verbose=False)\n",
    "\n",
    "            events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "            events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "            # Check data\n",
    "            if(events.shape[0] != 50):\n",
    "                raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "            epochs = mne.Epochs(raw, events, tmin=t_start, tmax=t_stop, baseline=(t_start,t_stop), verbose=False)\n",
    "            if(epochs.get_data().shape[0] != 50):\n",
    "                raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "            # Extract features\n",
    "            import sys\n",
    "            sys.stdout = open(os.devnull, 'w')\n",
    "            events = np.array([int(event / 100) for event in epochs.events[:,2]])\n",
    "            csp = mne.decoding.CSP(n_components=15, transform_into='csp_space', norm_trace=True)\n",
    "            data = csp.fit_transform(epochs.get_data()[:,:8,:], events)\n",
    "            for index_inner, evoked in enumerate(epochs.iter_evoked()):\n",
    "                power,freq = mne.time_frequency.psd_array_welch(data[index_inner],sfreq=250,n_fft=128, verbose=False)\n",
    "                row = power\n",
    "                row = np.expand_dims(row, axis=0)\n",
    "                row = 10 * np.log10(row)\n",
    "                if(type(X) == type(None)): X = row\n",
    "                else: X = np.concatenate( [X, row ], axis=0 )\n",
    "\n",
    "                label = gt.loc[id][['lh','le','lx','la','lc','lo']].to_numpy()\n",
    "                label = np.expand_dims(label, axis=0)\n",
    "                if(type(Y) == type(None)): Y = label\n",
    "                else: Y = np.concatenate( [Y, label ], axis=0 )\n",
    "            sys.stdout = sys.__stdout__\n",
    "    print(f\"{p_num} done| {ids}\")\n",
    "    return np.array(X),np.array(Y),freq\n",
    "\n",
    "def get_accuracy(X,y):\n",
    "    result = []\n",
    "    traits = [\"h\",\"e\",\"x\",\"a\",\"c\",\"o\"]\n",
    "    for index,label in enumerate(traits):\n",
    "        y = Y[:,index]\n",
    "        X_copy = X.copy()\n",
    "        X_copy = normalize(X_copy,axis=0)\n",
    "        mnb = GaussianNB()\n",
    "        mnb.fit(X_copy, y)\n",
    "        acc = sum(mnb.predict(X_copy) == y) / len(y)\n",
    "        scores = cross_val_score(mnb, X_copy, y)\n",
    "        result.append([acc,scores.mean(),scores.std()])\n",
    "        print(label,\"| Accuracy: %0.2f Scores: %0.2f (+/- %0.2f)\" % (acc,scores.mean(), scores.std() * 2))\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "try:\n",
    "    # [33,2,10,12,16]\n",
    "    t_out = 300\n",
    "    pool = Pool()\n",
    "    ids = np.array(list(EEG_image.keys()))\n",
    "    p1 = pool.apply_async(build_data, [1,EEG_image,ids[0::6]])\n",
    "    p2 = pool.apply_async(build_data, [2,EEG_image,ids[1::6]])\n",
    "    p3 = pool.apply_async(build_data, [3,EEG_image,ids[2::6]])\n",
    "    p4 = pool.apply_async(build_data, [4,EEG_image,ids[3::6]])\n",
    "    p5 = pool.apply_async(build_data, [5,EEG_image,ids[4::6]])\n",
    "    p6 = pool.apply_async(build_data, [6,EEG_image,ids[5::6]])\n",
    "    ans1 = p1.get(timeout=t_out)\n",
    "    ans2 = p2.get(timeout=t_out)\n",
    "    ans3 = p3.get(timeout=t_out)\n",
    "    ans4 = p4.get(timeout=t_out)\n",
    "    ans5 = p5.get(timeout=t_out)\n",
    "    ans6 = p6.get(timeout=t_out)\n",
    "    X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "    Y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "    freq = ans1[2]\n",
    "    print(X.shape, Y.shape)\n",
    "finally:\n",
    "    print(\"========= close ========\")\n",
    "    pool.close() \n",
    "    pool.terminate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p_no=1|index=0|id=10\n",
      "p_no=2|index=0|id=12\n",
      "p_no=3|index=0|id=13\n",
      "p_no=4|index=0|id=14\n",
      "p_no=5|index=0|id=15\n",
      "p_no=6|index=0|id=16\n",
      "p_no=1|index=1|id=17\n",
      "p_no=3|index=1|id=2\n",
      "p_no=2|index=1|id=18\n",
      "p_no=4|index=1|id=20\n",
      "p_no=5|index=1|id=21\n",
      "p_no=6|index=1|id=22\n",
      "p_no=3|index=2|id=26\n",
      "p_no=1|index=2|id=23\n",
      "p_no=2|index=2|id=25\n",
      "p_no=4|index=2|id=27\n",
      "p_no=5|index=2|id=28\n",
      "p_no=6|index=2|id=29\n",
      "p_no=3|index=3|id=31\n",
      "p_no=1|index=3|id=3\n",
      "p_no=4|index=3|id=32\n",
      "p_no=2|index=3|id=30\n",
      "p_no=5|index=3|id=33\n",
      "p_no=6|index=3|id=34\n",
      "p_no=1|index=4|id=35\n",
      "p_no=3|index=4|id=6\n",
      "p_no=4|index=4|id=7\n",
      "p_no=5|index=4|id=8\n",
      "p_no=2|index=4|id=5\n",
      "p_no=6|index=4|id=9\n",
      "1 done| [10 17 23  3 35]\n",
      "3 done| [13  2 26 31  6]\n",
      "4 done| [14 20 27 32  7]\n",
      "5 done| [15 21 28 33  8]\n",
      "6 done| [16 22 29 34  9]\n",
      "2 done| [12 18 25 30  5]\n",
      "(1500, 8, 65) (1500, 6)\n",
      "========= close ========\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "X,Y = shuffle(X,Y)\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "\n",
    "result_image = []\n",
    "best_image = 0\n",
    "best_image_idx = -1\n",
    "best_image_comb = None\n",
    "for r in [1,2,3,4,5]:\n",
    "    print(\"=\"*20,f\"Number {r}\",\"=\"*20)\n",
    "    for comb in combinations([0,1,2,3,4],r):\n",
    "        print(\" \",band_names[list(comb)])\n",
    "        selected_x = None\n",
    "        # print(bands[ list(comb) ])\n",
    "        for pt in bands[ list(comb) ]:\n",
    "            # print(pt)\n",
    "            if(type(selected_x) == type(None)): selected_x = X[:,:,pt].mean(axis=2)\n",
    "            else:\n",
    "                selected_x = np.concatenate([selected_x, X[:,:,pt].mean(axis=2)], axis=1)\n",
    "        # print(selected_x.shape)\n",
    "        # pts = np.concatenate( bands[ list(comb) ] )\n",
    "        result = np.array(get_accuracy(selected_x,Y))\n",
    "        print(\" Averag accuracy:\", result[:,0].mean(), \"Average Score:\", result[:,1].mean(), \"Average Variance:\", result[:,2].mean())\n",
    "        result_image.append(result)\n",
    "        if(result[:,1].mean() > best_image):\n",
    "            best_image = result[:,1].mean()\n",
    "            best_image_idx = len(result_image)-1\n",
    "            best_image_comb = band_names[ list(comb) ]\n",
    "\n",
    "print(f\"Best Score is {best_image} at index {best_image_idx} with combination {best_image_comb}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_212118/1983967163.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== Number 1 ====================\n",
      "  ['Delta']\n",
      "h | Accuracy: 0.56 Scores: 0.56 (+/- 0.06)\n",
      "e | Accuracy: 0.62 Scores: 0.62 (+/- 0.01)\n",
      "x | Accuracy: 0.62 Scores: 0.62 (+/- 0.06)\n",
      "a | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.05)\n",
      "o | Accuracy: 0.63 Scores: 0.63 (+/- 0.05)\n",
      " Averag accuracy: 0.6077777777777778 Average Score: 0.6058888888888888 Average Variance: 0.023207394280043692\n",
      "  ['Theta']\n",
      "h | Accuracy: 0.64 Scores: 0.64 (+/- 0.06)\n",
      "e | Accuracy: 0.66 Scores: 0.67 (+/- 0.04)\n",
      "x | Accuracy: 0.65 Scores: 0.64 (+/- 0.05)\n",
      "a | Accuracy: 0.60 Scores: 0.59 (+/- 0.09)\n",
      "c | Accuracy: 0.64 Scores: 0.63 (+/- 0.01)\n",
      "o | Accuracy: 0.62 Scores: 0.62 (+/- 0.05)\n",
      " Averag accuracy: 0.634888888888889 Average Score: 0.6298888888888888 Average Variance: 0.024515535527567255\n",
      "  ['Alpha']\n",
      "h | Accuracy: 0.64 Scores: 0.64 (+/- 0.04)\n",
      "e | Accuracy: 0.65 Scores: 0.65 (+/- 0.05)\n",
      "x | Accuracy: 0.67 Scores: 0.66 (+/- 0.05)\n",
      "a | Accuracy: 0.66 Scores: 0.65 (+/- 0.04)\n",
      "c | Accuracy: 0.69 Scores: 0.69 (+/- 0.02)\n",
      "o | Accuracy: 0.63 Scores: 0.62 (+/- 0.07)\n",
      " Averag accuracy: 0.6572222222222223 Average Score: 0.6528888888888889 Average Variance: 0.022304849917518604\n",
      "  ['Beta']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.04)\n",
      "e | Accuracy: 0.72 Scores: 0.72 (+/- 0.03)\n",
      "x | Accuracy: 0.72 Scores: 0.72 (+/- 0.04)\n",
      "a | Accuracy: 0.69 Scores: 0.69 (+/- 0.03)\n",
      "c | Accuracy: 0.66 Scores: 0.66 (+/- 0.04)\n",
      "o | Accuracy: 0.62 Scores: 0.61 (+/- 0.08)\n",
      " Averag accuracy: 0.6822222222222223 Average Score: 0.6783333333333332 Average Variance: 0.022290136886959397\n",
      "  ['Gamma']\n",
      "h | Accuracy: 0.67 Scores: 0.67 (+/- 0.08)\n",
      "e | Accuracy: 0.60 Scores: 0.60 (+/- 0.03)\n",
      "x | Accuracy: 0.66 Scores: 0.66 (+/- 0.06)\n",
      "a | Accuracy: 0.74 Scores: 0.72 (+/- 0.08)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.03)\n",
      "o | Accuracy: 0.57 Scores: 0.56 (+/- 0.13)\n",
      " Averag accuracy: 0.6444444444444445 Average Score: 0.6413333333333333 Average Variance: 0.035099041168135836\n",
      "==================== Number 2 ====================\n",
      "  ['Delta' 'Theta']\n",
      "h | Accuracy: 0.61 Scores: 0.60 (+/- 0.05)\n",
      "e | Accuracy: 0.66 Scores: 0.66 (+/- 0.02)\n",
      "x | Accuracy: 0.64 Scores: 0.63 (+/- 0.05)\n",
      "a | Accuracy: 0.60 Scores: 0.60 (+/- 0.07)\n",
      "c | Accuracy: 0.64 Scores: 0.64 (+/- 0.05)\n",
      "o | Accuracy: 0.65 Scores: 0.66 (+/- 0.03)\n",
      " Averag accuracy: 0.6352222222222221 Average Score: 0.6301111111111112 Average Variance: 0.021974504370496573\n",
      "  ['Delta' 'Alpha']\n",
      "h | Accuracy: 0.62 Scores: 0.60 (+/- 0.03)\n",
      "e | Accuracy: 0.65 Scores: 0.65 (+/- 0.06)\n",
      "x | Accuracy: 0.65 Scores: 0.65 (+/- 0.05)\n",
      "a | Accuracy: 0.67 Scores: 0.66 (+/- 0.05)\n",
      "c | Accuracy: 0.68 Scores: 0.68 (+/- 0.03)\n",
      "o | Accuracy: 0.66 Scores: 0.65 (+/- 0.03)\n",
      " Averag accuracy: 0.6539999999999999 Average Score: 0.6468888888888888 Average Variance: 0.02153035071250323\n",
      "  ['Delta' 'Beta']\n",
      "h | Accuracy: 0.67 Scores: 0.67 (+/- 0.03)\n",
      "e | Accuracy: 0.67 Scores: 0.67 (+/- 0.05)\n",
      "x | Accuracy: 0.70 Scores: 0.69 (+/- 0.06)\n",
      "a | Accuracy: 0.69 Scores: 0.68 (+/- 0.02)\n",
      "c | Accuracy: 0.67 Scores: 0.66 (+/- 0.04)\n",
      "o | Accuracy: 0.66 Scores: 0.65 (+/- 0.06)\n",
      " Averag accuracy: 0.6771111111111111 Average Score: 0.6695555555555556 Average Variance: 0.020908365121315168\n",
      "  ['Delta' 'Gamma']\n",
      "h | Accuracy: 0.74 Scores: 0.73 (+/- 0.04)\n",
      "e | Accuracy: 0.63 Scores: 0.63 (+/- 0.04)\n",
      "x | Accuracy: 0.65 Scores: 0.65 (+/- 0.07)\n",
      "a | Accuracy: 0.64 Scores: 0.64 (+/- 0.06)\n",
      "c | Accuracy: 0.66 Scores: 0.66 (+/- 0.04)\n",
      "o | Accuracy: 0.65 Scores: 0.65 (+/- 0.06)\n",
      " Averag accuracy: 0.6624444444444445 Average Score: 0.6593333333333332 Average Variance: 0.026416017270549413\n",
      "  ['Theta' 'Alpha']\n",
      "h | Accuracy: 0.67 Scores: 0.65 (+/- 0.04)\n",
      "e | Accuracy: 0.68 Scores: 0.68 (+/- 0.04)\n",
      "x | Accuracy: 0.67 Scores: 0.67 (+/- 0.06)\n",
      "a | Accuracy: 0.66 Scores: 0.65 (+/- 0.05)\n",
      "c | Accuracy: 0.69 Scores: 0.69 (+/- 0.02)\n",
      "o | Accuracy: 0.65 Scores: 0.65 (+/- 0.06)\n",
      " Averag accuracy: 0.6711111111111111 Average Score: 0.6624444444444444 Average Variance: 0.02194050104321531\n",
      "  ['Theta' 'Beta']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.03)\n",
      "e | Accuracy: 0.69 Scores: 0.69 (+/- 0.03)\n",
      "x | Accuracy: 0.71 Scores: 0.70 (+/- 0.06)\n",
      "a | Accuracy: 0.67 Scores: 0.67 (+/- 0.03)\n",
      "c | Accuracy: 0.69 Scores: 0.68 (+/- 0.03)\n",
      "o | Accuracy: 0.63 Scores: 0.63 (+/- 0.07)\n",
      " Averag accuracy: 0.6786666666666666 Average Score: 0.6756666666666667 Average Variance: 0.020885115811375917\n",
      "  ['Theta' 'Gamma']\n",
      "h | Accuracy: 0.76 Scores: 0.74 (+/- 0.06)\n",
      "e | Accuracy: 0.66 Scores: 0.66 (+/- 0.04)\n",
      "x | Accuracy: 0.66 Scores: 0.66 (+/- 0.07)\n",
      "a | Accuracy: 0.67 Scores: 0.66 (+/- 0.07)\n",
      "c | Accuracy: 0.65 Scores: 0.65 (+/- 0.03)\n",
      "o | Accuracy: 0.62 Scores: 0.62 (+/- 0.10)\n",
      " Averag accuracy: 0.6715555555555556 Average Score: 0.6645555555555555 Average Variance: 0.030689823590487164\n",
      "  ['Alpha' 'Beta']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.02)\n",
      "e | Accuracy: 0.72 Scores: 0.71 (+/- 0.05)\n",
      "x | Accuracy: 0.72 Scores: 0.72 (+/- 0.05)\n",
      "a | Accuracy: 0.71 Scores: 0.70 (+/- 0.06)\n",
      "c | Accuracy: 0.71 Scores: 0.71 (+/- 0.02)\n",
      "o | Accuracy: 0.65 Scores: 0.64 (+/- 0.07)\n",
      " Averag accuracy: 0.6968888888888888 Average Score: 0.6896666666666667 Average Variance: 0.02139832917441539\n",
      "  ['Alpha' 'Gamma']\n",
      "h | Accuracy: 0.75 Scores: 0.73 (+/- 0.05)\n",
      "e | Accuracy: 0.65 Scores: 0.65 (+/- 0.05)\n",
      "x | Accuracy: 0.69 Scores: 0.68 (+/- 0.05)\n",
      "a | Accuracy: 0.72 Scores: 0.71 (+/- 0.06)\n",
      "c | Accuracy: 0.68 Scores: 0.68 (+/- 0.04)\n",
      "o | Accuracy: 0.63 Scores: 0.62 (+/- 0.05)\n",
      " Averag accuracy: 0.6864444444444443 Average Score: 0.6805555555555555 Average Variance: 0.02611646798209986\n",
      "  ['Beta' 'Gamma']\n",
      "h | Accuracy: 0.76 Scores: 0.76 (+/- 0.05)\n",
      "e | Accuracy: 0.66 Scores: 0.67 (+/- 0.04)\n",
      "x | Accuracy: 0.74 Scores: 0.73 (+/- 0.05)\n",
      "a | Accuracy: 0.72 Scores: 0.71 (+/- 0.04)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.04)\n",
      "o | Accuracy: 0.60 Scores: 0.60 (+/- 0.09)\n",
      " Averag accuracy: 0.6866666666666666 Average Score: 0.6812222222222223 Average Variance: 0.025852017639676466\n",
      "==================== Number 3 ====================\n",
      "  ['Delta' 'Theta' 'Alpha']\n",
      "h | Accuracy: 0.63 Scores: 0.62 (+/- 0.02)\n",
      "e | Accuracy: 0.67 Scores: 0.67 (+/- 0.04)\n",
      "x | Accuracy: 0.66 Scores: 0.66 (+/- 0.05)\n",
      "a | Accuracy: 0.65 Scores: 0.64 (+/- 0.07)\n",
      "c | Accuracy: 0.67 Scores: 0.68 (+/- 0.04)\n",
      "o | Accuracy: 0.66 Scores: 0.65 (+/- 0.03)\n",
      " Averag accuracy: 0.6562222222222222 Average Score: 0.6523333333333333 Average Variance: 0.021425850774297216\n",
      "  ['Delta' 'Theta' 'Beta']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.01)\n",
      "e | Accuracy: 0.67 Scores: 0.67 (+/- 0.02)\n",
      "x | Accuracy: 0.70 Scores: 0.69 (+/- 0.07)\n",
      "a | Accuracy: 0.67 Scores: 0.65 (+/- 0.03)\n",
      "c | Accuracy: 0.68 Scores: 0.68 (+/- 0.03)\n",
      "o | Accuracy: 0.65 Scores: 0.65 (+/- 0.06)\n",
      " Averag accuracy: 0.6727777777777778 Average Score: 0.6671111111111111 Average Variance: 0.01869699793035259\n",
      "  ['Delta' 'Theta' 'Gamma']\n",
      "h | Accuracy: 0.73 Scores: 0.72 (+/- 0.04)\n",
      "e | Accuracy: 0.65 Scores: 0.65 (+/- 0.03)\n",
      "x | Accuracy: 0.64 Scores: 0.64 (+/- 0.07)\n",
      "a | Accuracy: 0.63 Scores: 0.61 (+/- 0.05)\n",
      "c | Accuracy: 0.66 Scores: 0.67 (+/- 0.02)\n",
      "o | Accuracy: 0.66 Scores: 0.66 (+/- 0.05)\n",
      " Averag accuracy: 0.6632222222222223 Average Score: 0.6585555555555557 Average Variance: 0.02203967633345273\n",
      "  ['Delta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.03)\n",
      "e | Accuracy: 0.67 Scores: 0.67 (+/- 0.04)\n",
      "x | Accuracy: 0.69 Scores: 0.69 (+/- 0.07)\n",
      "a | Accuracy: 0.70 Scores: 0.69 (+/- 0.04)\n",
      "c | Accuracy: 0.71 Scores: 0.70 (+/- 0.06)\n",
      "o | Accuracy: 0.66 Scores: 0.65 (+/- 0.04)\n",
      " Averag accuracy: 0.6844444444444444 Average Score: 0.6776666666666666 Average Variance: 0.02280907420203768\n",
      "  ['Delta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.73 Scores: 0.72 (+/- 0.04)\n",
      "e | Accuracy: 0.65 Scores: 0.65 (+/- 0.03)\n",
      "x | Accuracy: 0.66 Scores: 0.66 (+/- 0.05)\n",
      "a | Accuracy: 0.70 Scores: 0.68 (+/- 0.05)\n",
      "c | Accuracy: 0.69 Scores: 0.69 (+/- 0.03)\n",
      "o | Accuracy: 0.66 Scores: 0.65 (+/- 0.03)\n",
      " Averag accuracy: 0.6825555555555556 Average Score: 0.6756666666666665 Average Variance: 0.01971140810043035\n",
      "  ['Delta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.76 Scores: 0.74 (+/- 0.02)\n",
      "e | Accuracy: 0.67 Scores: 0.67 (+/- 0.05)\n",
      "x | Accuracy: 0.71 Scores: 0.71 (+/- 0.07)\n",
      "a | Accuracy: 0.70 Scores: 0.70 (+/- 0.06)\n",
      "c | Accuracy: 0.65 Scores: 0.64 (+/- 0.03)\n",
      "o | Accuracy: 0.64 Scores: 0.64 (+/- 0.08)\n",
      " Averag accuracy: 0.6874444444444444 Average Score: 0.6835555555555555 Average Variance: 0.026735470785910407\n",
      "  ['Theta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.69 Scores: 0.67 (+/- 0.03)\n",
      "e | Accuracy: 0.70 Scores: 0.70 (+/- 0.03)\n",
      "x | Accuracy: 0.69 Scores: 0.69 (+/- 0.07)\n",
      "a | Accuracy: 0.69 Scores: 0.68 (+/- 0.04)\n",
      "c | Accuracy: 0.71 Scores: 0.71 (+/- 0.03)\n",
      "o | Accuracy: 0.65 Scores: 0.64 (+/- 0.06)\n",
      " Averag accuracy: 0.6865555555555556 Average Score: 0.6824444444444445 Average Variance: 0.02140969775158977\n",
      "  ['Theta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.75 Scores: 0.73 (+/- 0.01)\n",
      "e | Accuracy: 0.68 Scores: 0.68 (+/- 0.05)\n",
      "x | Accuracy: 0.66 Scores: 0.66 (+/- 0.05)\n",
      "a | Accuracy: 0.69 Scores: 0.69 (+/- 0.06)\n",
      "c | Accuracy: 0.70 Scores: 0.70 (+/- 0.04)\n",
      "o | Accuracy: 0.65 Scores: 0.65 (+/- 0.06)\n",
      " Averag accuracy: 0.691 Average Score: 0.6843333333333333 Average Variance: 0.022354507793671024\n",
      "  ['Theta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.76 Scores: 0.75 (+/- 0.02)\n",
      "e | Accuracy: 0.69 Scores: 0.68 (+/- 0.03)\n",
      "x | Accuracy: 0.72 Scores: 0.72 (+/- 0.06)\n",
      "a | Accuracy: 0.70 Scores: 0.69 (+/- 0.05)\n",
      "c | Accuracy: 0.65 Scores: 0.65 (+/- 0.03)\n",
      "o | Accuracy: 0.62 Scores: 0.61 (+/- 0.10)\n",
      " Averag accuracy: 0.6893333333333334 Average Score: 0.6829999999999999 Average Variance: 0.025080824836563657\n",
      "  ['Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.74 Scores: 0.73 (+/- 0.02)\n",
      "e | Accuracy: 0.69 Scores: 0.69 (+/- 0.04)\n",
      "x | Accuracy: 0.73 Scores: 0.73 (+/- 0.06)\n",
      "a | Accuracy: 0.72 Scores: 0.72 (+/- 0.04)\n",
      "c | Accuracy: 0.68 Scores: 0.68 (+/- 0.04)\n",
      "o | Accuracy: 0.63 Scores: 0.61 (+/- 0.08)\n",
      " Averag accuracy: 0.6996666666666668 Average Score: 0.6925555555555555 Average Variance: 0.02431949641483583\n",
      "==================== Number 4 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.01)\n",
      "e | Accuracy: 0.67 Scores: 0.67 (+/- 0.03)\n",
      "x | Accuracy: 0.69 Scores: 0.69 (+/- 0.07)\n",
      "a | Accuracy: 0.68 Scores: 0.68 (+/- 0.03)\n",
      "c | Accuracy: 0.70 Scores: 0.70 (+/- 0.05)\n",
      "o | Accuracy: 0.66 Scores: 0.65 (+/- 0.05)\n",
      " Averag accuracy: 0.6807777777777778 Average Score: 0.6776666666666666 Average Variance: 0.01990261581430154\n",
      "  ['Delta' 'Theta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.72 Scores: 0.71 (+/- 0.04)\n",
      "e | Accuracy: 0.66 Scores: 0.66 (+/- 0.04)\n",
      "x | Accuracy: 0.66 Scores: 0.66 (+/- 0.05)\n",
      "a | Accuracy: 0.68 Scores: 0.67 (+/- 0.07)\n",
      "c | Accuracy: 0.69 Scores: 0.69 (+/- 0.04)\n",
      "o | Accuracy: 0.66 Scores: 0.65 (+/- 0.04)\n",
      " Averag accuracy: 0.6782222222222223 Average Score: 0.672 Average Variance: 0.022245419304220762\n",
      "  ['Delta' 'Theta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.75 Scores: 0.74 (+/- 0.03)\n",
      "e | Accuracy: 0.67 Scores: 0.67 (+/- 0.03)\n",
      "x | Accuracy: 0.71 Scores: 0.70 (+/- 0.09)\n",
      "a | Accuracy: 0.68 Scores: 0.67 (+/- 0.05)\n",
      "c | Accuracy: 0.66 Scores: 0.66 (+/- 0.04)\n",
      "o | Accuracy: 0.65 Scores: 0.64 (+/- 0.08)\n",
      " Averag accuracy: 0.6848888888888888 Average Score: 0.6798888888888889 Average Variance: 0.02582484886048696\n",
      "  ['Delta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.74 Scores: 0.73 (+/- 0.03)\n",
      "e | Accuracy: 0.68 Scores: 0.68 (+/- 0.04)\n",
      "x | Accuracy: 0.71 Scores: 0.70 (+/- 0.07)\n",
      "a | Accuracy: 0.73 Scores: 0.72 (+/- 0.05)\n",
      "c | Accuracy: 0.68 Scores: 0.68 (+/- 0.04)\n",
      "o | Accuracy: 0.65 Scores: 0.64 (+/- 0.05)\n",
      " Averag accuracy: 0.6992222222222222 Average Score: 0.6908888888888889 Average Variance: 0.022896208690046365\n",
      "  ['Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.74 Scores: 0.73 (+/- 0.02)\n",
      "e | Accuracy: 0.69 Scores: 0.69 (+/- 0.04)\n",
      "x | Accuracy: 0.71 Scores: 0.70 (+/- 0.07)\n",
      "a | Accuracy: 0.71 Scores: 0.70 (+/- 0.04)\n",
      "c | Accuracy: 0.69 Scores: 0.69 (+/- 0.04)\n",
      "o | Accuracy: 0.64 Scores: 0.63 (+/- 0.07)\n",
      " Averag accuracy: 0.6961111111111111 Average Score: 0.69 Average Variance: 0.023692938126876145\n",
      "==================== Number 5 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.73 Scores: 0.73 (+/- 0.03)\n",
      "e | Accuracy: 0.67 Scores: 0.67 (+/- 0.03)\n",
      "x | Accuracy: 0.69 Scores: 0.69 (+/- 0.07)\n",
      "a | Accuracy: 0.71 Scores: 0.70 (+/- 0.05)\n",
      "c | Accuracy: 0.69 Scores: 0.69 (+/- 0.04)\n",
      "o | Accuracy: 0.65 Scores: 0.64 (+/- 0.05)\n",
      " Averag accuracy: 0.6905555555555555 Average Score: 0.6871111111111111 Average Variance: 0.022720510019070956\n",
      "Best Score is 0.6925555555555555 at index 24 with combination ['Alpha' 'Beta' 'Gamma']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "try:\n",
    "    # [33,2,10,12,16]\n",
    "    t_out = 300\n",
    "    pool = Pool()\n",
    "    ids = np.array(list(EEG_audio.keys()))\n",
    "    p1 = pool.apply_async(build_data, [1,EEG_audio,ids[0::6]])\n",
    "    p2 = pool.apply_async(build_data, [2,EEG_audio,ids[1::6]])\n",
    "    p3 = pool.apply_async(build_data, [3,EEG_audio,ids[2::6]])\n",
    "    p4 = pool.apply_async(build_data, [4,EEG_audio,ids[3::6]])\n",
    "    p5 = pool.apply_async(build_data, [5,EEG_audio,ids[4::6]])\n",
    "    p6 = pool.apply_async(build_data, [6,EEG_audio,ids[5::6]])\n",
    "    ans1 = p1.get(timeout=t_out)\n",
    "    ans2 = p2.get(timeout=t_out)\n",
    "    ans3 = p3.get(timeout=t_out)\n",
    "    ans4 = p4.get(timeout=t_out)\n",
    "    ans5 = p5.get(timeout=t_out)\n",
    "    ans6 = p6.get(timeout=t_out)\n",
    "    X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "    Y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "    freq = ans1[2]\n",
    "    print(X.shape, Y.shape)\n",
    "finally:\n",
    "    print(\"========= close ========\")\n",
    "    pool.close() \n",
    "    pool.terminate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p_no=1|index=0|id=10\n",
      "p_no=2|index=0|id=12\n",
      "p_no=3|index=0|id=13\n",
      "p_no=4|index=0|id=14\n",
      "p_no=5|index=0|id=15\n",
      "p_no=6|index=0|id=16\n",
      "p_no=2|index=1|id=18\n",
      "p_no=3|index=1|id=2\n",
      "p_no=1|index=1|id=17\n",
      "p_no=4|index=1|id=20\n",
      "p_no=5|index=1|id=21\n",
      "p_no=6|index=1|id=22\n",
      "p_no=3|index=2|id=26\n",
      "p_no=1|index=2|id=23\n",
      "p_no=2|index=2|id=25\n",
      "p_no=4|index=2|id=27\n",
      "p_no=5|index=2|id=28\n",
      "p_no=6|index=2|id=29\n",
      "p_no=1|index=3|id=3\n",
      "p_no=3|index=3|id=31\n",
      "p_no=2|index=3|id=30\n",
      "p_no=4|index=3|id=32\n",
      "p_no=5|index=3|id=33\n",
      "p_no=6|index=3|id=34\n",
      "p_no=1|index=4|id=35\n",
      "p_no=3|index=4|id=6\n",
      "p_no=2|index=4|id=5\n",
      "p_no=4|index=4|id=7\n",
      "p_no=5|index=4|id=8\n",
      "p_no=6|index=4|id=9\n",
      "1 done| [10 17 23  3 35]\n",
      "3 done| [13  2 26 31  6]\n",
      "4 done| [14 20 27 32  7]\n",
      "2 done| [12 18 25 30  5]\n",
      "5 done| [15 21 28 33  8]\n",
      "6 done| [16 22 29 34  9]\n",
      "(1500, 8, 65) (1500, 6)\n",
      "========= close ========\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "X,Y = shuffle(X,Y)\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "\n",
    "result_audio = []\n",
    "best_audio = 0\n",
    "best_audio_idx = -1\n",
    "best_audio_comb = None\n",
    "for r in [1,2,3,4,5]:\n",
    "    print(\"=\"*20,f\"Number {r}\",\"=\"*20)\n",
    "    for comb in combinations([0,1,2,3,4],r):\n",
    "        print(\" \",band_names[list(comb)])\n",
    "        selected_x = None\n",
    "        # print(bands[ list(comb) ])\n",
    "        for pt in bands[ list(comb) ]:\n",
    "            # print(pt)\n",
    "            if(type(selected_x) == type(None)): selected_x = X[:,:,pt].mean(axis=2)\n",
    "            else:\n",
    "                selected_x = np.concatenate([selected_x, X[:,:,pt].mean(axis=2)], axis=1)\n",
    "        # print(selected_x.shape)\n",
    "        # pts = np.concatenate( bands[ list(comb) ] )\n",
    "        result = np.array(get_accuracy(selected_x,Y))\n",
    "        print(\" Averag accuracy:\", result[:,0].mean(), \"Average Score:\", result[:,1].mean(), \"Average Variance:\", result[:,2].mean())\n",
    "        result_audio.append(result)\n",
    "        if(result[:,1].mean() > best_audio):\n",
    "            best_audio = result[:,1].mean()\n",
    "            best_audio_idx = len(result_audio)-1\n",
    "            best_audio_comb = band_names[ list(comb) ]\n",
    "\n",
    "print(f\"Best Score is {best_audio} at index {best_audio_idx} with combination {best_audio_comb}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_212118/1958830028.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== Number 1 ====================\n",
      "  ['Delta']\n",
      "h | Accuracy: 0.59 Scores: 0.58 (+/- 0.04)\n",
      "e | Accuracy: 0.64 Scores: 0.63 (+/- 0.06)\n",
      "x | Accuracy: 0.56 Scores: 0.55 (+/- 0.04)\n",
      "a | Accuracy: 0.64 Scores: 0.64 (+/- 0.04)\n",
      "c | Accuracy: 0.61 Scores: 0.61 (+/- 0.05)\n",
      "o | Accuracy: 0.64 Scores: 0.64 (+/- 0.06)\n",
      " Averag accuracy: 0.6124444444444445 Average Score: 0.608111111111111 Average Variance: 0.023648813673510946\n",
      "  ['Theta']\n",
      "h | Accuracy: 0.64 Scores: 0.63 (+/- 0.07)\n",
      "e | Accuracy: 0.73 Scores: 0.72 (+/- 0.05)\n",
      "x | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      "a | Accuracy: 0.64 Scores: 0.62 (+/- 0.04)\n",
      "c | Accuracy: 0.58 Scores: 0.58 (+/- 0.04)\n",
      "o | Accuracy: 0.68 Scores: 0.68 (+/- 0.04)\n",
      " Averag accuracy: 0.644 Average Score: 0.6365555555555557 Average Variance: 0.023708840555667115\n",
      "  ['Alpha']\n",
      "h | Accuracy: 0.71 Scores: 0.70 (+/- 0.04)\n",
      "e | Accuracy: 0.70 Scores: 0.71 (+/- 0.02)\n",
      "x | Accuracy: 0.65 Scores: 0.65 (+/- 0.04)\n",
      "a | Accuracy: 0.69 Scores: 0.68 (+/- 0.06)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.02)\n",
      "o | Accuracy: 0.65 Scores: 0.64 (+/- 0.04)\n",
      " Averag accuracy: 0.6706666666666666 Average Score: 0.6669999999999999 Average Variance: 0.018776891158486127\n",
      "  ['Beta']\n",
      "h | Accuracy: 0.70 Scores: 0.69 (+/- 0.03)\n",
      "e | Accuracy: 0.76 Scores: 0.76 (+/- 0.04)\n",
      "x | Accuracy: 0.65 Scores: 0.64 (+/- 0.06)\n",
      "a | Accuracy: 0.66 Scores: 0.66 (+/- 0.07)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.03)\n",
      "o | Accuracy: 0.75 Scores: 0.75 (+/- 0.06)\n",
      " Averag accuracy: 0.6927777777777777 Average Score: 0.6875555555555556 Average Variance: 0.023276770235809794\n",
      "  ['Gamma']\n",
      "h | Accuracy: 0.63 Scores: 0.62 (+/- 0.05)\n",
      "e | Accuracy: 0.71 Scores: 0.72 (+/- 0.04)\n",
      "x | Accuracy: 0.64 Scores: 0.64 (+/- 0.05)\n",
      "a | Accuracy: 0.76 Scores: 0.76 (+/- 0.07)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.03)\n",
      "o | Accuracy: 0.72 Scores: 0.72 (+/- 0.05)\n",
      " Averag accuracy: 0.6822222222222223 Average Score: 0.6809999999999999 Average Variance: 0.024974043761461454\n",
      "==================== Number 2 ====================\n",
      "  ['Delta' 'Theta']\n",
      "h | Accuracy: 0.64 Scores: 0.63 (+/- 0.06)\n",
      "e | Accuracy: 0.71 Scores: 0.71 (+/- 0.07)\n",
      "x | Accuracy: 0.58 Scores: 0.57 (+/- 0.05)\n",
      "a | Accuracy: 0.68 Scores: 0.67 (+/- 0.06)\n",
      "c | Accuracy: 0.60 Scores: 0.59 (+/- 0.03)\n",
      "o | Accuracy: 0.68 Scores: 0.67 (+/- 0.05)\n",
      " Averag accuracy: 0.6481111111111111 Average Score: 0.641 Average Variance: 0.027448445476515346\n",
      "  ['Delta' 'Alpha']\n",
      "h | Accuracy: 0.68 Scores: 0.68 (+/- 0.07)\n",
      "e | Accuracy: 0.73 Scores: 0.73 (+/- 0.04)\n",
      "x | Accuracy: 0.62 Scores: 0.61 (+/- 0.05)\n",
      "a | Accuracy: 0.72 Scores: 0.71 (+/- 0.05)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.05)\n",
      "o | Accuracy: 0.67 Scores: 0.67 (+/- 0.04)\n",
      " Averag accuracy: 0.6762222222222222 Average Score: 0.6696666666666667 Average Variance: 0.02409465975317994\n",
      "  ['Delta' 'Beta']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.06)\n",
      "e | Accuracy: 0.75 Scores: 0.74 (+/- 0.06)\n",
      "x | Accuracy: 0.62 Scores: 0.61 (+/- 0.04)\n",
      "a | Accuracy: 0.71 Scores: 0.70 (+/- 0.05)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.05)\n",
      "o | Accuracy: 0.70 Scores: 0.70 (+/- 0.07)\n",
      " Averag accuracy: 0.6823333333333332 Average Score: 0.6752222222222222 Average Variance: 0.026606750367605306\n",
      "  ['Delta' 'Gamma']\n",
      "h | Accuracy: 0.63 Scores: 0.63 (+/- 0.07)\n",
      "e | Accuracy: 0.70 Scores: 0.69 (+/- 0.02)\n",
      "x | Accuracy: 0.65 Scores: 0.64 (+/- 0.06)\n",
      "a | Accuracy: 0.79 Scores: 0.79 (+/- 0.07)\n",
      "c | Accuracy: 0.65 Scores: 0.65 (+/- 0.04)\n",
      "o | Accuracy: 0.68 Scores: 0.68 (+/- 0.05)\n",
      " Averag accuracy: 0.6838888888888889 Average Score: 0.6782222222222223 Average Variance: 0.026663526370348304\n",
      "  ['Theta' 'Alpha']\n",
      "h | Accuracy: 0.69 Scores: 0.68 (+/- 0.05)\n",
      "e | Accuracy: 0.75 Scores: 0.74 (+/- 0.04)\n",
      "x | Accuracy: 0.62 Scores: 0.62 (+/- 0.03)\n",
      "a | Accuracy: 0.71 Scores: 0.70 (+/- 0.04)\n",
      "c | Accuracy: 0.62 Scores: 0.62 (+/- 0.05)\n",
      "o | Accuracy: 0.70 Scores: 0.69 (+/- 0.02)\n",
      " Averag accuracy: 0.6831111111111111 Average Score: 0.6766666666666666 Average Variance: 0.019205738936152704\n",
      "  ['Theta' 'Beta']\n",
      "h | Accuracy: 0.70 Scores: 0.68 (+/- 0.06)\n",
      "e | Accuracy: 0.78 Scores: 0.78 (+/- 0.05)\n",
      "x | Accuracy: 0.63 Scores: 0.62 (+/- 0.03)\n",
      "a | Accuracy: 0.66 Scores: 0.65 (+/- 0.08)\n",
      "c | Accuracy: 0.62 Scores: 0.61 (+/- 0.06)\n",
      "o | Accuracy: 0.72 Scores: 0.72 (+/- 0.03)\n",
      " Averag accuracy: 0.6826666666666666 Average Score: 0.6756666666666667 Average Variance: 0.02536302371560156\n",
      "  ['Theta' 'Gamma']\n",
      "h | Accuracy: 0.65 Scores: 0.64 (+/- 0.06)\n",
      "e | Accuracy: 0.76 Scores: 0.75 (+/- 0.05)\n",
      "x | Accuracy: 0.67 Scores: 0.66 (+/- 0.06)\n",
      "a | Accuracy: 0.76 Scores: 0.75 (+/- 0.07)\n",
      "c | Accuracy: 0.64 Scores: 0.64 (+/- 0.03)\n",
      "o | Accuracy: 0.72 Scores: 0.72 (+/- 0.04)\n",
      " Averag accuracy: 0.7003333333333334 Average Score: 0.6932222222222223 Average Variance: 0.02635125545147622\n",
      "  ['Alpha' 'Beta']\n",
      "h | Accuracy: 0.71 Scores: 0.70 (+/- 0.03)\n",
      "e | Accuracy: 0.80 Scores: 0.80 (+/- 0.03)\n",
      "x | Accuracy: 0.67 Scores: 0.66 (+/- 0.05)\n",
      "a | Accuracy: 0.70 Scores: 0.70 (+/- 0.07)\n",
      "c | Accuracy: 0.65 Scores: 0.65 (+/- 0.04)\n",
      "o | Accuracy: 0.71 Scores: 0.71 (+/- 0.03)\n",
      " Averag accuracy: 0.708111111111111 Average Score: 0.7036666666666668 Average Variance: 0.02092117550824538\n",
      "  ['Alpha' 'Gamma']\n",
      "h | Accuracy: 0.69 Scores: 0.67 (+/- 0.02)\n",
      "e | Accuracy: 0.77 Scores: 0.77 (+/- 0.02)\n",
      "x | Accuracy: 0.70 Scores: 0.70 (+/- 0.07)\n",
      "a | Accuracy: 0.78 Scores: 0.78 (+/- 0.07)\n",
      "c | Accuracy: 0.65 Scores: 0.65 (+/- 0.03)\n",
      "o | Accuracy: 0.73 Scores: 0.73 (+/- 0.07)\n",
      " Averag accuracy: 0.7214444444444444 Average Score: 0.7162222222222222 Average Variance: 0.023170967855193614\n",
      "  ['Beta' 'Gamma']\n",
      "h | Accuracy: 0.66 Scores: 0.66 (+/- 0.04)\n",
      "e | Accuracy: 0.73 Scores: 0.73 (+/- 0.04)\n",
      "x | Accuracy: 0.65 Scores: 0.65 (+/- 0.07)\n",
      "a | Accuracy: 0.76 Scores: 0.75 (+/- 0.09)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.04)\n",
      "o | Accuracy: 0.74 Scores: 0.73 (+/- 0.07)\n",
      " Averag accuracy: 0.6951111111111111 Average Score: 0.692888888888889 Average Variance: 0.029080011480069622\n",
      "==================== Number 3 ====================\n",
      "  ['Delta' 'Theta' 'Alpha']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.05)\n",
      "e | Accuracy: 0.75 Scores: 0.74 (+/- 0.05)\n",
      "x | Accuracy: 0.60 Scores: 0.60 (+/- 0.05)\n",
      "a | Accuracy: 0.71 Scores: 0.71 (+/- 0.05)\n",
      "c | Accuracy: 0.63 Scores: 0.62 (+/- 0.04)\n",
      "o | Accuracy: 0.69 Scores: 0.69 (+/- 0.04)\n",
      " Averag accuracy: 0.6771111111111111 Average Score: 0.6704444444444445 Average Variance: 0.023183338459253078\n",
      "  ['Delta' 'Theta' 'Beta']\n",
      "h | Accuracy: 0.69 Scores: 0.68 (+/- 0.06)\n",
      "e | Accuracy: 0.77 Scores: 0.76 (+/- 0.04)\n",
      "x | Accuracy: 0.62 Scores: 0.61 (+/- 0.04)\n",
      "a | Accuracy: 0.69 Scores: 0.68 (+/- 0.06)\n",
      "c | Accuracy: 0.63 Scores: 0.63 (+/- 0.06)\n",
      "o | Accuracy: 0.70 Scores: 0.70 (+/- 0.03)\n",
      " Averag accuracy: 0.6828888888888889 Average Score: 0.6757777777777777 Average Variance: 0.024661684865943084\n",
      "  ['Delta' 'Theta' 'Gamma']\n",
      "h | Accuracy: 0.65 Scores: 0.64 (+/- 0.07)\n",
      "e | Accuracy: 0.74 Scores: 0.73 (+/- 0.07)\n",
      "x | Accuracy: 0.64 Scores: 0.63 (+/- 0.03)\n",
      "a | Accuracy: 0.77 Scores: 0.76 (+/- 0.08)\n",
      "c | Accuracy: 0.66 Scores: 0.66 (+/- 0.05)\n",
      "o | Accuracy: 0.70 Scores: 0.70 (+/- 0.03)\n",
      " Averag accuracy: 0.6936666666666667 Average Score: 0.6881111111111111 Average Variance: 0.027747967422461228\n",
      "  ['Delta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.71 Scores: 0.70 (+/- 0.06)\n",
      "e | Accuracy: 0.80 Scores: 0.79 (+/- 0.05)\n",
      "x | Accuracy: 0.66 Scores: 0.65 (+/- 0.03)\n",
      "a | Accuracy: 0.73 Scores: 0.72 (+/- 0.08)\n",
      "c | Accuracy: 0.65 Scores: 0.65 (+/- 0.04)\n",
      "o | Accuracy: 0.70 Scores: 0.69 (+/- 0.04)\n",
      " Averag accuracy: 0.7057777777777777 Average Score: 0.6995555555555555 Average Variance: 0.024159706588012687\n",
      "  ['Delta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.05)\n",
      "e | Accuracy: 0.77 Scores: 0.76 (+/- 0.05)\n",
      "x | Accuracy: 0.69 Scores: 0.68 (+/- 0.02)\n",
      "a | Accuracy: 0.79 Scores: 0.79 (+/- 0.06)\n",
      "c | Accuracy: 0.66 Scores: 0.66 (+/- 0.02)\n",
      "o | Accuracy: 0.70 Scores: 0.70 (+/- 0.05)\n",
      " Averag accuracy: 0.7141111111111113 Average Score: 0.7107777777777778 Average Variance: 0.02112892176212071\n",
      "  ['Delta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.66 Scores: 0.65 (+/- 0.06)\n",
      "e | Accuracy: 0.73 Scores: 0.74 (+/- 0.06)\n",
      "x | Accuracy: 0.65 Scores: 0.65 (+/- 0.05)\n",
      "a | Accuracy: 0.78 Scores: 0.77 (+/- 0.09)\n",
      "c | Accuracy: 0.64 Scores: 0.64 (+/- 0.05)\n",
      "o | Accuracy: 0.71 Scores: 0.71 (+/- 0.07)\n",
      " Averag accuracy: 0.6948888888888889 Average Score: 0.6923333333333334 Average Variance: 0.03256444376236342\n",
      "  ['Theta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.71 Scores: 0.70 (+/- 0.05)\n",
      "e | Accuracy: 0.80 Scores: 0.79 (+/- 0.03)\n",
      "x | Accuracy: 0.66 Scores: 0.66 (+/- 0.04)\n",
      "a | Accuracy: 0.71 Scores: 0.71 (+/- 0.09)\n",
      "c | Accuracy: 0.64 Scores: 0.64 (+/- 0.05)\n",
      "o | Accuracy: 0.71 Scores: 0.71 (+/- 0.04)\n",
      " Averag accuracy: 0.7055555555555554 Average Score: 0.7004444444444444 Average Variance: 0.024931892613852813\n",
      "  ['Theta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.71 Scores: 0.69 (+/- 0.05)\n",
      "e | Accuracy: 0.78 Scores: 0.78 (+/- 0.03)\n",
      "x | Accuracy: 0.69 Scores: 0.68 (+/- 0.05)\n",
      "a | Accuracy: 0.78 Scores: 0.77 (+/- 0.07)\n",
      "c | Accuracy: 0.65 Scores: 0.65 (+/- 0.03)\n",
      "o | Accuracy: 0.72 Scores: 0.72 (+/- 0.06)\n",
      " Averag accuracy: 0.7234444444444444 Average Score: 0.7153333333333333 Average Variance: 0.023229777107126964\n",
      "  ['Theta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.68 Scores: 0.67 (+/- 0.05)\n",
      "e | Accuracy: 0.77 Scores: 0.77 (+/- 0.03)\n",
      "x | Accuracy: 0.68 Scores: 0.67 (+/- 0.05)\n",
      "a | Accuracy: 0.76 Scores: 0.75 (+/- 0.09)\n",
      "c | Accuracy: 0.64 Scores: 0.64 (+/- 0.04)\n",
      "o | Accuracy: 0.74 Scores: 0.74 (+/- 0.06)\n",
      " Averag accuracy: 0.7118888888888889 Average Score: 0.7076666666666666 Average Variance: 0.027133909434140426\n",
      "  ['Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.70 Scores: 0.70 (+/- 0.03)\n",
      "e | Accuracy: 0.79 Scores: 0.78 (+/- 0.03)\n",
      "x | Accuracy: 0.71 Scores: 0.71 (+/- 0.05)\n",
      "a | Accuracy: 0.78 Scores: 0.76 (+/- 0.07)\n",
      "c | Accuracy: 0.64 Scores: 0.63 (+/- 0.05)\n",
      "o | Accuracy: 0.74 Scores: 0.74 (+/- 0.05)\n",
      " Averag accuracy: 0.7244444444444444 Average Score: 0.7207777777777777 Average Variance: 0.022430592765336918\n",
      "==================== Number 4 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta']\n",
      "h | Accuracy: 0.71 Scores: 0.70 (+/- 0.06)\n",
      "e | Accuracy: 0.80 Scores: 0.79 (+/- 0.03)\n",
      "x | Accuracy: 0.64 Scores: 0.63 (+/- 0.04)\n",
      "a | Accuracy: 0.72 Scores: 0.72 (+/- 0.06)\n",
      "c | Accuracy: 0.64 Scores: 0.63 (+/- 0.04)\n",
      "o | Accuracy: 0.70 Scores: 0.70 (+/- 0.03)\n",
      " Averag accuracy: 0.7026666666666667 Average Score: 0.6951111111111109 Average Variance: 0.021644415858148542\n",
      "  ['Delta' 'Theta' 'Alpha' 'Gamma']\n",
      "h | Accuracy: 0.70 Scores: 0.69 (+/- 0.07)\n",
      "e | Accuracy: 0.79 Scores: 0.78 (+/- 0.04)\n",
      "x | Accuracy: 0.66 Scores: 0.66 (+/- 0.03)\n",
      "a | Accuracy: 0.78 Scores: 0.77 (+/- 0.05)\n",
      "c | Accuracy: 0.66 Scores: 0.66 (+/- 0.04)\n",
      "o | Accuracy: 0.70 Scores: 0.70 (+/- 0.04)\n",
      " Averag accuracy: 0.715 Average Score: 0.7097777777777777 Average Variance: 0.022856515253180568\n",
      "  ['Delta' 'Theta' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.67 Scores: 0.66 (+/- 0.08)\n",
      "e | Accuracy: 0.77 Scores: 0.77 (+/- 0.05)\n",
      "x | Accuracy: 0.65 Scores: 0.65 (+/- 0.05)\n",
      "a | Accuracy: 0.76 Scores: 0.75 (+/- 0.08)\n",
      "c | Accuracy: 0.64 Scores: 0.64 (+/- 0.05)\n",
      "o | Accuracy: 0.72 Scores: 0.72 (+/- 0.05)\n",
      " Averag accuracy: 0.7027777777777776 Average Score: 0.698111111111111 Average Variance: 0.02969772395554414\n",
      "  ['Delta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.70 Scores: 0.69 (+/- 0.05)\n",
      "e | Accuracy: 0.79 Scores: 0.79 (+/- 0.05)\n",
      "x | Accuracy: 0.70 Scores: 0.69 (+/- 0.04)\n",
      "a | Accuracy: 0.79 Scores: 0.77 (+/- 0.07)\n",
      "c | Accuracy: 0.64 Scores: 0.64 (+/- 0.05)\n",
      "o | Accuracy: 0.72 Scores: 0.72 (+/- 0.05)\n",
      " Averag accuracy: 0.7237777777777777 Average Score: 0.7177777777777777 Average Variance: 0.02566122523687175\n",
      "  ['Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.72 Scores: 0.71 (+/- 0.03)\n",
      "e | Accuracy: 0.79 Scores: 0.79 (+/- 0.03)\n",
      "x | Accuracy: 0.69 Scores: 0.69 (+/- 0.05)\n",
      "a | Accuracy: 0.77 Scores: 0.76 (+/- 0.07)\n",
      "c | Accuracy: 0.64 Scores: 0.64 (+/- 0.04)\n",
      "o | Accuracy: 0.73 Scores: 0.73 (+/- 0.05)\n",
      " Averag accuracy: 0.7240000000000001 Average Score: 0.7207777777777777 Average Variance: 0.021683888539340418\n",
      "==================== Number 5 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "h | Accuracy: 0.72 Scores: 0.70 (+/- 0.04)\n",
      "e | Accuracy: 0.80 Scores: 0.79 (+/- 0.04)\n",
      "x | Accuracy: 0.68 Scores: 0.67 (+/- 0.02)\n",
      "a | Accuracy: 0.77 Scores: 0.76 (+/- 0.08)\n",
      "c | Accuracy: 0.65 Scores: 0.64 (+/- 0.04)\n",
      "o | Accuracy: 0.72 Scores: 0.72 (+/- 0.05)\n",
      " Averag accuracy: 0.7228888888888889 Average Score: 0.7166666666666667 Average Variance: 0.02215754942252508\n",
      "Best Score is 0.7207777777777777 at index 24 with combination ['Alpha' 'Beta' 'Gamma']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "result_image = np.array(result_image)\n",
    "result_audio = np.array(result_audio)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "traits = [\"h\",\"e\",\"x\",\"a\",\"c\",\"o\"]\n",
    "width =.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.bar(np.arange(6)      ,result_image[best_image_idx,:,0] * 100, yerr=result_image[best_image_idx,:,2] * 100, width=width, label='image', ecolor='black', capsize=10)\n",
    "ax.bar(np.arange(6)+width,result_audio[best_audio_idx,:,0] * 100, yerr=result_image[best_audio_idx,:,2] * 100, width=width, label='audio', ecolor='black', capsize=10)\n",
    "\n",
    "ax.set_xlabel('Traits')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Accuracy of each trait prediction')\n",
    "ax.set_xticks(np.arange(6) + width / 2)\n",
    "ax.set_xticklabels(traits)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAHsCAYAAADLi4v2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3CUlEQVR4nO3deVxWdf7//+cFiKIGigGmWI2VE+nkHpLmgigamGgaluMntT7lTOZaplMp2tjiWFo2Mw3Tpo4f1xRzXyjHJpVbMTrmRDNlLriBYbix4/n94c/rG/bGC4FzXVz6uN9u3OI62/t1zlvo6dv3OcdhWZYlAAAAAGX4eLoAAAAAoCYiKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAaAapSenq7evXurbdu22rp1q1vanDdvnp555hm3tHXJ448/rlWrVrm1zSsZNmyYli9fLkn6+OOPNXLkyEodp6adFwDPIigDqFbDhg1Tx44dVVRU5OlSPOKtt97S0KFDtXv3bsXExHi6HKNf/vKXOnToUJWO8e6772rAgAGSpJUrV+rhhx+ujtKqxQMPPKD333/f5Xamv2D89LwAgKAMoNocOXJEX375pRwOh1JTU93adklJiVvbK8+xY8d0xx13eLqMKvH0tfR0+wBwCUEZQLVJSUlR69atNWDAAKWkpJRZd/z4cY0ePVqdOnVSZGSkZsyY4Vy3bNky9e3bV23bttX999+vf//735J+PvI5efJkzZkzR5KUlpamrl27Kjk5WZ07d9aUKVN0+vRpPfnkk+rUqZM6duyoJ598UidOnHDun5ubqylTpqhLly7q2LGjfvvb30qS4uPj9cknnzi3Ky4uVmRkpL7++mvjeS5btky9evXSPffco1GjRikrK0uSFBMTo8zMTI0aNUpt27Y1jqpnZWXp6aefVqdOnRQdHa0FCxY41+3du1eJiYnq0KGDunTpohkzZpQ5xrfffqsRI0bonnvu0b333qt33nmnTM2TJk1S27ZtFRcXp6+++spY+9ChQyVJ/fv3V9u2bbV+/fpKXctLUx3279+vadOmac+ePWrbtq06dOhgbHfYsGF6/fXXNWjQILVr106/+c1vlJubK+niX7B++ctfavny5erevbseffRRSdKKFSvUt29fdezYUY899piOHj3qPN7nn3+uPn36qH379poxY4Z++pLZy0e4Tddt+/bt+stf/qINGzaobdu2euCBB8qclyRduHBBf/rTn9SjRw9FRUVp0qRJOnv2bJmaV61ape7duysyMlJ//vOfjecOwItZAFBNYmJirL/97W/WV199Zd11113WyZMnLcuyrJKSEqtfv37WzJkzrfPnz1sFBQXWF198YVmWZa1fv97q0qWL9a9//cu6cOGCdfDgQevIkSOWZVlWixYtrIMHDzqP/9xzz1lvvPGGZVmWtWvXLisiIsKaNWuWVVhYaOXn51unTp2yNm7caOXl5Vlnz561nn76aes3v/mNc////d//tcaOHWvl5uZaRUVFVlpammVZlpWcnGyNHTvWud2WLVus+Ph44znu2LHDuueee6x9+/ZZhYWF1owZM6xHHnnEub5Hjx7W559/bty3tLTUGjBggDVv3jyrsLDQOnz4sBUdHW1t377dsizL+uqrr6zdu3dbxcXFVmZmptWnTx/rgw8+sCzLss6ePWt17tzZeu+996yCggLr7Nmz1p49eyzLsqy33nrLatWqlbVt2zarpKTEmj17tjV48OBy++ny61qZa/nrX//aWrZsmWVZlvXRRx9ZQ4YMKbe9S9t36dLF+s9//mOdP3/eGj16tDVx4kTLsiwrMzPTatGihfXss89a58+ft/Lz860tW7ZYMTEx1nfffWcVFxdbf/zjH63ExETLsiwrJyfHatOmjbVhwwarqKjI+uCDD6yIiAhjPa6u26UaTOe1fPlyKyYmxjp8+LB17tw566mnnrKeeeaZMjU///zzVn5+vpWRkWG1bNnS+u677654HQB4F0aUAVSLL7/8UseOHVPfvn3VqlUrNWvWTGvXrpV0caQ0OztbkyZNUt26dVW7dm3nyOOKFSv0+OOP6+6775bD4dAtt9yipk2bVqhNHx8fjRkzRv7+/qpTp44aNmyo2NhYBQQEqH79+vrNb36jL774QpKUnZ2t7du3a/r06QoKClKtWrV0zz33SLo4p/Xvf/+7zp07J+nizWCXRhgvt2bNGj344INq2bKl/P39NWHCBO3Zs0dHjhxxWe9XX32lU6dOafTo0fL391ezZs300EMPaf369ZKkVq1aqU2bNvLz81N4eLgSExOd9W/btk033nijRo4cqdq1a6t+/fpq3bq189jt27dXt27d5Ovrq/79++ubb76p0DWszLWsrP79+6tFixaqW7euxo4dq40bN6q0tNS5/umnn1bdunVVp04dLVmyRE888YRuu+02+fn5adSoUcrIyNDRo0e1fft23XHHHerTp49q1aqlRx99VDfeeKOxTVfX7UrWrFmj4cOHq1mzZqpXr54mTJig9evXl5kaMnr0aNWpU0d33nmn7rzzzqu+7gBqNj9PFwDg2pCSkqLOnTsrODhY0sXpDKtWrdLw4cN1/PhxNWnSRH5+P/+Vc/z4cd18882VarNhw4aqXbu283N+fr5eeeUVffbZZzp9+rQk6fz58yotLdWJEycUFBSkoKCgnx0nLCxM7dq106ZNm9SrVy9t375dzz//vLHN7OxstWzZ0vm5Xr16atCggbKyshQeHn7Feo8ePars7Owy0xNKS0udnw8cOKBXX31V+/btU35+vkpLS51tubpOPw2KderUUWFhoUpKSozX3ORqrqWvr2+Fjnm5m266yfl9kyZNVFxcrB9//NG5rHHjxs7vjx07ppdfflmvvfaac5llWcrKylJ2dnaZbR0OR5lj/1RV/nxlZ2eX+Utb06ZNVVJSopycHOeyn173gIAA5eXlVaotADUTQRlAlRUUFGjDhg26cOGCOnfuLEkqKirSmTNn9M033+imm27S8ePHjcHtpptu0uHDh43HDQgIUH5+vvPzyZMnFRYW5vzscDjKbP/+++/rwIEDWrZsmUJCQpSRkaGEhARZlqXGjRvr9OnTOnPmjAIDA3/W1oABA7R8+XKVlpaqTZs2Zdr5qdDQ0DJzZfPy8pSbm1vu9pefa3h4uDZv3mxcn5SUpLvuukuvv/666tevrw8//FCbNm1y7ntp5NkOV3MtXe1bnuPHj5f5vlatWmrYsKFz+U+Pc9NNN2nUqFHGkf1Dhw6VmS9tWVaZY//Ula6bq7ov7+tjx47Jz89PjRo1KtM+gGsXUy8AVNnWrVvl6+urdevWKSUlRSkpKVq/fr06dOiglJQU3X333QoJCdHrr7+uvLw8FRYWKj09XZI0aNAgvf/++9q3b58sy9KhQ4ec4eTOO+/U2rVrVVpaqu3bt7v8p//z58+rdu3aCgwMVG5urt5++23nutDQUHXt2lXTp0/X6dOnVVxcXOZ4MTEx+vrrr7VgwQIlJCSU20Z8fLxWrlypjIwMFRUV6Y033tDdd9/tcjRZku6++27Vq1dPycnJKigoUGlpqf773/9q7969zvrr1aunevXqaf/+/Vq8eLFz3+7du+vkyZP68MMPVVRUpHPnzulf//qXyzZNbrzxRmVmZl5xmytdy8s1atRIWVlZLh8J+PHHH+u7775Tfn6+3nzzTcXGxpY7Oj1kyBAlJyfr22+/lSSdPXtWGzZskCR169ZN3377rTZv3qySkhItWLBAP/zwg/E4V7pujRo10tGjR3XhwgXjvvHx8Zo/f74yMzN1/vx5zZkzR3379q3wKD0A70dQBlBlq1at0sCBA9WkSROFhIQ4v4YOHao1a9bIsiy98847OnTokHr06KGuXbs6Q0/fvn01atQoTZw4Ue3atdNTTz3l/Kf+559/Xp9++qk6dOigNWvWuHwu8aOPPqrCwkJ16tRJiYmJuu+++8qsnzVrlvz8/NS3b1/de++9mj9/vnNdnTp11Lt3bx05ckS9evUqt417771XY8eO1dNPP60uXbooMzPT+SQOV3x9ffXOO+/om2++Uc+ePdWpUye98MILzrnRzz33nNauXat27drpxRdf1P333+/ct379+nr//ff16aefqnPnzoqNjVVaWlqF2r3c6NGjNXnyZHXo0KHc0VZX1/KnOnXqpNtvv11dunRRZGRkudv1799fkydPVufOnVVUVFTu9BZJ6tWrlx5//HFNmDBB7dq1U3x8vLZv3y5JCg4O1ptvvqnXX39dkZGROnTokNq1a2c8zpWuW58+fSRJkZGRxmcnP/jgg3rggQf061//Wj179pS/v79efPHFcmsGcO1xWKZ/RwOA69Dbb7+tgwcPavbs2Z4u5ZozbNgwPfDAAxo8eLCnSwGACmNEGQB08RnLH330kRITEz1dCgCghiAoA7juLVu2TN27d9d9992njh07erocAEANwdQLAAAAwIARZQAAAMCgRj7j5tJjowAAAAC7tW/f3ri8RgZlqfyCr0cZGRmKiIjwdBmoAPrKe9BX3oO+8g70k/egr8q60gAtUy8AAAAAA4IyAAAAYEBQBgAAAAwIygAAAIABQRkAAAAwICgDAAAABgRlAAAAwICgDAAAABjU2BeOuHLr5HXVeryDr8a53GbIkCFasmRJtbYLAACAmokR5atASAYAALh+eO2Isie0bdtWu3fvVlpamubNm6cbbrhB//3vf9W3b1+1aNFCCxYsUGFhof74xz/q5ptv1ieffKI///nPKi4uVoMGDTR79mzdeOONOnXqlCZOnKjs7Gy1adNGO3bs0EcffaTg4GCtXr1aCxcuVHFxsVq3bq1p06Z5+rQBAACuS4woV9I333yj6dOna8OGDVq9erUOHjyoFStWaNCgQVq4cKEkqX379lq2bJlSUlIUFxend999V5L09ttvq1OnTlq3bp1iY2N17NgxSdL+/fu1YcMGLV68WKtXr5aPj4/WrFnjsXMEAAC4njGiXEm/+tWvFBoaKkm6+eab1blzZ0lSixYtlJaWJkk6ceKExo8fr5MnT6qoqEjh4eGSpPT0dL399tuSpK5duyooKEiStHPnTu3bt0+DBg2SJBUUFKhRo0b65S9/6dZzAwAAAEG50vz9/Z3f+/j4OD/7+PiotLRUkvT73/9ew4cPV8+ePZWWluYMx+WxLEsDBgzQxIkTyyzPyMio5uoBAADgClMvbHT27FmFhYVJklJSUpzL27Vrpw0bNkiS/vGPf+j06dOSpKioKG3atEk5OTmSpNzcXB09etS9RQMAAECSF48oV+Rxbp42evRojR07VkFBQYqMjNSRI0ecyydMmKCPP/5Ybdq0UUhIiOrXr6/g4GCNGzdOI0eO1IULF1SrVi1NnTpVtWvX9vCZAAAAXH+8Nih7wu7duyVJkZGRioyMdC6/dPPe5etiYmIUExPzs+PccMMNeu+99+Tn56fdu3frq6++ck7duP/++3X//feX2Z6pFwAAAO5HUPaAY8eOady4cc5R45deesnTJQEAAOAyBGUPuPXWW8vMWQYAAEDNY+vNfB9++KHi4uIUHx+vCRMmqLCwUJmZmRo8eLB69eqlcePGqaioyM4SgBonKSlJDoej2r6SkpI8fUoAAFyTbAvKWVlZWrBggT766COtXbtWpaWlWrdunWbPnq3hw4dry5YtCgwM1IoVK+wqAaiRkpKSZFnWFb+6deumbt26udzOsiyCMgAANrF1RLm0tFQFBQUqKSlRQUGBQkJCtGvXLsXGxkqSBgwYoNTUVDtLAAAAACrFtjnKYWFhGjlypHr06KHatWurc+fOatmypQIDA+Xnd7HZxo0bKysry64SAAAAgEqzLSifPn1aqampSk1N1Q033KCxY8fqs88+q/D+rh6JFrG0U1VLLNte4q5qPZ7JkCFDtGTJEp06dUp//etf9dxzz1Vov4KCAh4R5yWqq6/y8vIk8WhAO/Fz5T3oK+9AP3kP+qribAvKO3bsUHh4uIKDgyVJvXv31j//+U+dOXNGJSUl8vPz04kTJ5xvrrtcRESEXaV5rD0fHx9nO507d67wfhkZGW6/Hqic6uqrunXrSnL/z8H1hJ8r7+Gqr5KSkjR9+vRqa2/atGnM/a8Efqa8B31VVnp6ernrbJuj3KRJE/3rX/9Sfn6+LMvSzp07dfvttysyMlKbNm2SJK1atUrR0dF2lWCL3/72txo4cKDi4uK0dOlSSVLbtm2d6zdu3KjJkydLkjIzM5WYmKh+/fppzpw5zm2OHDmi+Ph4SVJhYaGmTJmifv36KSEhQbt22T+yDQDXEm6QBWAX20aUW7durdjYWA0YMEB+fn6KiIhQYmKiunfvrvHjx2vu3LmKiIjQ4MGD7SrBFi+//LIaNGiggoICDRo0SL179y5325kzZ+rhhx9WQkKCFi1aZNzm0vI1a9Zo//79euyxx7Rp0yZeWw0AAOBhtr5wZMyYMRozZkyZZc2aNfPqR8ItXLhQW7ZskSQdP35chw4dKnfb3bt3a968eZKk/v37a/bs2T/bJj09Xb/+9a8lSbfddpuaNGmiAwcO6M4777ShegAAAFQUb+a7CmlpadqxY4eWLl2qgIAADRs2TIWFhWW2ufyzw+FwZ4kAAACoJrY+R/lac/bsWQUFBSkgIED79+/Xnj17JEk33nij9u/frwsXLmjr1q3O7du2bat169ZJkj7++GPjMTt06KA1a9ZIkg4cOKDjx4+refPm9p4IAAAAXPLeEeWk025vsmvXrlqyZIn69u2rX/ziF2rTpo0kaeLEiXryyScVHBysVq1aOR/t9fzzz+uZZ57Ru+++W+5Ni4888oiSkpLUr18/+fr66pVXXpG/v7+7TgnVrNoeW3jw/MX/JgVV/Vge+FkBAOBa4L1B2QP8/f317rvvGtf16dPnZ8uaNWvmfDKGJI0fP16SFB4errVr10qSateurVdeecWGagEAAFAVTL0AAAAADAjKAAAAgAFBGQAAADBgjjIAoEarlptkq/MGWYmbZHHN49XwFxGUAQAAUEZSUpLLYNu9e3dJ0rZt22yvx1OYegEAAAAYEJQBAAAAA4IyAAAAYEBQBgAAAAy4mQ9ws6RtBZr+96IKbeuYfsblNtO6+Supe52qlgUAAC5DUAbcLKl7HYLtZXgMEQCgJiIoA/A4HkMEAKiJmKMMAAAAGBCUAQAAAAOCMgAAAGDAHGUAgFfjSTIA7EJQvkrcnQ8ANQtPkgFgF4LyVeLufAAAgOsDc5QBABWWlJQkh8NRbV/8ixqAmoygDAAGBEKzpKQkWZZ1xa9u3bqpW7duLrezLOuauS4Ark1MvbjMrZPXVfkYJ77PqbZjSdKGR5tXy3EAVBzTrAAAjCgDAAAABgRlAAAAwICgDAAAABgwRxkAAOA6ErG0U/Uc6OD5i/9NCqr6sZJOV/0YNiAoX6XcfyzS6c8XV2jbQ6/Fu9wmqPPDatBlaFXLAgAAQDUjKF+lBl2GEmwBAACuAwRlALaqrsck8thFAIC7cTMfAAAAYMCIMgBAUs0d/T9Yp1oOAwBXjRFlAAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADHjqBa5ZSUlJmj59erUdb9q0aUpKSqq248GzquUVrtX5+lapxr7CFQCuVwRlXLOSkpJcBtvu3btLkrZt22Z7PQAAwLsw9QIAAAAwIChfI5KSkuRwOKrtiykGAADgemfb1Ivvv/9e48ePd37OzMzUmDFjlJCQoPHjx+vo0aNq2rSp5s6dq6Cgaprfdx1jmgEAAED1sm1EuXnz5lq9erVWr16tlStXKiAgQL169VJycrKioqK0efNmRUVFKTk52a4SAAAAgEpzy818O3fuVLNmzdS0aVOlpqZq4cKFkqSEhAQNGzZMzz77rDvKAABUUe4/Fun054srtO2h1+JdbhPU+WE16DK0qmXBgCf/AFXnlqC8bt06xcdf/IWZk5Oj0NBQSVJISIhycnKM+2RkZLijNK9QLY+xkqr9UVYZibuq5TielJeXJ6n6/rxFVMtRqhc/S97DG/qqQZehBFt5R18lJiYqMTHxits8+uijkqT58+dX6JhXOu+CggKvuC7g/1VXw/agXFRUpE8++UQTJ0782bpLN46ZRER4qhu/91C73sdzfVR96tatK+naOJfyeP7cXP9MMUp5kTf0FS7yfF9Vj+r8HZiRkXHNXBe4nyf/7KSnp5e7zvagvH37drVs2VI33nijJKlRo0bKzs5WaGiosrOzFRwcbHcJAGo4RikBADWR7UF53bp1iouLc36Ojo5WSkqKnnjiCaWkpKhnz552lwAAAICrkLStQNP/XlShbR3Tz7jcZlo3fyV1r1PVstzO1qCcl5enHTt2aMaMGc5lTzzxhMaNG6cVK1aoSZMmmjt3rp0l4Bp26+R1VT7Gie9zqu1YknTQ+34HAADwM0nd63hlsK1utgblunXrKi0trcyyhg0bVvimAVQcf/MDAACoXm556gXsx9/8AAAAqhevsAYAAAAMCMoAAACAAVMvAMCAef+oyarrBuTqvKF5w6PNq3wMoKYhKAOAAfP+AQBMvQAAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAbczIdrVu4/Fun054srtO2h1+JdbhPU+WE16DK0qmUBAAAvQVDGNatBl6EEWwAAUGlMvQAAAPCQpKQkORyOavtKSkry9CldUxhRBgAA8JCkpCSX4bZ79+6SpG3bttleD8piRBkAAAAwYEQZAIBrEDc0A1VHUAYA4BrEDc1A1TH1AgAAuAU3rsHbMKIMAADcghvX4G0YUQYAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAoAwAAAAYEJQBAAAAA4IyAAAAYMALRwAAQJVFLO1UPQc6eP7if5OCqud4Saer5zi4LjGiDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFPvQAAALDJrZPXVfkYJ77PqbZjSdLBOtVymOsCI8oAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAm/kAAIBbJG0r0PS/F1VoW8f0My63mdbNX0nduTMN9iEoAwAAt0jqXodgC6/C1AsAAADAgKAMAAAAGBCUAQAAAANbg/KZM2c0ZswY9enTR3379tXu3buVm5urESNGqHfv3hoxYoROnz5tZwkAAABApdgalGfOnKn77rtPGzdu1OrVq3XbbbcpOTlZUVFR2rx5s6KiopScnGxnCQAAAECl2BaUz549qy+++EKDBg2SJPn7+yswMFCpqalKSEiQJCUkJGjr1q12lQAAAABUmm2Phzty5IiCg4M1ZcoUffPNN2rZsqWef/555eTkKDQ0VJIUEhKinJwc4/4ZGRl2lYZqQh95B/rJe9BX3oO+8h70lXeoqf1kW1AuKSnR119/rRdffFGtW7fW73//+59Ns3A4HHI4HMb9IyIi7CrNhe891K738VwfXUJfVQT95D3oK+9BX3kP+so7eLKf0tPTy11n29SLxo0bq3HjxmrdurUkqU+fPvr666/VqFEjZWdnS5Kys7MVHBxsVwkAAABApdkWlENCQtS4cWN9//3Fv0nt3LlTt912m6Kjo5WSkiJJSklJUc+ePe0qAQAAAKg0W19h/eKLL+qZZ55RcXGxmjVrpldeeUUXLlzQuHHjtGLFCjVp0kRz5861swQAAACgUmwNyhEREVq5cuXPls+fP9/OZgEAAIAq4818AAAAgAFBGQAAADCwdeoFAAAAypf7j0U6/fniCm176LV4l9sEdX5YDboMrWpZ+P8RlAEAADykQZehBNsajKkXAAAAgAFBGQAAADAgKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAYAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAoAwAAAAYEJQBAAAAA4IyAAAAYEBQBgAAAAwIygAAAIABQRkAAAAwICgDAAAABgRlAAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFBGQAAADAgKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAYAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAoAwAAAAYEJQBAAAAAz87Dx4dHa169erJx8dHvr6+WrlypXJzczV+/HgdPXpUTZs21dy5cxUUFGRnGQAAAMBVs31Eef78+Vq9erVWrlwpSUpOTlZUVJQ2b96sqKgoJScn210CAAAAcNXcPvUiNTVVCQkJkqSEhARt3brV3SUAAAAALtkelB977DENHDhQS5culSTl5OQoNDRUkhQSEqKcnBy7SwAAAACumq1zlBcvXqywsDDl5ORoxIgRat68eZn1DodDDofDuG9GRoadpaEa0EfegX7yHvSV96CvvAd95R1qaj/ZGpTDwsIkSY0aNVKvXr20d+9eNWrUSNnZ2QoNDVV2draCg4ON+0ZERNhZ2hV876F2vY/n+ugS+qoi6CfvQV95D/rKe9BX3sGT/ZSenl7uOtumXuTl5encuXPO7z///HPdcccdio6OVkpKiiQpJSVFPXv2tKsEAAAAoNJsG1HOycnRU089JUkqLS1VfHy8unbtql/96lcaN26cVqxYoSZNmmju3Ll2lQAAAABUmm1BuVmzZvr4449/trxhw4aaP3++Xc0CAAAA1YI38wEAAAAGBGUAAADAgKAMAAAAGFRojvLp06eVnZ2tOnXqqGnTpvLxIV8DAADg2lZuUD579qwWLVqkdevWqaioSMHBwSosLFROTo5at26tRx55RJ06dXJnrQAAAIDblBuUx4wZo/79+2vRokUKDAwss27fvn1avXq1MjMzNXjwYNuLBAAAANyt3KD8wQcflLtTq1at1KpVK1sKAgAAAGqCCj9H+dSpU5o/f74KCws1ZMgQ3XrrrTaWBQAAAHhWhe/Ke/XVV3XfffcpJiZGEydOtLMmAAAAwOPKDcqPPfaYvvjiC+fn4uJiNW3aVOHh4SoqKnJLcQAAAICnlDv1Yu7cufrTn/6kxYsXa9y4cRo7dqxef/11FRYWatq0ae6sEQAAAHC7coPyDTfcoOeee06ZmZmaM2eOQkNDNXXq1J89AQMAAAC4FpUblA8fPqzFixerVq1azsA8fvx4devWTUOHDpWvr6876wQAAADcqtw5yhMmTFCvXr0UGRmpSZMmqUOHDnrvvfcUGBiokSNHurNGAAAAwO3KHVEuKipSeHi48vLyVFBQ4FyekJCgPn36uKU4AAAAwFPKDcrTpk3TSy+9pFq1amn69Oll1tWpU8f2wgAAAABPKjcot2/fXu3bt3dnLQAAAECNUe4c5VGjRunTTz9VcXHxz9ZlZmbqzTff1IoVK2wtDgAAAPCUckeUX3rpJX3wwQeaOXOmgoKCFBwcrMLCQh09elQ333yzhg4dqpiYGHfWCgAAALhNuUE5JCREkyZN0qRJk3TkyBGdPHlSderU0a233qqAgAB31ggAAAC4XblB+afCw8MVHh5udy0AAABAjVHuHGUAAADgekZQBgAAAAxcBuVPPvlEFy5ccEctAAAAQI3hMiivX79evXv31qxZs7R//3531AQAAAB4nMub+WbPnq1z585p7dq1mjJlihwOhwYOHKi4uDjVr1/fHTUCAAAAblehOcr169dXbGys7r//fp08eVJbtmzRwIEDtXDhQrvrAwAAADzC5YhyamqqVq5cqcOHD6t///5avny5GjVqpPz8fMXFxWnYsGHuqBMAAABwK5dBefPmzRo+fLg6duxYZnlAQIBmzpxpW2EAAACAJ7kMyqNHj1ZoaKjzc0FBgX744QeFh4crKirK1uIAAAAAT3E5R3ns2LFyOBz/bwcfH40dO9bWogAAAABPcxmUS0tL5e/v7/zs7++v4uJiW4sCAAAAPM1lUA4ODlZqaqrz89atW9WwYUNbiwIAAAA8zeUc5enTp+uZZ57RSy+9JMuydNNNN+m1115zR20AAACAx7gMyjfffLOWLVum8+fPS5Lq1atne1EAAACAp7kMypK0bds2ffvttyosLHQuGz16tG1FAQAAAJ7mco7y1KlTtX79ev3tb3+TJG3atEnHjh2zvTAAAADAk1wG5d27d2vWrFkKDAzU6NGjtWTJEh08eNANpQEAAACe4zIo165dW9LFN/FlZWWpVq1aOnnypO2FAQAAAJ7kco5yjx49dObMGT322GMaOHCgHA6HBg8e7I7aAAAAAI+5YlC+cOGCoqKiFBgYqNjYWPXo0UOFhYW64YYb3FUfAAAA4BFXnHrh4+OjGTNmOD/7+/sTkgEAAHBdcDlHOSoqSps2bZJlWe6oBwAAAKgRXM5RXrJkiT744AP5+fnJ399flmXJ4XDon//8Z4UaKC0t1YMPPqiwsDD95S9/UWZmpiZMmKDc3Fy1bNlSs2bNkr+/f5VPBAAAAKhOLoPy7t27q9TAggULdNttt+ncuXOSpNmzZ2v48OGKi4vT1KlTtWLFCj3yyCNVagMAAACobi6nXnzxxRfGr4o4ceKEtm3bpkGDBkmSLMvSrl27FBsbK0kaMGCAUlNTq1A+AAAAYA+XI8rvvfee8/vCwkLt3btXLVu21IIFC1we/OWXX9azzz6r8+fPS5J+/PFHBQYGys/vYrONGzdWVlaWcd+MjIwKnQA8hz7yDvST96CvvAd95T3oK+9QU/vJZVB+5513ynw+fvy4Xn75ZZcH/vTTTxUcHKxWrVopLS3tqguLiIi46n2qx/ceatf7eK6PLqGvKoJ+8h70lfegr7wHfeUdPNlP6enp5a5zGZQv17hxY+3fv9/ldv/85z/1ySefaPv27SosLNS5c+c0c+ZMnTlzRiUlJfLz89OJEycUFhZ2tSUAAAAAtnMZlF966SU5HA5JF19AkpGRobvuusvlgSdOnKiJEydKktLS0vT+++/r9ddf15gxY7Rp0ybFxcVp1apVio6OruIpAAAAANXPZVBu1aqV83tfX1/FxcWpffv2lW7w2Wef1fjx4zV37lxFRETwOmwAAADUSC6DcmxsrGrXri1fX19JF5+LnJ+fr4CAgAo3EhkZqcjISElSs2bNtGLFikqWCwAAALiHy8fDDR8+XAUFBc7PBQUFGjFihK1FAQAAAJ7mMigXFhaqXr16zs/16tVTfn6+rUUBAAAAnuYyKAcEBOjf//638/O+fftUp04dW4sCAAAAPM3lHOXf/e53Gjt2rEJDQ2VZln744QfNmTPHHbUBAAAAHuMyKN99993asGGDDhw4IEn6xS9+oVq1atleGAAAAOBJLqdeLFq0SPn5+WrRooVatGihvLw8LVq0yB21AQAAAB7jMigvW7ZMgYGBzs9BQUFavny5rUUBAAAAnuYyKF+4cEGWZTk/l5aWqri42NaiAAAAAE9zOUe5S5cuGjdunIYMGSJJWrJkie677z7bCwMAAAA8yWVQfvbZZ7V06VItXrxYknTvvffqoYcesr0wAAAAwJNcTr3w8fHRww8/rLfeektvvfWWbr/9dr300kvuqA0AAADwGJcjypL09ddfa+3atdq4caOaNm2q3r17210XAAAA4FHlBuUDBw5o3bp1Wrt2rRo2bKj7779flmVp4cKF7qwPAAAA8Ihyg3Lfvn3VoUMH/eUvf9Ett9wiSfrwww/dVRcAAADgUeXOUX777bcVEhKi//mf/9ELL7ygnTt3lnlMHAAAAHAtK3dEOSYmRjExMcrLy1Nqaqrmz5+vU6dOadq0aerVq5e6dOnizjoBAAAAt3L51Iu6deuqX79+euedd/T3v/9dd911l/7617+6ozYAAADAYyr01ItLgoKClJiYqMTERLvqAQAAAGoElyPKAAAAwPWIoAwAAAAYEJQBAAAAA4IyAAAAYEBQBgAAAAwIygAAAIABQRkAAAAwICgDAAAABgRlAAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFBGQAAADAgKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAYAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAZ+dh24sLBQQ4cOVVFRkUpLSxUbG6sxY8YoMzNTEyZMUG5urlq2bKlZs2bJ39/frjIAAACASrFtRNnf31/z58/Xxx9/rJSUFH322Wfas2ePZs+ereHDh2vLli0KDAzUihUr7CoBAAAAqDTbgrLD4VC9evUkSSUlJSopKZHD4dCuXbsUGxsrSRowYIBSU1PtKgEAAACoNNumXkhSaWmpBg4cqMOHD+uRRx5Rs2bNFBgYKD+/i802btxYWVlZxn0zMjLsLA3VgD7yDvST96CvvAd95T3oK+9QU/vJ1qDs6+ur1atX68yZM3rqqaf0/fffV3jfiIgIGyu7korXeL3zXB9dQl9VBP3kPegr70FfeQ/6yjt4sp/S09PLXeeWp14EBgYqMjJSe/bs0ZkzZ1RSUiJJOnHihMLCwtxRAgAAAHBVbAvKp06d0pkzZyRJBQUF2rFjh2677TZFRkZq06ZNkqRVq1YpOjrarhIAAACASrNt6kV2drYmT56s0tJSWZalPn36qEePHrr99ts1fvx4zZ07VxERERo8eLBdJQAAAACVZltQvvPOO5WSkvKz5c2aNeORcAAAAKjxeDMfAAAAYEBQBgAAAAwIygAAAIABQRkAAAAwICgDAAAABgRlAAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFBGQAAADAgKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAYAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAoAwAAAAYEJQBAAAAA4IyAAAAYEBQBgAAAAwIygAAAIABQRkAAAAwICgDAAAABgRlAAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFBGQAAADAgKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAYAAAAM/Ow68PHjxzVp0iTl5OTI4XDooYce0qOPPqrc3FyNHz9eR48eVdOmTTV37lwFBQXZVQYAAABQKbaNKPv6+mry5Mlav369li5dqv/7v//Td999p+TkZEVFRWnz5s2KiopScnKyXSUAAAAAlWZbUA4NDVXLli0lSfXr11fz5s2VlZWl1NRUJSQkSJISEhK0detWu0oAAAAAKs0tc5SPHDmijIwMtW7dWjk5OQoNDZUkhYSEKCcnxx0lAAAAAFfFtjnKl5w/f15jxozR7373O9WvX7/MOofDIYfDYdwvIyPD7tJQRfSRd6CfvAd95T3oK+9BX3mHmtpPtgbl4uJijRkzRv369VPv3r0lSY0aNVJ2drZCQ0OVnZ2t4OBg474RERF2lnYF33uoXe/juT66hL6qCPrJe9BX3oO+8h70lXfwZD+lp6eXu862qReWZen5559X8+bNNWLECOfy6OhopaSkSJJSUlLUs2dPu0oAAAAAKs22EeX09HStXr1aLVq0UP/+/SVJEyZM0BNPPKFx48ZpxYoVatKkiebOnWtXCQAAAECl2RaUO3TooP/85z/GdfPnz7erWQAAAKBa8GY+AAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFBGQAAADAgKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAYAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAoAwAAAAYEJQBAAAAA4IyAAAAYEBQBgAAAAwIygAAAIABQRkAAAAwICgDAAAABgRlAAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFBGQAAADAgKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAYAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAoAwAAAAYEJQBAAAAA9uC8pQpUxQVFaX4+HjnstzcXI0YMUK9e/fWiBEjdPr0abuaBwAAAKrEtqA8cOBAvfvuu2WWJScnKyoqSps3b1ZUVJSSk5Ptah4AAACoEtuCcseOHRUUFFRmWWpqqhISEiRJCQkJ2rp1q13NAwAAAFXi587GcnJyFBoaKkkKCQlRTk5OudtmZGS4qyxUEn3kHegn70FfeQ/6ynvQV96hpvaTW4PyTzkcDjkcjnLXR0REuLGan/reQ+16H8/10SX0VUXQT96DvvIe9JX3oK+8gyf7KT09vdx1bn3qRaNGjZSdnS1Jys7OVnBwsDubBwAAACrMrUE5OjpaKSkpkqSUlBT17NnTnc0DAAAAFWZbUJ4wYYKGDBmiAwcOqGvXrlq+fLmeeOIJff755+rdu7d27NihJ554wq7mAQAAgCqxbY7yG2+8YVw+f/58u5oEAAAAqg1v5gMAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAoAwAAAAYEJQBAAAAA4IyAAAAYEBQBgAAAAwIygAAAIABQRkAAAAwICgDAAAABgRlAAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFBGQAAADAgKAMAAAAGBGUAAADAgKAMAAAAGBCUAQAAAAOCMgAAAGBAUAYAAAAMCMoAAACAAUEZAAAAMCAoAwAAAAYEZQAAAMCAoAwAAAAYEJQBAAAAA4IyAAAAYEBQBgAAAAwIygAAAIABQRkAAAAwICgDAAAABgRlAAAAwICgDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgIFHgvL27dsVGxurXr16KTk52RMlAAAAAFfk9qBcWlqqGTNm6N1339W6deu0du1afffdd+4uAwAAALgitwflvXv36pZbblGzZs3k7++vuLg4paamursMAAAA4IoclmVZ7mxw48aN+uyzzzRz5kxJUkpKivbu3aupU6c6t0lPT3dnSQAAALiOtW/f3rjcz811VEh5xQIAAADu4vapF2FhYTpx4oTzc1ZWlsLCwtxdBgAAAHBFbg/Kv/rVr3Tw4EFlZmaqqKhI69atU3R0tLvLAAAAAK7I7VMv/Pz8NHXqVD3++OMqLS3Vgw8+qDvuuMPdZQAAAABX5Pab+VBxR44c0ahRo7R27VpPlwIAAHDd4c18AAAAgAFBuYYrLS3VCy+8oLi4OI0cOVIFBQWeLgkGq1ev1qBBg9S/f39NnTpVpaWlni4JBnv37lW/fv1UWFiovLw8xcXF6b///a+ny0I5fvvb32rgwIGKi4vT0qVLPV0OriAlJUX9+vXTAw88oGeffdbT5eAKPvjgA8XHxys+Pl4ffvihp8up8Zh6UYMdOXJEvXv31kcffaSIiAiNHTtW0dHR6t+/v6dLw0/s379ff/jDHzRv3jzVqlVLSUlJatOmjRISEjxdGgzmzJmjoqIiFRQUqHHjxnryySc9XRLKkZubqwYNGqigoECDBg3SwoUL1bBhQ0+Xhct8++23Gj16tBYvXqzg4GBnv6Hm2bdvn6ZMmaKlS5fKsiw99NBD+sMf/qC77rrL06XVWDXyOcr4f8LDwxURESFJatmypY4ePerhinC5nTt3at++fRo0aJAkqaCgQI0aNfJwVSjPU089pUGDBql27dp64YUXPF0OrmDhwoXasmWLJOn48eM6dOgQQbkG2rVrl/r06aPg4GBJIiTXYOnp6YqJiVHdunUlSb169dKXX35JUL4CgnIN5+/v7/ze19dXhYWFHqwGJpZlacCAAZo4caKnS0EF5ObmKi8vTyUlJSosLHT+DwM1S1pamnbs2KGlS5cqICBAw4YN4/cfALdjjjJQRVFRUdq0aZNycnIkXQxijPzXXFOnTtXYsWPVr18/zZ4929PloBxnz55VUFCQAgICtH//fu3Zs8fTJaEcnTp10saNG/Xjjz9Kuvg7EDVThw4dtHXrVuXn5ysvL09bt25Vhw4dPF1WjcaIMlBFt99+u8aNG6eRI0fqwoULqlWrlqZOnaqmTZt6ujRcJiUlRbVq1VK/fv1UWlqqIUOGaOfOnYqKivJ0abhM165dtWTJEvXt21e/+MUv1KZNG0+XhHLccccdGjVqlIYNGyYfHx/dddddevXVVz1dFgxatmypgQMHavDgwZKkQYMGMe3CBW7mAwAAAAyYegEAAAAYEJQBAAAAA4IyAAAAYEBQBgAAAAwIygAAAIABj4cDgBroxx9/1PDhwyVJP/zwg3x8fJxvPlu+fHmZlxFd7quvvtLq1av1wgsvKC0tTbVq1VK7du3cUTYAXFN4PBwA1HDz5s1T3bp19dhjjzmXlZSUyM/P9ViHaV8AQMUQlAGghrsUdr/99lv5+/srIyND7dq1U1xcnGbOnKnCwkLVqVNHL7/8spo3b660tDS9//77evHFF5WYmOgcjX7xxRd18uRJ/fGPf5SPj49uuOEGLVq0yNOnBwA1FlMvAMCLZGVlacmSJfL19dW5c+e0aNEi+fn5aceOHZozZ47mzZvn3DY8PFxDhgwpM6Lcr18/vffeewoLC9OZM2c8dRoA4BUIygDgRfr06SNfX19J0tmzZ/Xcc8/p0KFDcjgcKi4udrl/27ZtNXnyZPXt21e9evWyu1wA8Go89QIAvEhAQIDz+zfffFORkZFau3at/vznP6uoqMjl/jNmzNC4ceN0/PhxPfjgg/rxxx/tLBcAvBojygDgpc6ePauwsDBJ0qpVq4zb1KtXT+fOnXN+Pnz4sFq3bq3WrVtr+/btOnHihBo2bOiWegHA2zCiDABe6vHHH9cbb7yhhIQElZSUGLfp0aOHtmzZov79++vLL7/UrFmz1K9fP8XHx6tt27a688473Vw1AHgPnnoBAAAAGDCiDAAAABgQlAEAAAADgjIAAABgQFAGAAAADAjKAAAAgAFBGQAAADAgKAMAAAAG/x84phYsL2NQ4AAAAABJRU5ErkJggg=="
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(f\"On average, image accuracy is {round(result_image[best_image_idx,:,0].mean(),2)} and audio accuracy is {round(result_audio[best_audio_idx,:,0].mean(),2)}\")\n",
    "print(f\"On average, image    score is {round(result_image[best_image_idx,:,1].mean(),2)} and audio    score is {round(result_audio[best_audio_idx,:,1].mean(),2)}\")\n",
    "print(f\"On average, image      std is {round(result_image[best_image_idx,:,2].mean(),2)} and audio      std is {round(result_audio[best_audio_idx,:,2].mean(),2)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "On average, image accuracy is 0.7 and audio accuracy is 0.72\n",
      "On average, image    score is 0.69 and audio    score is 0.72\n",
      "On average, image      std is 0.02 and audio      std is 0.02\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "for index, trait in enumerate(traits):\n",
    "    print(f\"Image {trait}: Acc: {round(result_image[best_image_idx,index,0],2)} | score: {round(result_image[best_image_idx,index,1],2)} | std: score: {round(result_image[best_image_idx,index,2],2)}\" )\n",
    "    print(f\"Audio {trait}: Acc: {round(result_audio[best_audio_idx,index,0],2)} | score: {round(result_audio[best_audio_idx,index,1],2)} | std: score: {round(result_audio[best_audio_idx,index,2],2)}\" )\n",
    "    print()\n",
    "print(f\"Image: Best Score is {best_image} at index {best_image_idx} with combination {best_image_comb}\")\n",
    "print(f\"Audio: Best Score is {best_audio} at index {best_audio_idx} with combination {best_audio_comb}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Image h: Acc: 0.74 | score: 0.73 | std: score: 0.01\n",
      "Audio h: Acc: 0.7 | score: 0.7 | std: score: 0.01\n",
      "\n",
      "Image e: Acc: 0.69 | score: 0.69 | std: score: 0.02\n",
      "Audio e: Acc: 0.79 | score: 0.78 | std: score: 0.01\n",
      "\n",
      "Image x: Acc: 0.73 | score: 0.73 | std: score: 0.03\n",
      "Audio x: Acc: 0.71 | score: 0.71 | std: score: 0.02\n",
      "\n",
      "Image a: Acc: 0.72 | score: 0.72 | std: score: 0.02\n",
      "Audio a: Acc: 0.78 | score: 0.76 | std: score: 0.03\n",
      "\n",
      "Image c: Acc: 0.68 | score: 0.68 | std: score: 0.02\n",
      "Audio c: Acc: 0.64 | score: 0.63 | std: score: 0.02\n",
      "\n",
      "Image o: Acc: 0.63 | score: 0.61 | std: score: 0.04\n",
      "Audio o: Acc: 0.74 | score: 0.74 | std: score: 0.03\n",
      "\n",
      "Image: Best Score is 0.6925555555555555 at index 24 with combination ['Alpha' 'Beta' 'Gamma']\n",
      "Audio: Best Score is 0.7207777777777777 at index 24 with combination ['Alpha' 'Beta' 'Gamma']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}