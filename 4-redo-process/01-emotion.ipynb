{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('hci': venv)"
  },
  "interpreter": {
   "hash": "815efcf0c7342b169540b615ea1bef3fe0d02f9423b58bdf03d9ef3fd8d24248"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "from scipy import signal\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import Pool\n",
    "plt.style.use('seaborn-whitegrid')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EEG data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def load_data():\n",
    "    path, folders, filenames = next(walk('./data'))\n",
    "\n",
    "    filenames.remove('11-audio.csv')\n",
    "    filenames.remove('11-image.csv')\n",
    "\n",
    "    filenames.remove('36-audio.csv')\n",
    "    filenames.remove('36-image.csv')\n",
    "\n",
    "    path = './data'\n",
    "    columns = {'Unnamed: 1':'Fp1',\n",
    "            'Unnamed: 2':'Fp2',\n",
    "            'Unnamed: 3':'F3',\n",
    "            'Unnamed: 4':'F4',\n",
    "            'Unnamed: 5':'F7',\n",
    "            'Unnamed: 6':'F8',\n",
    "            'Unnamed: 7':'P7',\n",
    "            'Unnamed: 8':'P8'}\n",
    "\n",
    "    EEG_audio, EEG_image = dict(), dict()\n",
    "    from itertools import product\n",
    "    categories = [1,2,3,4,5]\n",
    "    blocks = [1,2]\n",
    "    with tqdm(filenames) as t:\n",
    "        for filename in t:\n",
    "            t.set_description(f\"{filename}\")\n",
    "            participant_id, stimuli = filename.split('-')\n",
    "            stimuli = stimuli.rstrip('.csv')\n",
    "            data = pandas.read_csv(f'{path}/{filename}', dtype={'Marker': str}).rename(columns=columns).drop(columns='timestamps')\n",
    "            # Aviod warning on stim has negative value\n",
    "            marker = np.array(data['Marker'])\n",
    "            marker[marker == '-1'] = '1'\n",
    "            data['Marker'] = marker\n",
    "\n",
    "            if(stimuli == 'audio'):\n",
    "                EEG_audio[int(participant_id)] = data\n",
    "            elif(stimuli == 'image'):\n",
    "                EEG_image[int(participant_id)] = data\n",
    "            else:\n",
    "                raise ValueError(f\"Stimuli:{stimuli} is unexpected.\")\n",
    "    return EEG_audio, EEG_image\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# clear_cache()\n",
    "try:\n",
    "    # Load from cache\n",
    "    EEG_audio = load('EEG_audio')\n",
    "    EEG_image = load('EEG_image')\n",
    "    print('Load data from cache')\n",
    "    if( set(EEG_audio.keys()) != set(EEG_image.keys()) ):\n",
    "        extra = None\n",
    "        if(len(EEG_audio.keys()) > len(EEG_image.keys())):\n",
    "            extra = set(EEG_audio.keys()).difference( set(EEG_image.keys()) )\n",
    "        else:\n",
    "            extra = set(EEG_image.keys()).difference( set(EEG_audio.keys()) )\n",
    "        raise ValueError(f\"In equal keys. audio has {len(EEG_audio.keys())} and image has {len(EEG_image.keys())}. The extra key is {extra}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    EEG_audio, EEG_image = load_data()\n",
    "    # Save to cache\n",
    "    save(EEG_audio, 'EEG_audio')\n",
    "    save(EEG_image, 'EEG_image')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load data from cache\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess data\n",
    "## STFT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# #### Test section ####\n",
    "# raw = dataframe_to_raw(EEG_image[33], sfreq=250)\n",
    "\n",
    "# # Preprocess\n",
    "# raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "# raw.filter(1., None, fir_design='firwin', verbose=False) # Slow drift\n",
    "# events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "# events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "# # Check data\n",
    "# if(events.shape[0] != 50):\n",
    "#     raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "# epochs = mne.Epochs(raw, events, tmin=0.3, tmax=5.8, baseline=(0.3,0.3), verbose=False)\n",
    "# if(epochs.get_data().shape[0] != 50):\n",
    "#     raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "# for evoked in tqdm(epochs.iter_evoked(), leave=False):\n",
    "#     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# sft = abs(mne.time_frequency.stft(evoked.data[:8], wsize=256, verbose=False))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "# sft = sft.mean(axis=2)\n",
    "# sft.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# sft[:,0:4].mean(axis=1).shape\n",
    "# features = []\n",
    "# for f in filter_list:\n",
    "#     features.append(sft[:,f[0]:f[1]+1].mean(axis=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# np.array(features).reshape(-1).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# def build_data(p_num, EEG,ids):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     # Delta, Theta, Alpha, Beta, Gamma\n",
    "#     filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "#     with tqdm(ids) as t:\n",
    "#         for index, id in enumerate(t):\n",
    "#             t.set_description(f\"{id}\")\n",
    "#             print(f\"p_no={p_num}|index={index}|id={id}\")\n",
    "#             raw = dataframe_to_raw(EEG[id], sfreq=250)\n",
    "            \n",
    "#             # Preprocess\n",
    "#             raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "#             raw.filter(1., None, fir_design='firwin', verbose=False) # Slow drift\n",
    "#             events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "#             events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "#             # Check data\n",
    "#             if(events.shape[0] != 50):\n",
    "#                 raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "#             epochs = mne.Epochs(raw, events, tmin=0.3, tmax=5.8, baseline=(0.3,0.3), verbose=False)\n",
    "#             if(epochs.get_data().shape[0] != 50):\n",
    "#                 raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "#             # Extract features\n",
    "#             for evoked in tqdm(epochs.iter_evoked(), leave=False):\n",
    "#                 event = int(evoked.comment[0])\n",
    "#                 sft = abs(mne.time_frequency.stft(evoked.data[:8], wsize=256, verbose=False).mean(axis=2))\n",
    "#                 features = []\n",
    "#                 for f in filter_list:\n",
    "#                     features.append(sft[:,f[0]:f[1]+1].mean(axis=1))\n",
    "#                 X.append(np.array(features).reshape(-1))\n",
    "#                 y.append(event)\n",
    "#     print(f\"{p_num} done| {ids}\")\n",
    "#     return np.array(X),np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# try:\n",
    "#     # [33,2,10,12,16]\n",
    "#     t_out = 100\n",
    "#     pool = Pool()\n",
    "#     ids = np.array(list(EEG_image.keys()))\n",
    "#     p1 = pool.apply_async(build_data, [1,EEG_image,ids[0::6]])\n",
    "#     p2 = pool.apply_async(build_data, [2,EEG_image,ids[1::6]])\n",
    "#     p3 = pool.apply_async(build_data, [3,EEG_image,ids[2::6]])\n",
    "#     p4 = pool.apply_async(build_data, [4,EEG_image,ids[3::6]])\n",
    "#     p5 = pool.apply_async(build_data, [5,EEG_image,ids[4::6]])\n",
    "#     p6 = pool.apply_async(build_data, [6,EEG_image,ids[5::6]])\n",
    "#     ans1 = p1.get(timeout=t_out)\n",
    "#     ans2 = p2.get(timeout=t_out)\n",
    "#     ans3 = p3.get(timeout=t_out)\n",
    "#     ans4 = p4.get(timeout=t_out)\n",
    "#     ans5 = p5.get(timeout=t_out)\n",
    "#     ans6 = p6.get(timeout=t_out)\n",
    "#     X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "#     y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "#     print(X.shape, y.shape)\n",
    "# finally:\n",
    "#     print(\"========= close ========\")\n",
    "#     pool.close() \n",
    "#     pool.terminate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# def get_acc(X,y):\n",
    "#     X_norm = normalize(X, axis=0)\n",
    "#     gnb = GaussianNB()\n",
    "#     gnb.fit(X_norm, y)  \n",
    "#     pred = gnb.predict(X_norm)\n",
    "#     acc = sum(y == pred)/len(y)\n",
    "#     return acc\n",
    "# get_acc(X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PSD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "band_names = np.array(['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma'])\n",
    "filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "def build_data(p_num, EEG,ids):\n",
    "    X = None\n",
    "    y = []\n",
    "    # Delta, Theta, Alpha, Beta, Gamma\n",
    "    filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "    with tqdm(ids) as t:\n",
    "        for index, id in enumerate(t):\n",
    "            t.set_description(f\"{id}\")\n",
    "            print(f\"p_no={p_num}|index={index}|id={id}\")\n",
    "            raw = dataframe_to_raw(EEG[id], sfreq=250)\n",
    "            \n",
    "            # Preprocess\n",
    "            raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "            raw.filter(1., None, fir_design='firwin', verbose=False) # Slow drift\n",
    "            events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "            events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "            # Check data\n",
    "            if(events.shape[0] != 50):\n",
    "                raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "            epochs = mne.Epochs(raw, events, tmin=2, tmax=4, baseline=(2,4), verbose=False)\n",
    "            if(epochs.get_data().shape[0] != 50):\n",
    "                raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "            # Extract features\n",
    "            # powers,freq = mne.time_frequency.psd_welch(epochs,n_fft = 250, verbose=False)\n",
    "            # features = np.mean(powers, axis=1)\n",
    "            # # print(features.shape) #(50,8,65)\n",
    "            # for e in range(features.shape[0]):\n",
    "            #     row = np.expand_dims(features[e].reshape(-1), axis=0)\n",
    "            #     row = 10 * np.log10(row)\n",
    "            #     if(type(X) == type(None)): X = row\n",
    "            #     else: X = np.concatenate( [X, row ], axis=0 )\n",
    "            #     # print(events[e]) [1894    0  521]\n",
    "            #     y.append(int(str(events[e][2])[0]))\n",
    "\n",
    "            import sys\n",
    "            sys.stdout = open(os.devnull, 'w')\n",
    "            events = np.array([int(event / 100) for event in epochs.events[:,2]])\n",
    "            csp = mne.decoding.CSP(n_components=15, transform_into='csp_space', norm_trace=True)\n",
    "            data = csp.fit_transform(epochs.get_data()[:,:8,:], events)\n",
    "            for index_inner, evoked in enumerate(epochs.iter_evoked()):\n",
    "                power,freq = mne.time_frequency.psd_array_welch(data[index_inner],sfreq=250,n_fft=128, verbose=False)\n",
    "                row = power\n",
    "                row = np.expand_dims(row, axis=0)\n",
    "                # row = np.expand_dims(power.reshape(-1), axis=0)\n",
    "                row = 10 * np.log10(row)\n",
    "                if(type(X) == type(None)): X = row\n",
    "                else: X = np.concatenate( [X, row ], axis=0 )\n",
    "                event = int(evoked.comment[0])\n",
    "                y.append(event)\n",
    "                # label = gt.loc[id][['lh','le','lx','la','lc','lo']].to_numpy()\n",
    "                # label = np.expand_dims(label, axis=0)\n",
    "                # if(type(Y) == type(None)): Y = label\n",
    "                # else: Y = np.concatenate( [Y, label ], axis=0 )\n",
    "            sys.stdout = sys.__stdout__\n",
    "\n",
    "\n",
    "    print(f\"{p_num} done| {ids}\")\n",
    "    return np.array(X),np.array(y),freq\n",
    "\n",
    "def get_acc(X,y):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    X_copy = X.copy()\n",
    "    X_copy = normalize(X_copy,axis=0)\n",
    "    mnb = GaussianNB()\n",
    "    mnb.fit(X_copy, y)  \n",
    "    acc = sum(mnb.predict(X_copy) == y) / len(y)\n",
    "    scores = cross_val_score(mnb, X_copy, y)\n",
    "    print(\"| Accuracy: %0.2f Scores: %0.2f (+/- %0.2f)\" % (acc,scores.mean(), scores.std() * 2))\n",
    "    result = (acc,scores.mean(),scores.std() * 2)\n",
    "    return result, mnb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "try:\n",
    "    # [33,2,10,12,16]\n",
    "    t_out = 100\n",
    "    pool = Pool()\n",
    "    ids = np.array(list(EEG_image.keys()))\n",
    "    p1 = pool.apply_async(build_data, [1,EEG_image,ids[0::6]])\n",
    "    p2 = pool.apply_async(build_data, [2,EEG_image,ids[1::6]])\n",
    "    p3 = pool.apply_async(build_data, [3,EEG_image,ids[2::6]])\n",
    "    p4 = pool.apply_async(build_data, [4,EEG_image,ids[3::6]])\n",
    "    p5 = pool.apply_async(build_data, [5,EEG_image,ids[4::6]])\n",
    "    p6 = pool.apply_async(build_data, [6,EEG_image,ids[5::6]])\n",
    "    ans1 = p1.get(timeout=t_out)\n",
    "    ans2 = p2.get(timeout=t_out)\n",
    "    ans3 = p3.get(timeout=t_out)\n",
    "    ans4 = p4.get(timeout=t_out)\n",
    "    ans5 = p5.get(timeout=t_out)\n",
    "    ans6 = p6.get(timeout=t_out)\n",
    "    X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "    y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "    freq = ans1[2]\n",
    "    print(X.shape, y.shape)\n",
    "finally:\n",
    "    print(\"========= close ========\")\n",
    "    pool.close() \n",
    "    pool.terminate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p_no=1|index=0|id=10\n",
      "p_no=2|index=0|id=13\n",
      "p_no=3|index=0|id=25\n",
      "p_no=4|index=0|id=5\n",
      "p_no=5|index=0|id=14\n",
      "p_no=6|index=0|id=22\n",
      "(1500, 8, 65) (1500,)\n",
      "========= close ========\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 3, 1, ..., 1, 5, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "X,y = shuffle(X,y)\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "\n",
    "result_image = []\n",
    "best_image = 0\n",
    "best_image_idx = -1\n",
    "best_image_comb = None\n",
    "bast_image_model = None\n",
    "image_X, image_y = None, None\n",
    "for r in [1,2,3,4,5]:\n",
    "    print(\"=\"*20,f\"Number {r}\",\"=\"*20)\n",
    "    for comb in combinations([0,1,2,3,4],r):\n",
    "        print(\" \",band_names[list(comb)])\n",
    "        selected_x = None\n",
    "        for pt in bands[ list(comb) ]:\n",
    "            if(type(selected_x) == type(None)): selected_x = X[:,:,pt].mean(axis=2)\n",
    "            else: selected_x = np.concatenate([selected_x, X[:,:,pt].mean(axis=2)], axis=1)\n",
    "        result,model = get_acc(selected_x,y)\n",
    "        print(\" Averag accuracy:\", result[0].mean(), \"Average Score:\", result[1].mean(), \"Average Variance:\", result[2].mean())\n",
    "        result_image.append(result)\n",
    "        if(result[1].mean() > best_image):\n",
    "            best_image = result[1].mean()\n",
    "            best_image_idx = len(result_image)-1\n",
    "            best_image_comb = band_names[ list(comb) ]\n",
    "            bast_image_model = model\n",
    "            image_X = selected_x\n",
    "            image_y = y\n",
    "\n",
    "print(f\"Best Score is {best_image} at index {best_image_idx} with combination {best_image_comb}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-35-cb2ec6527af9>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== Number 1 ====================\n",
      "  ['Delta']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.256 Average Score: 0.21466666666666664 Average Variance: 0.03492213560989013\n",
      "  ['Theta']\n",
      "| Accuracy: 0.24 Scores: 0.20 (+/- 0.03)\n",
      " Averag accuracy: 0.23866666666666667 Average Score: 0.20400000000000001 Average Variance: 0.03461534662865912\n",
      "  ['Alpha']\n",
      "| Accuracy: 0.23 Scores: 0.19 (+/- 0.04)\n",
      " Averag accuracy: 0.228 Average Score: 0.19333333333333336 Average Variance: 0.03651483716701108\n",
      "  ['Beta']\n",
      "| Accuracy: 0.23 Scores: 0.18 (+/- 0.05)\n",
      " Averag accuracy: 0.23133333333333334 Average Score: 0.18333333333333332 Average Variance: 0.05383101130183027\n",
      "  ['Gamma']\n",
      "| Accuracy: 0.24 Scores: 0.22 (+/- 0.02)\n",
      " Averag accuracy: 0.23933333333333334 Average Score: 0.21800000000000003 Average Variance: 0.02133333333333333\n",
      "==================== Number 2 ====================\n",
      "  ['Delta' 'Theta']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.05)\n",
      " Averag accuracy: 0.25733333333333336 Average Score: 0.2006666666666667 Average Variance: 0.04509742540076737\n",
      "  ['Delta' 'Alpha']\n",
      "| Accuracy: 0.26 Scores: 0.22 (+/- 0.05)\n",
      " Averag accuracy: 0.25933333333333336 Average Score: 0.21533333333333332 Average Variance: 0.05139822737972368\n",
      "  ['Delta' 'Beta']\n",
      "| Accuracy: 0.25 Scores: 0.19 (+/- 0.03)\n",
      " Averag accuracy: 0.248 Average Score: 0.18533333333333335 Average Variance: 0.026195843605851338\n",
      "  ['Delta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.22 (+/- 0.01)\n",
      " Averag accuracy: 0.25533333333333336 Average Score: 0.2166666666666667 Average Variance: 0.01264911064067351\n",
      "  ['Theta' 'Alpha']\n",
      "| Accuracy: 0.25 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.24933333333333332 Average Score: 0.21000000000000002 Average Variance: 0.041096093353126514\n",
      "  ['Theta' 'Beta']\n",
      "| Accuracy: 0.24 Scores: 0.18 (+/- 0.02)\n",
      " Averag accuracy: 0.24466666666666667 Average Score: 0.17533333333333334 Average Variance: 0.01913693345920976\n",
      "  ['Theta' 'Gamma']\n",
      "| Accuracy: 0.25 Scores: 0.21 (+/- 0.02)\n",
      " Averag accuracy: 0.25066666666666665 Average Score: 0.21066666666666664 Average Variance: 0.016000000000000014\n",
      "  ['Alpha' 'Beta']\n",
      "| Accuracy: 0.25 Scores: 0.19 (+/- 0.05)\n",
      " Averag accuracy: 0.25266666666666665 Average Score: 0.188 Average Variance: 0.0490985403720586\n",
      "  ['Alpha' 'Gamma']\n",
      "| Accuracy: 0.27 Scores: 0.22 (+/- 0.03)\n",
      " Averag accuracy: 0.268 Average Score: 0.21866666666666665 Average Variance: 0.03492213560989011\n",
      "  ['Beta' 'Gamma']\n",
      "| Accuracy: 0.24 Scores: 0.19 (+/- 0.05)\n",
      " Averag accuracy: 0.24466666666666667 Average Score: 0.18733333333333335 Average Variance: 0.045879068090894\n",
      "==================== Number 3 ====================\n",
      "  ['Delta' 'Theta' 'Alpha']\n",
      "| Accuracy: 0.27 Scores: 0.20 (+/- 0.05)\n",
      " Averag accuracy: 0.268 Average Score: 0.19666666666666666 Average Variance: 0.05349974039397034\n",
      "  ['Delta' 'Theta' 'Beta']\n",
      "| Accuracy: 0.25 Scores: 0.19 (+/- 0.03)\n",
      " Averag accuracy: 0.254 Average Score: 0.19066666666666668 Average Variance: 0.032221455929585543\n",
      "  ['Delta' 'Theta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.25733333333333336 Average Score: 0.20999999999999996 Average Variance: 0.04087922591134904\n",
      "  ['Delta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.27 Scores: 0.20 (+/- 0.02)\n",
      " Averag accuracy: 0.2693333333333333 Average Score: 0.2006666666666667 Average Variance: 0.022469732728470294\n",
      "  ['Delta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.22 (+/- 0.05)\n",
      " Averag accuracy: 0.2906666666666667 Average Score: 0.21999999999999997 Average Variance: 0.04935134806219134\n",
      "  ['Delta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.27 Scores: 0.20 (+/- 0.02)\n",
      " Averag accuracy: 0.266 Average Score: 0.2006666666666667 Average Variance: 0.02362672686222581\n",
      "  ['Theta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.25 Scores: 0.19 (+/- 0.02)\n",
      " Averag accuracy: 0.25066666666666665 Average Score: 0.18866666666666668 Average Variance: 0.024073960113690385\n",
      "  ['Theta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.28 Scores: 0.22 (+/- 0.05)\n",
      " Averag accuracy: 0.28 Average Score: 0.21600000000000003 Average Variance: 0.051880203888916586\n",
      "  ['Theta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.03)\n",
      " Averag accuracy: 0.2633333333333333 Average Score: 0.19666666666666668 Average Variance: 0.03126943839882287\n",
      "  ['Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.27 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.272 Average Score: 0.202 Average Variance: 0.03690227334159481\n",
      "==================== Number 4 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.28 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.28 Average Score: 0.19933333333333333 Average Variance: 0.04118252056394801\n",
      "  ['Delta' 'Theta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.286 Average Score: 0.2066666666666667 Average Variance: 0.028905977851571726\n",
      "  ['Delta' 'Theta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.02)\n",
      " Averag accuracy: 0.256 Average Score: 0.2013333333333333 Average Variance: 0.022548712700383697\n",
      "  ['Delta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.286 Average Score: 0.20600000000000002 Average Variance: 0.03383620677453206\n",
      "  ['Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.28 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.2846666666666667 Average Score: 0.20600000000000002 Average Variance: 0.03709447398198282\n",
      "==================== Number 5 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.20 (+/- 0.03)\n",
      " Averag accuracy: 0.286 Average Score: 0.19666666666666668 Average Variance: 0.034253953543107\n",
      "Best Score is 0.21999999999999997 at index 19 with combination ['Delta' 'Alpha' 'Gamma']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "try:\n",
    "    # [33,2,10,12,16]\n",
    "    t_out = 100\n",
    "    pool = Pool()\n",
    "    ids = np.array(list(EEG_image.keys()))\n",
    "    p1 = pool.apply_async(build_data, [1,EEG_audio,ids[0::6]])\n",
    "    p2 = pool.apply_async(build_data, [2,EEG_audio,ids[1::6]])\n",
    "    p3 = pool.apply_async(build_data, [3,EEG_audio,ids[2::6]])\n",
    "    p4 = pool.apply_async(build_data, [4,EEG_audio,ids[3::6]])\n",
    "    p5 = pool.apply_async(build_data, [5,EEG_audio,ids[4::6]])\n",
    "    p6 = pool.apply_async(build_data, [6,EEG_audio,ids[5::6]])\n",
    "    ans1 = p1.get(timeout=t_out)\n",
    "    ans2 = p2.get(timeout=t_out)\n",
    "    ans3 = p3.get(timeout=t_out)\n",
    "    ans4 = p4.get(timeout=t_out)\n",
    "    ans5 = p5.get(timeout=t_out)\n",
    "    ans6 = p6.get(timeout=t_out)\n",
    "    X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "    y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "    print(X.shape, y.shape)\n",
    "finally:\n",
    "    print(\"========= close ========\")\n",
    "    pool.close() \n",
    "    pool.terminate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p_no=1|index=0|id=10\n",
      "p_no=2|index=0|id=13\n",
      "p_no=3|index=0|id=25\n",
      "p_no=4|index=0|id=5\n",
      "p_no=5|index=0|id=14\n",
      "p_no=6|index=0|id=22\n",
      "(1500, 8, 65) (1500,)\n",
      "========= close ========\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "audio_X, audio_y = X, y\n",
    "X,y = shuffle(X,y)\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "\n",
    "result_audio = []\n",
    "best_audio = 0\n",
    "best_audio_idx = -1\n",
    "best_audio_comb = None\n",
    "bast_audio_model = None\n",
    "for r in [1,2,3,4,5]:\n",
    "    print(\"=\"*20,f\"Number {r}\",\"=\"*20)\n",
    "    for comb in combinations([0,1,2,3,4],r):\n",
    "        print(\" \",band_names[list(comb)])\n",
    "        selected_x = None\n",
    "        # print(bands[ list(comb) ])\n",
    "        for pt in bands[ list(comb) ]:\n",
    "            # print(pt)\n",
    "            if(type(selected_x) == type(None)): selected_x = X[:,:,pt].mean(axis=2)\n",
    "            else:\n",
    "                selected_x = np.concatenate([selected_x, X[:,:,pt].mean(axis=2)], axis=1)\n",
    "        # print(selected_x.shape)\n",
    "        # pts = np.concatenate( bands[ list(comb) ] )\n",
    "        result,model = get_acc(selected_x,y)\n",
    "        print(\" Averag accuracy:\", result[0].mean(), \"Average Score:\", result[1].mean(), \"Average Variance:\", result[2].mean())\n",
    "        result_audio.append(result)\n",
    "        if(result[1].mean() > best_audio):\n",
    "            best_audio = result[1].mean()\n",
    "            best_audio_idx = len(result_audio)-1\n",
    "            best_audio_comb = band_names[ list(comb) ]\n",
    "            bast_audio_model = model\n",
    "\n",
    "print(f\"Best Score is {best_audio} at index {best_audio_idx} with combination {best_audio_comb}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== Number 1 ====================\n",
      "  ['Delta']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.06)\n",
      " Averag accuracy: 0.256 Average Score: 0.21066666666666664 Average Variance: 0.058484565865230154\n",
      "  ['Theta']\n",
      "| Accuracy: 0.24 Scores: 0.19 (+/- 0.02)\n",
      " Averag accuracy: 0.23866666666666667 Average Score: 0.19066666666666668 Average Variance: 0.01600000000000001\n",
      "  ['Alpha']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-32-047399ca0f5d>:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| Accuracy: 0.23 Scores: 0.19 (+/- 0.02)\n",
      " Averag accuracy: 0.228 Average Score: 0.194 Average Variance: 0.021249836600678976\n",
      "  ['Beta']\n",
      "| Accuracy: 0.23 Scores: 0.18 (+/- 0.03)\n",
      " Averag accuracy: 0.23133333333333334 Average Score: 0.17866666666666667 Average Variance: 0.03309246305597563\n",
      "  ['Gamma']\n",
      "| Accuracy: 0.24 Scores: 0.22 (+/- 0.06)\n",
      " Averag accuracy: 0.23933333333333334 Average Score: 0.22066666666666665 Average Variance: 0.0627375485654325\n",
      "==================== Number 2 ====================\n",
      "  ['Delta' 'Theta']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.06)\n",
      " Averag accuracy: 0.25733333333333336 Average Score: 0.202 Average Variance: 0.058057442818872644\n",
      "  ['Delta' 'Alpha']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.02)\n",
      " Averag accuracy: 0.25933333333333336 Average Score: 0.20733333333333331 Average Variance: 0.022070593809662465\n",
      "  ['Delta' 'Beta']\n",
      "| Accuracy: 0.25 Scores: 0.21 (+/- 0.06)\n",
      " Averag accuracy: 0.248 Average Score: 0.20933333333333332 Average Variance: 0.05787342510456187\n",
      "  ['Delta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.22 (+/- 0.04)\n",
      " Averag accuracy: 0.25533333333333336 Average Score: 0.21866666666666665 Average Variance: 0.04035398920112416\n",
      "  ['Theta' 'Alpha']\n",
      "| Accuracy: 0.25 Scores: 0.20 (+/- 0.03)\n",
      " Averag accuracy: 0.24933333333333332 Average Score: 0.19733333333333333 Average Variance: 0.031944396135229175\n",
      "  ['Theta' 'Beta']\n",
      "| Accuracy: 0.24 Scores: 0.19 (+/- 0.03)\n",
      " Averag accuracy: 0.24466666666666667 Average Score: 0.186 Average Variance: 0.026799668322989047\n",
      "  ['Theta' 'Gamma']\n",
      "| Accuracy: 0.25 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.25066666666666665 Average Score: 0.21000000000000002 Average Variance: 0.03651483716701109\n",
      "  ['Alpha' 'Beta']\n",
      "| Accuracy: 0.25 Scores: 0.20 (+/- 0.05)\n",
      " Averag accuracy: 0.25266666666666665 Average Score: 0.19866666666666666 Average Variance: 0.047814456205442966\n",
      "  ['Alpha' 'Gamma']\n",
      "| Accuracy: 0.27 Scores: 0.22 (+/- 0.02)\n",
      " Averag accuracy: 0.268 Average Score: 0.21733333333333332 Average Variance: 0.019955506062794354\n",
      "  ['Beta' 'Gamma']\n",
      "| Accuracy: 0.24 Scores: 0.20 (+/- 0.02)\n",
      " Averag accuracy: 0.24466666666666667 Average Score: 0.2006666666666667 Average Variance: 0.02207059380966248\n",
      "==================== Number 3 ====================\n",
      "  ['Delta' 'Theta' 'Alpha']\n",
      "| Accuracy: 0.27 Scores: 0.20 (+/- 0.05)\n",
      " Averag accuracy: 0.268 Average Score: 0.19933333333333333 Average Variance: 0.046837781520667456\n",
      "  ['Delta' 'Theta' 'Beta']\n",
      "| Accuracy: 0.25 Scores: 0.20 (+/- 0.06)\n",
      " Averag accuracy: 0.254 Average Score: 0.2 Average Variance: 0.06338594306135847\n",
      "  ['Delta' 'Theta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.25733333333333336 Average Score: 0.20933333333333332 Average Variance: 0.034615346628659116\n",
      "  ['Delta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.27 Scores: 0.19 (+/- 0.03)\n",
      " Averag accuracy: 0.2693333333333333 Average Score: 0.19466666666666668 Average Variance: 0.025157283018817627\n",
      "  ['Delta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.22 (+/- 0.04)\n",
      " Averag accuracy: 0.2906666666666667 Average Score: 0.22000000000000003 Average Variance: 0.04258325179379017\n",
      "  ['Delta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.27 Scores: 0.20 (+/- 0.02)\n",
      " Averag accuracy: 0.266 Average Score: 0.2026666666666667 Average Variance: 0.021249836600678976\n",
      "  ['Theta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.25 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.25066666666666665 Average Score: 0.20400000000000001 Average Variance: 0.0380409136471656\n",
      "  ['Theta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.28 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.28 Average Score: 0.21333333333333332 Average Variance: 0.025991451586157243\n",
      "  ['Theta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.2633333333333333 Average Score: 0.19733333333333333 Average Variance: 0.04008879034232776\n",
      "  ['Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.27 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.272 Average Score: 0.21000000000000002 Average Variance: 0.0345124776147861\n",
      "==================== Number 4 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.28 Scores: 0.19 (+/- 0.04)\n",
      " Averag accuracy: 0.28 Average Score: 0.1913333333333333 Average Variance: 0.03968766950969924\n",
      "  ['Delta' 'Theta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.286 Average Score: 0.2126666666666667 Average Variance: 0.026465910988372282\n",
      "  ['Delta' 'Theta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.05)\n",
      " Averag accuracy: 0.256 Average Score: 0.20400000000000001 Average Variance: 0.04509742540076737\n",
      "  ['Delta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.286 Average Score: 0.20866666666666664 Average Variance: 0.030579586509812576\n",
      "  ['Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.28 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.2846666666666667 Average Score: 0.21266666666666664 Average Variance: 0.03222145592958552\n",
      "==================== Number 5 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.02)\n",
      " Averag accuracy: 0.286 Average Score: 0.21200000000000002 Average Variance: 0.022150996967781535\n",
      "Best Score is 0.22066666666666665 at index 4 with combination ['Gamma']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "bast_image_model.predict(image_X)\n",
    "al = set()\n",
    "for i in bast_image_model.predict(image_X):\n",
    "    if(i not in al): \n",
    "        al.add(i)\n",
    "        print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}