{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import Pool\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "source": [
    "# EEG data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path, folders, filenames = next(walk('./data'))\n",
    "\n",
    "    filenames.remove('11-audio.csv')\n",
    "    filenames.remove('11-image.csv')\n",
    "\n",
    "    filenames.remove('36-audio.csv')\n",
    "    filenames.remove('36-image.csv')\n",
    "\n",
    "    path = './data'\n",
    "    columns = {'Unnamed: 1':'Fp1',\n",
    "            'Unnamed: 2':'Fp2',\n",
    "            'Unnamed: 3':'F3',\n",
    "            'Unnamed: 4':'F4',\n",
    "            'Unnamed: 5':'F7',\n",
    "            'Unnamed: 6':'F8',\n",
    "            'Unnamed: 7':'P7',\n",
    "            'Unnamed: 8':'P8'}\n",
    "\n",
    "    EEG_audio, EEG_image = dict(), dict()\n",
    "    from itertools import product\n",
    "    categories = [1,2,3,4,5]\n",
    "    blocks = [1,2]\n",
    "    with tqdm(filenames) as t:\n",
    "        for filename in t:\n",
    "            t.set_description(f\"{filename}\")\n",
    "            participant_id, stimuli = filename.split('-')\n",
    "            stimuli = stimuli.rstrip('.csv')\n",
    "            data = pandas.read_csv(f'{path}/{filename}', dtype={'Marker': str}).rename(columns=columns).drop(columns='timestamps')\n",
    "            # Aviod warning on stim has negative value\n",
    "            marker = np.array(data['Marker'])\n",
    "            marker[marker == '-1'] = '1'\n",
    "            data['Marker'] = marker\n",
    "\n",
    "            if(stimuli == 'audio'):\n",
    "                EEG_audio[int(participant_id)] = data\n",
    "            elif(stimuli == 'image'):\n",
    "                EEG_image[int(participant_id)] = data\n",
    "            else:\n",
    "                raise ValueError(f\"Stimuli:{stimuli} is unexpected.\")\n",
    "    return EEG_audio, EEG_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/60 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f396d80e1a04b80ab42e54f6826e3e8"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# clear_cache()\n",
    "try:\n",
    "    # Load from cache\n",
    "    EEG_audio = load('EEG_audio')\n",
    "    EEG_image = load('EEG_image')\n",
    "    print('Load data from cache')\n",
    "    if( set(EEG_audio.keys()) != set(EEG_image.keys()) ):\n",
    "        extra = None\n",
    "        if(len(EEG_audio.keys()) > len(EEG_image.keys())):\n",
    "            extra = set(EEG_audio.keys()).difference( set(EEG_image.keys()) )\n",
    "        else:\n",
    "            extra = set(EEG_image.keys()).difference( set(EEG_audio.keys()) )\n",
    "        raise ValueError(f\"In equal keys. audio has {len(EEG_audio.keys())} and image has {len(EEG_image.keys())}. The extra key is {extra}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    EEG_audio, EEG_image = load_data()\n",
    "    # Save to cache\n",
    "    save(EEG_audio, 'EEG_audio')\n",
    "    save(EEG_image, 'EEG_image')"
   ]
  },
  {
   "source": [
    "# Preprocess data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(p_num, EEG,ids):\n",
    "    X = []\n",
    "    y = []\n",
    "    # Delta, Theta, Alpha, Beta, Gamma\n",
    "    filter_list = [[0,4],[4,8],[8,12],[13,30],[30,125]]\n",
    "    with tqdm(ids) as t:\n",
    "        for id in t:\n",
    "            t.set_description(f\"{id}\")\n",
    "            raw = dataframe_to_raw(EEG[id], sfreq=250)\n",
    "            \n",
    "            # Preprocess\n",
    "            raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "            raw.filter(1., None, fir_design='firwin', verbose=False) # Slow drift\n",
    "            events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "            events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "            # Check data\n",
    "            if(events.shape[0] != 50):\n",
    "                raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "            epochs = mne.Epochs(raw, events, tmin=0.3, tmax=5.8, baseline=(0.3,0.3), verbose=False)\n",
    "            if(epochs.get_data().shape[0] != 50):\n",
    "                raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "            # Extract features\n",
    "            for evoked in tqdm(epochs.iter_evoked(), leave=False):\n",
    "                event = int(evoked.comment[0])\n",
    "                sft = abs(mne.time_frequency.stft(epoch.data[:8], wsize=256, verbose=False).mean(axis=2).mean(axis=0))\n",
    "                features = []\n",
    "                for f in filter_list:\n",
    "                    features.append(sft[f[0]:f[1]+1].mean())\n",
    "                X.append(features)\n",
    "                y.append(event)\n",
    "    print(f\"{p_num} done| {ids}\")\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 done| [10 17 23  3 35]\n",
      "6 done| [16 22 29 34  9]\n",
      "4 done| [14 20 27 32  7]\n",
      "3 done| [13  2 26 31  6]\n",
      "5 done| [15 21 28 33  8]\n",
      "2 done| [12 18 25 30  5]\n"
     ]
    }
   ],
   "source": [
    "# [33,2,10,12,16]\n",
    "pool = Pool()\n",
    "ids = np.array(list(EEG_image.keys()))\n",
    "p1 = pool.apply_async(build_data, [1,EEG_image,ids[0::6]])\n",
    "p2 = pool.apply_async(build_data, [2,EEG_image,ids[1::6]])\n",
    "p3 = pool.apply_async(build_data, [3,EEG_image,ids[2::6]])\n",
    "p4 = pool.apply_async(build_data, [4,EEG_image,ids[3::6]])\n",
    "p5 = pool.apply_async(build_data, [5,EEG_image,ids[4::6]])\n",
    "p6 = pool.apply_async(build_data, [6,EEG_image,ids[5::6]])\n",
    "ans1 = p1.get(timeout=(40))\n",
    "ans2 = p2.get(timeout=(40))\n",
    "ans3 = p3.get(timeout=(40))\n",
    "ans4 = p4.get(timeout=(40))\n",
    "ans5 = p5.get(timeout=(40))\n",
    "ans6 = p6.get(timeout=(40))\n",
    "X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(X,y):\n",
    "    X_norm = normalize(X, axis=0)\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_norm, y)  \n",
    "    pred = gnb.predict(X_norm)\n",
    "    acc = sum(y == pred)/len(y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "# X_norm = normalize(X, axis=0)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X, y)  \n",
    "pred = gnb.predict(X)\n",
    "acc = sum(y == pred)/len(y)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5 5 5 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  }
 ]
}