{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('hci': venv)"
  },
  "interpreter": {
   "hash": "815efcf0c7342b169540b615ea1bef3fe0d02f9423b58bdf03d9ef3fd8d24248"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "from scipy import signal\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import Pool\n",
    "plt.style.use('seaborn-whitegrid')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EEG data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def load_data():\n",
    "    path, folders, filenames = next(walk('./data'))\n",
    "\n",
    "    filenames.remove('11-audio.csv')\n",
    "    filenames.remove('11-image.csv')\n",
    "\n",
    "    filenames.remove('36-audio.csv')\n",
    "    filenames.remove('36-image.csv')\n",
    "\n",
    "    path = './data'\n",
    "    columns = {'Unnamed: 1':'Fp1',\n",
    "            'Unnamed: 2':'Fp2',\n",
    "            'Unnamed: 3':'F3',\n",
    "            'Unnamed: 4':'F4',\n",
    "            'Unnamed: 5':'F7',\n",
    "            'Unnamed: 6':'F8',\n",
    "            'Unnamed: 7':'P7',\n",
    "            'Unnamed: 8':'P8'}\n",
    "\n",
    "    EEG_audio, EEG_image = dict(), dict()\n",
    "    from itertools import product\n",
    "    categories = [1,2,3,4,5]\n",
    "    blocks = [1,2]\n",
    "    with tqdm(filenames) as t:\n",
    "        for filename in t:\n",
    "            t.set_description(f\"{filename}\")\n",
    "            participant_id, stimuli = filename.split('-')\n",
    "            stimuli = stimuli.rstrip('.csv')\n",
    "            data = pandas.read_csv(f'{path}/{filename}', dtype={'Marker': str}).rename(columns=columns).drop(columns='timestamps')\n",
    "            # Aviod warning on stim has negative value\n",
    "            marker = np.array(data['Marker'])\n",
    "            marker[marker == '-1'] = '1'\n",
    "            data['Marker'] = marker\n",
    "\n",
    "            if(stimuli == 'audio'):\n",
    "                EEG_audio[int(participant_id)] = data\n",
    "            elif(stimuli == 'image'):\n",
    "                EEG_image[int(participant_id)] = data\n",
    "            else:\n",
    "                raise ValueError(f\"Stimuli:{stimuli} is unexpected.\")\n",
    "    return EEG_audio, EEG_image\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# clear_cache()\n",
    "try:\n",
    "    # Load from cache\n",
    "    EEG_audio = load('EEG_audio')\n",
    "    EEG_image = load('EEG_image')\n",
    "    print('Load data from cache')\n",
    "    if( set(EEG_audio.keys()) != set(EEG_image.keys()) ):\n",
    "        extra = None\n",
    "        if(len(EEG_audio.keys()) > len(EEG_image.keys())):\n",
    "            extra = set(EEG_audio.keys()).difference( set(EEG_image.keys()) )\n",
    "        else:\n",
    "            extra = set(EEG_image.keys()).difference( set(EEG_audio.keys()) )\n",
    "        raise ValueError(f\"In equal keys. audio has {len(EEG_audio.keys())} and image has {len(EEG_image.keys())}. The extra key is {extra}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    EEG_audio, EEG_image = load_data()\n",
    "    # Save to cache\n",
    "    save(EEG_audio, 'EEG_audio')\n",
    "    save(EEG_image, 'EEG_image')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load data from cache\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess data\n",
    "## STFT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# #### Test section ####\n",
    "# raw = dataframe_to_raw(EEG_image[33], sfreq=250)\n",
    "\n",
    "# # Preprocess\n",
    "# raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "# raw.filter(1., None, fir_design='firwin', verbose=False) # Slow drift\n",
    "# events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "# events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "# # Check data\n",
    "# if(events.shape[0] != 50):\n",
    "#     raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "# epochs = mne.Epochs(raw, events, tmin=0.3, tmax=5.8, baseline=(0.3,0.3), verbose=False)\n",
    "# if(epochs.get_data().shape[0] != 50):\n",
    "#     raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "# for evoked in tqdm(epochs.iter_evoked(), leave=False):\n",
    "#     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# sft = abs(mne.time_frequency.stft(evoked.data[:8], wsize=256, verbose=False))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "# sft = sft.mean(axis=2)\n",
    "# sft.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# sft[:,0:4].mean(axis=1).shape\n",
    "# features = []\n",
    "# for f in filter_list:\n",
    "#     features.append(sft[:,f[0]:f[1]+1].mean(axis=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# np.array(features).reshape(-1).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# def build_data(p_num, EEG,ids):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     # Delta, Theta, Alpha, Beta, Gamma\n",
    "#     filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "#     with tqdm(ids) as t:\n",
    "#         for index, id in enumerate(t):\n",
    "#             t.set_description(f\"{id}\")\n",
    "#             print(f\"p_no={p_num}|index={index}|id={id}\")\n",
    "#             raw = dataframe_to_raw(EEG[id], sfreq=250)\n",
    "            \n",
    "#             # Preprocess\n",
    "#             raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "#             raw.filter(1., None, fir_design='firwin', verbose=False) # Slow drift\n",
    "#             events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "#             events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "#             # Check data\n",
    "#             if(events.shape[0] != 50):\n",
    "#                 raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "#             epochs = mne.Epochs(raw, events, tmin=0.3, tmax=5.8, baseline=(0.3,0.3), verbose=False)\n",
    "#             if(epochs.get_data().shape[0] != 50):\n",
    "#                 raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "#             # Extract features\n",
    "#             for evoked in tqdm(epochs.iter_evoked(), leave=False):\n",
    "#                 event = int(evoked.comment[0])\n",
    "#                 sft = abs(mne.time_frequency.stft(evoked.data[:8], wsize=256, verbose=False).mean(axis=2))\n",
    "#                 features = []\n",
    "#                 for f in filter_list:\n",
    "#                     features.append(sft[:,f[0]:f[1]+1].mean(axis=1))\n",
    "#                 X.append(np.array(features).reshape(-1))\n",
    "#                 y.append(event)\n",
    "#     print(f\"{p_num} done| {ids}\")\n",
    "#     return np.array(X),np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# try:\n",
    "#     # [33,2,10,12,16]\n",
    "#     t_out = 100\n",
    "#     pool = Pool()\n",
    "#     ids = np.array(list(EEG_image.keys()))\n",
    "#     p1 = pool.apply_async(build_data, [1,EEG_image,ids[0::6]])\n",
    "#     p2 = pool.apply_async(build_data, [2,EEG_image,ids[1::6]])\n",
    "#     p3 = pool.apply_async(build_data, [3,EEG_image,ids[2::6]])\n",
    "#     p4 = pool.apply_async(build_data, [4,EEG_image,ids[3::6]])\n",
    "#     p5 = pool.apply_async(build_data, [5,EEG_image,ids[4::6]])\n",
    "#     p6 = pool.apply_async(build_data, [6,EEG_image,ids[5::6]])\n",
    "#     ans1 = p1.get(timeout=t_out)\n",
    "#     ans2 = p2.get(timeout=t_out)\n",
    "#     ans3 = p3.get(timeout=t_out)\n",
    "#     ans4 = p4.get(timeout=t_out)\n",
    "#     ans5 = p5.get(timeout=t_out)\n",
    "#     ans6 = p6.get(timeout=t_out)\n",
    "#     X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "#     y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "#     print(X.shape, y.shape)\n",
    "# finally:\n",
    "#     print(\"========= close ========\")\n",
    "#     pool.close() \n",
    "#     pool.terminate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# def get_acc(X,y):\n",
    "#     X_norm = normalize(X, axis=0)\n",
    "#     gnb = GaussianNB()\n",
    "#     gnb.fit(X_norm, y)  \n",
    "#     pred = gnb.predict(X_norm)\n",
    "#     acc = sum(y == pred)/len(y)\n",
    "#     return acc\n",
    "# get_acc(X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PSD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "band_names = np.array(['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma'])\n",
    "filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "def build_data(p_num, EEG,ids):\n",
    "    X = None\n",
    "    y = []\n",
    "    # Delta, Theta, Alpha, Beta, Gamma\n",
    "    filter_list = [[0,4],[4,8],[8,13],[13,30],[30,125]]\n",
    "    with tqdm(ids) as t:\n",
    "        for index, id in enumerate(t):\n",
    "            t.set_description(f\"{id}\")\n",
    "            print(f\"p_no={p_num}|index={index}|id={id}\")\n",
    "            raw = dataframe_to_raw(EEG[id], sfreq=250)\n",
    "            \n",
    "            # Preprocess\n",
    "            raw.notch_filter([50,100],filter_length='auto', phase='zero', verbose=False) # Line power\n",
    "            raw.filter(1., None, fir_design='firwin', verbose=False) # Slow drift\n",
    "            events = mne.find_events(raw, stim_channel='Marker', initial_event=True, verbose=False, uint_cast=False)\n",
    "            events = np.delete(events,np.argwhere(events[:,2] == 1), axis=0) # break\n",
    "            # Check data\n",
    "            if(events.shape[0] != 50):\n",
    "                raise ValueError(f\"Event missing: {events[:,2]}. len(events.shape[0])={events.shape[0]}\")\n",
    "            epochs = mne.Epochs(raw, events, tmin=2, tmax=4, baseline=(2,4), verbose=False)\n",
    "            if(epochs.get_data().shape[0] != 50):\n",
    "                raise ValueError(f\"There might be a bad data. epochs.get_data().shape = {epochs.get_data().shape}\")\n",
    "\n",
    "            # Extract features\n",
    "            # powers,freq = mne.time_frequency.psd_welch(epochs,n_fft = 250, verbose=False)\n",
    "            # features = np.mean(powers, axis=1)\n",
    "            # # print(features.shape) #(50,8,65)\n",
    "            # for e in range(features.shape[0]):\n",
    "            #     row = np.expand_dims(features[e].reshape(-1), axis=0)\n",
    "            #     row = 10 * np.log10(row)\n",
    "            #     if(type(X) == type(None)): X = row\n",
    "            #     else: X = np.concatenate( [X, row ], axis=0 )\n",
    "            #     # print(events[e]) [1894    0  521]\n",
    "            #     y.append(int(str(events[e][2])[0]))\n",
    "\n",
    "            import sys\n",
    "            sys.stdout = open(os.devnull, 'w')\n",
    "            events = np.array([int(event / 100) for event in epochs.events[:,2]])\n",
    "            csp = mne.decoding.CSP(n_components=15, transform_into='csp_space', norm_trace=True)\n",
    "            data = csp.fit_transform(epochs.get_data()[:,:8,:], events)\n",
    "            for index_inner, evoked in enumerate(epochs.iter_evoked()):\n",
    "                power,freq = mne.time_frequency.psd_array_welch(data[index_inner],sfreq=250,n_fft=128, verbose=False)\n",
    "                row = power\n",
    "                row = np.expand_dims(row, axis=0)\n",
    "                # row = np.expand_dims(power.reshape(-1), axis=0)\n",
    "                row = 10 * np.log10(row)\n",
    "                if(type(X) == type(None)): X = row\n",
    "                else: X = np.concatenate( [X, row ], axis=0 )\n",
    "                event = int(evoked.comment[0])\n",
    "                y.append(event)\n",
    "                # label = gt.loc[id][['lh','le','lx','la','lc','lo']].to_numpy()\n",
    "                # label = np.expand_dims(label, axis=0)\n",
    "                # if(type(Y) == type(None)): Y = label\n",
    "                # else: Y = np.concatenate( [Y, label ], axis=0 )\n",
    "            sys.stdout = sys.__stdout__\n",
    "\n",
    "\n",
    "    print(f\"{p_num} done| {ids}\")\n",
    "    return np.array(X),np.array(y),freq\n",
    "\n",
    "def get_acc(X,y):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    X_copy = X.copy() * -1\n",
    "    X_copy = normalize(X_copy,axis=1)\n",
    "    mnb = GaussianNB()\n",
    "    mnb.fit(X_copy, y)  \n",
    "    acc = sum(mnb.predict(X_copy) == y) / len(y)\n",
    "    scores = cross_val_score(mnb, X_copy, y)\n",
    "    print(\"| Accuracy: %0.2f Scores: %0.2f (+/- %0.2f)\" % (acc,scores.mean(), scores.std() * 2))\n",
    "    result = (acc,scores.mean(),scores.std() * 2)\n",
    "    return result, mnb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "try:\n",
    "    # [33,2,10,12,16]\n",
    "    t_out = 100\n",
    "    pool = Pool()\n",
    "    ids = np.array(list(EEG_image.keys()))\n",
    "    p1 = pool.apply_async(build_data, [1,EEG_image,ids[0::6]])\n",
    "    p2 = pool.apply_async(build_data, [2,EEG_image,ids[1::6]])\n",
    "    p3 = pool.apply_async(build_data, [3,EEG_image,ids[2::6]])\n",
    "    p4 = pool.apply_async(build_data, [4,EEG_image,ids[3::6]])\n",
    "    p5 = pool.apply_async(build_data, [5,EEG_image,ids[4::6]])\n",
    "    p6 = pool.apply_async(build_data, [6,EEG_image,ids[5::6]])\n",
    "    ans1 = p1.get(timeout=t_out)\n",
    "    ans2 = p2.get(timeout=t_out)\n",
    "    ans3 = p3.get(timeout=t_out)\n",
    "    ans4 = p4.get(timeout=t_out)\n",
    "    ans5 = p5.get(timeout=t_out)\n",
    "    ans6 = p6.get(timeout=t_out)\n",
    "    X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "    y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "    freq = ans1[2]\n",
    "    print(X.shape, y.shape)\n",
    "finally:\n",
    "    print(\"========= close ========\")\n",
    "    pool.close() \n",
    "    pool.terminate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p_no=1|index=0|id=10\n",
      "p_no=2|index=0|id=13\n",
      "p_no=3|index=0|id=25\n",
      "p_no=4|index=0|id=5\n",
      "p_no=5|index=0|id=14\n",
      "p_no=6|index=0|id=22\n",
      "(1500, 8, 65) (1500,)\n",
      "========= close ========\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "X,y = shuffle(X,y)\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "\n",
    "result_image = []\n",
    "best_image = 0\n",
    "best_image_idx = -1\n",
    "best_image_comb = None\n",
    "bast_image_model = None\n",
    "for r in [1,2,3,4,5]:\n",
    "    print(\"=\"*20,f\"Number {r}\",\"=\"*20)\n",
    "    for comb in combinations([0,1,2,3,4],r):\n",
    "        print(\" \",band_names[list(comb)])\n",
    "        selected_x = None\n",
    "        # print(bands[ list(comb) ])\n",
    "        for pt in bands[ list(comb) ]:\n",
    "            # print(pt)\n",
    "            if(type(selected_x) == type(None)): selected_x = X[:,:,pt].mean(axis=2)\n",
    "            else:\n",
    "                selected_x = np.concatenate([selected_x, X[:,:,pt].mean(axis=2)], axis=1)\n",
    "        # print(selected_x.shape)\n",
    "        # pts = np.concatenate( bands[ list(comb) ] )\n",
    "        result,model = get_acc(selected_x,y)\n",
    "        print(\" Averag accuracy:\", result[0].mean(), \"Average Score:\", result[1].mean(), \"Average Variance:\", result[2].mean())\n",
    "        result_image.append(result)\n",
    "        if(result[1].mean() > best_image):\n",
    "            best_image = result[1].mean()\n",
    "            best_image_idx = len(result_image)-1\n",
    "            best_image_comb = band_names[ list(comb) ]\n",
    "            bast_image_model = model\n",
    "\n",
    "print(f\"Best Score is {best_image} at index {best_image_idx} with combination {best_image_comb}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-40-821b37f854ad>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== Number 1 ====================\n",
      "  ['Delta']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.25733333333333336 Average Score: 0.20933333333333332 Average Variance: 0.025785439474418297\n",
      "  ['Theta']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.25733333333333336 Average Score: 0.19866666666666666 Average Variance: 0.03878143885933062\n",
      "  ['Alpha']\n",
      "| Accuracy: 0.23 Scores: 0.19 (+/- 0.04)\n",
      " Averag accuracy: 0.23066666666666666 Average Score: 0.1873333333333333 Average Variance: 0.03612324582438416\n",
      "  ['Beta']\n",
      "| Accuracy: 0.24 Scores: 0.21 (+/- 0.05)\n",
      " Averag accuracy: 0.24333333333333335 Average Score: 0.20999999999999996 Average Variance: 0.05215361924162119\n",
      "  ['Gamma']\n",
      "| Accuracy: 0.25 Scores: 0.22 (+/- 0.03)\n",
      " Averag accuracy: 0.24866666666666667 Average Score: 0.21600000000000003 Average Variance: 0.032496153618543834\n",
      "==================== Number 2 ====================\n",
      "  ['Delta' 'Theta']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.02)\n",
      " Averag accuracy: 0.2866666666666667 Average Score: 0.20733333333333331 Average Variance: 0.016546231527987815\n",
      "  ['Delta' 'Alpha']\n",
      "| Accuracy: 0.26 Scores: 0.19 (+/- 0.02)\n",
      " Averag accuracy: 0.2613333333333333 Average Score: 0.1933333333333333 Average Variance: 0.01885618083164127\n",
      "  ['Delta' 'Beta']\n",
      "| Accuracy: 0.27 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.2733333333333333 Average Score: 0.19866666666666669 Average Variance: 0.04186751591495356\n",
      "  ['Delta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.22 (+/- 0.05)\n",
      " Averag accuracy: 0.28933333333333333 Average Score: 0.22199999999999998 Average Variance: 0.04649492206443385\n",
      "  ['Theta' 'Alpha']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.262 Average Score: 0.202 Average Variance: 0.04434210439550904\n",
      "  ['Theta' 'Beta']\n",
      "| Accuracy: 0.27 Scores: 0.19 (+/- 0.03)\n",
      " Averag accuracy: 0.2653333333333333 Average Score: 0.19066666666666665 Average Variance: 0.03461534662865912\n",
      "  ['Theta' 'Gamma']\n",
      "| Accuracy: 0.27 Scores: 0.24 (+/- 0.04)\n",
      " Averag accuracy: 0.274 Average Score: 0.23533333333333334 Average Variance: 0.03923717058549911\n",
      "  ['Alpha' 'Beta']\n",
      "| Accuracy: 0.26 Scores: 0.19 (+/- 0.06)\n",
      " Averag accuracy: 0.25866666666666666 Average Score: 0.19066666666666662 Average Variance: 0.05923962637739484\n",
      "  ['Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.23 (+/- 0.01)\n",
      " Averag accuracy: 0.2946666666666667 Average Score: 0.23466666666666666 Average Variance: 0.01496662954709577\n",
      "  ['Beta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.22 (+/- 0.03)\n",
      " Averag accuracy: 0.26066666666666666 Average Score: 0.22466666666666665 Average Variance: 0.025854292572887103\n",
      "==================== Number 3 ====================\n",
      "  ['Delta' 'Theta' 'Alpha']\n",
      "| Accuracy: 0.29 Scores: 0.20 (+/- 0.03)\n",
      " Averag accuracy: 0.2866666666666667 Average Score: 0.2046666666666667 Average Variance: 0.026532998322843195\n",
      "  ['Delta' 'Theta' 'Beta']\n",
      "| Accuracy: 0.28 Scores: 0.20 (+/- 0.05)\n",
      " Averag accuracy: 0.2833333333333333 Average Score: 0.2 Average Variance: 0.045995168828427566\n",
      "  ['Delta' 'Theta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.22 (+/- 0.03)\n",
      " Averag accuracy: 0.2906666666666667 Average Score: 0.22466666666666665 Average Variance: 0.033359989341858146\n",
      "  ['Delta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.29 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.2886666666666667 Average Score: 0.2013333333333333 Average Variance: 0.04454211490264018\n",
      "  ['Delta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.23 (+/- 0.02)\n",
      " Averag accuracy: 0.29333333333333333 Average Score: 0.22666666666666666 Average Variance: 0.01788854381999831\n",
      "  ['Delta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.23 (+/- 0.04)\n",
      " Averag accuracy: 0.288 Average Score: 0.22533333333333333 Average Variance: 0.0447412312948334\n",
      "  ['Theta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.27 Scores: 0.19 (+/- 0.06)\n",
      " Averag accuracy: 0.26866666666666666 Average Score: 0.19466666666666668 Average Variance: 0.05881798666696741\n",
      "  ['Theta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.23 (+/- 0.04)\n",
      " Averag accuracy: 0.28933333333333333 Average Score: 0.22933333333333333 Average Variance: 0.03733333333333335\n",
      "  ['Theta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.28 Scores: 0.22 (+/- 0.01)\n",
      " Averag accuracy: 0.2826666666666667 Average Score: 0.21866666666666665 Average Variance: 0.009043106644167007\n",
      "  ['Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.28 Scores: 0.23 (+/- 0.05)\n",
      " Averag accuracy: 0.27666666666666667 Average Score: 0.23000000000000004 Average Variance: 0.0469515116310907\n",
      "==================== Number 4 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.30 Scores: 0.20 (+/- 0.06)\n",
      " Averag accuracy: 0.29533333333333334 Average Score: 0.19999999999999998 Average Variance: 0.06463573143221771\n",
      "  ['Delta' 'Theta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.31 Scores: 0.23 (+/- 0.04)\n",
      " Averag accuracy: 0.31066666666666665 Average Score: 0.22933333333333333 Average Variance: 0.04224794538067962\n",
      "  ['Delta' 'Theta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.30 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.3 Average Score: 0.21200000000000002 Average Variance: 0.036417334089993765\n",
      "  ['Delta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.30 Scores: 0.23 (+/- 0.03)\n",
      " Averag accuracy: 0.296 Average Score: 0.23000000000000004 Average Variance: 0.0339934634239519\n",
      "  ['Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.23 (+/- 0.03)\n",
      " Averag accuracy: 0.29 Average Score: 0.22800000000000004 Average Variance: 0.025508168626278648\n",
      "==================== Number 5 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.30 Scores: 0.22 (+/- 0.05)\n",
      " Averag accuracy: 0.30466666666666664 Average Score: 0.22400000000000003 Average Variance: 0.04683778152066746\n",
      "Best Score is 0.23533333333333334 at index 11 with combination ['Theta' 'Gamma']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "try:\n",
    "    # [33,2,10,12,16]\n",
    "    t_out = 100\n",
    "    pool = Pool()\n",
    "    ids = np.array(list(EEG_image.keys()))\n",
    "    p1 = pool.apply_async(build_data, [1,EEG_audio,ids[0::6]])\n",
    "    p2 = pool.apply_async(build_data, [2,EEG_audio,ids[1::6]])\n",
    "    p3 = pool.apply_async(build_data, [3,EEG_audio,ids[2::6]])\n",
    "    p4 = pool.apply_async(build_data, [4,EEG_audio,ids[3::6]])\n",
    "    p5 = pool.apply_async(build_data, [5,EEG_audio,ids[4::6]])\n",
    "    p6 = pool.apply_async(build_data, [6,EEG_audio,ids[5::6]])\n",
    "    ans1 = p1.get(timeout=t_out)\n",
    "    ans2 = p2.get(timeout=t_out)\n",
    "    ans3 = p3.get(timeout=t_out)\n",
    "    ans4 = p4.get(timeout=t_out)\n",
    "    ans5 = p5.get(timeout=t_out)\n",
    "    ans6 = p6.get(timeout=t_out)\n",
    "    X = np.concatenate([ans1[0] , ans2[0], ans3[0], ans4[0] ,ans5[0], ans6[0]])\n",
    "    y = np.concatenate([ans1[1] , ans2[1], ans3[1], ans4[1] ,ans5[1], ans6[1]])\n",
    "    print(X.shape, y.shape)\n",
    "finally:\n",
    "    print(\"========= close ========\")\n",
    "    pool.close() \n",
    "    pool.terminate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p_no=1|index=0|id=10\n",
      "p_no=2|index=0|id=13\n",
      "p_no=3|index=0|id=25\n",
      "p_no=4|index=0|id=5\n",
      "p_no=5|index=0|id=14\n",
      "p_no=6|index=0|id=22\n",
      "(1500, 8, 65) (1500,)\n",
      "========= close ========\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "X,y = shuffle(X,y)\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "\n",
    "result_audio = []\n",
    "best_audio = 0\n",
    "best_audio_idx = -1\n",
    "best_audio_comb = None\n",
    "bast_audio_model = None\n",
    "for r in [1,2,3,4,5]:\n",
    "    print(\"=\"*20,f\"Number {r}\",\"=\"*20)\n",
    "    for comb in combinations([0,1,2,3,4],r):\n",
    "        print(\" \",band_names[list(comb)])\n",
    "        selected_x = None\n",
    "        # print(bands[ list(comb) ])\n",
    "        for pt in bands[ list(comb) ]:\n",
    "            # print(pt)\n",
    "            if(type(selected_x) == type(None)): selected_x = X[:,:,pt].mean(axis=2)\n",
    "            else:\n",
    "                selected_x = np.concatenate([selected_x, X[:,:,pt].mean(axis=2)], axis=1)\n",
    "        # print(selected_x.shape)\n",
    "        # pts = np.concatenate( bands[ list(comb) ] )\n",
    "        result,model = get_acc(selected_x,y)\n",
    "        print(\" Averag accuracy:\", result[0].mean(), \"Average Score:\", result[1].mean(), \"Average Variance:\", result[2].mean())\n",
    "        result_audio.append(result)\n",
    "        if(result[1].mean() > best_audio):\n",
    "            best_audio = result[1].mean()\n",
    "            best_audio_idx = len(result_audio)-1\n",
    "            best_audio_comb = band_names[ list(comb) ]\n",
    "            bast_audio_model = model\n",
    "\n",
    "print(f\"Best Score is {best_audio} at index {best_audio_idx} with combination {best_audio_comb}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-41-68c85db3be4b>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== Number 1 ====================\n",
      "  ['Delta']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.05)\n",
      " Averag accuracy: 0.25733333333333336 Average Score: 0.21133333333333332 Average Variance: 0.05376492040974921\n",
      "  ['Theta']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.02)\n",
      " Averag accuracy: 0.25733333333333336 Average Score: 0.2053333333333333 Average Variance: 0.016110727964792765\n",
      "  ['Alpha']\n",
      "| Accuracy: 0.23 Scores: 0.19 (+/- 0.03)\n",
      " Averag accuracy: 0.23066666666666666 Average Score: 0.19066666666666668 Average Variance: 0.03383620677453206\n",
      "  ['Beta']\n",
      "| Accuracy: 0.24 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.24333333333333335 Average Score: 0.20933333333333332 Average Variance: 0.03612324582438418\n",
      "  ['Gamma']\n",
      "| Accuracy: 0.25 Scores: 0.20 (+/- 0.05)\n",
      " Averag accuracy: 0.24866666666666667 Average Score: 0.20400000000000001 Average Variance: 0.050314566037635226\n",
      "==================== Number 2 ====================\n",
      "  ['Delta' 'Theta']\n",
      "| Accuracy: 0.29 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.2866666666666667 Average Score: 0.19666666666666668 Average Variance: 0.03602468289628346\n",
      "  ['Delta' 'Alpha']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.06)\n",
      " Averag accuracy: 0.2613333333333333 Average Score: 0.20066666666666663 Average Variance: 0.058938762947467575\n",
      "  ['Delta' 'Beta']\n",
      "| Accuracy: 0.27 Scores: 0.21 (+/- 0.05)\n",
      " Averag accuracy: 0.2733333333333333 Average Score: 0.21466666666666664 Average Variance: 0.046303347611160915\n",
      "  ['Delta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.28933333333333333 Average Score: 0.20666666666666664 Average Variance: 0.0429987079909256\n",
      "  ['Theta' 'Alpha']\n",
      "| Accuracy: 0.26 Scores: 0.19 (+/- 0.03)\n",
      " Averag accuracy: 0.262 Average Score: 0.18866666666666668 Average Variance: 0.029694743268426787\n",
      "  ['Theta' 'Beta']\n",
      "| Accuracy: 0.27 Scores: 0.19 (+/- 0.04)\n",
      " Averag accuracy: 0.2653333333333333 Average Score: 0.192 Average Variance: 0.03641733408999377\n",
      "  ['Theta' 'Gamma']\n",
      "| Accuracy: 0.27 Scores: 0.22 (+/- 0.02)\n",
      " Averag accuracy: 0.274 Average Score: 0.21866666666666665 Average Variance: 0.020483055327649616\n",
      "  ['Alpha' 'Beta']\n",
      "| Accuracy: 0.26 Scores: 0.20 (+/- 0.02)\n",
      " Averag accuracy: 0.25866666666666666 Average Score: 0.20400000000000001 Average Variance: 0.022861904265976334\n",
      "  ['Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.22 (+/- 0.04)\n",
      " Averag accuracy: 0.2946666666666667 Average Score: 0.22000000000000003 Average Variance: 0.03699849846803095\n",
      "  ['Beta' 'Gamma']\n",
      "| Accuracy: 0.26 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.26066666666666666 Average Score: 0.20933333333333332 Average Variance: 0.0310984101058416\n",
      "==================== Number 3 ====================\n",
      "  ['Delta' 'Theta' 'Alpha']\n",
      "| Accuracy: 0.29 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.2866666666666667 Average Score: 0.2013333333333333 Average Variance: 0.040353989201124145\n",
      "  ['Delta' 'Theta' 'Beta']\n",
      "| Accuracy: 0.28 Scores: 0.20 (+/- 0.06)\n",
      " Averag accuracy: 0.2833333333333333 Average Score: 0.19666666666666666 Average Variance: 0.056253394959277316\n",
      "  ['Delta' 'Theta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.20 (+/- 0.04)\n",
      " Averag accuracy: 0.2906666666666667 Average Score: 0.19866666666666663 Average Variance: 0.03592584956081995\n",
      "  ['Delta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.2886666666666667 Average Score: 0.20600000000000002 Average Variance: 0.043287154881994486\n",
      "  ['Delta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.22 (+/- 0.03)\n",
      " Averag accuracy: 0.29333333333333333 Average Score: 0.21866666666666665 Average Variance: 0.028472208672083495\n",
      "  ['Delta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.288 Average Score: 0.20800000000000002 Average Variance: 0.028782710859897198\n",
      "  ['Theta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.27 Scores: 0.19 (+/- 0.04)\n",
      " Averag accuracy: 0.26866666666666666 Average Score: 0.18666666666666668 Average Variance: 0.03527668414752786\n",
      "  ['Theta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.22 (+/- 0.07)\n",
      " Averag accuracy: 0.28933333333333333 Average Score: 0.21533333333333332 Average Variance: 0.06935896961941307\n",
      "  ['Theta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.28 Scores: 0.20 (+/- 0.02)\n",
      " Averag accuracy: 0.2826666666666667 Average Score: 0.20466666666666664 Average Variance: 0.01913693345920977\n",
      "  ['Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.28 Scores: 0.21 (+/- 0.02)\n",
      " Averag accuracy: 0.27666666666666667 Average Score: 0.21333333333333332 Average Variance: 0.02231093404090868\n",
      "==================== Number 4 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta']\n",
      "| Accuracy: 0.30 Scores: 0.20 (+/- 0.03)\n",
      " Averag accuracy: 0.29533333333333334 Average Score: 0.19666666666666668 Average Variance: 0.027968235951204044\n",
      "  ['Delta' 'Theta' 'Alpha' 'Gamma']\n",
      "| Accuracy: 0.31 Scores: 0.21 (+/- 0.03)\n",
      " Averag accuracy: 0.31066666666666665 Average Score: 0.20666666666666664 Average Variance: 0.02599145158615725\n",
      "  ['Delta' 'Theta' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.30 Scores: 0.20 (+/- 0.03)\n",
      " Averag accuracy: 0.3 Average Score: 0.1993333333333333 Average Variance: 0.03383620677453205\n",
      "  ['Delta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.30 Scores: 0.21 (+/- 0.02)\n",
      " Averag accuracy: 0.296 Average Score: 0.21400000000000002 Average Variance: 0.021249836600678973\n",
      "  ['Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.29 Scores: 0.21 (+/- 0.04)\n",
      " Averag accuracy: 0.29 Average Score: 0.21066666666666664 Average Variance: 0.035876330792196556\n",
      "==================== Number 5 ====================\n",
      "  ['Delta' 'Theta' 'Alpha' 'Beta' 'Gamma']\n",
      "| Accuracy: 0.30 Scores: 0.20 (+/- 0.03)\n",
      " Averag accuracy: 0.30466666666666664 Average Score: 0.20466666666666664 Average Variance: 0.02686592223947985\n",
      "Best Score is 0.22000000000000003 at index 13 with combination ['Alpha' 'Gamma']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}